#!/usr/bin/env python3
"""
–ü–†–û–î–í–ò–ù–£–¢–´–ô —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞—Ä–±–∏—Ç—Ä–∞–∂–∞.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∞—Å—Ç–æ—è—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è + –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è + ADF —Ç–µ—Å—Ç.
"""

import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Tuple
import warnings
warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤
try:
    from statsmodels.tsa.stattools import coint, adfuller
    from scipy import stats
    STATSMODELS_AVAILABLE = True
except ImportError:
    print("‚ùå –¢—Ä–µ–±—É—é—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ:")
    print("   pip install statsmodels scipy")
    STATSMODELS_AVAILABLE = False
    sys.exit(1)

class CointegratedPairsFinder:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä —Å –ø–æ–ª–Ω—ã–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    
    def __init__(self, 
                 min_correlation: float = 0.7,
                 coint_pvalue_threshold: float = 0.05,
                 adf_pvalue_threshold: float = 0.05,
                 min_common_days: int = 100):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            min_correlation: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
            coint_pvalue_threshold: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π p-value –¥–ª—è —Ç–µ—Å—Ç–∞ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
            adf_pvalue_threshold: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π p-value –¥–ª—è ADF —Ç–µ—Å—Ç–∞ —Å–ø—Ä–µ–¥–∞
            min_common_days: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—â–∏—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π
        """
        if not STATSMODELS_AVAILABLE:
            print("‚ùå –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ statsmodels/scipy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
            sys.exit(1)
        
        self.min_correlation = min_correlation
        self.coint_pvalue_threshold = coint_pvalue_threshold
        self.adf_pvalue_threshold = adf_pvalue_threshold
        self.min_common_days = min_common_days
        
        self.price_matrix = None
        self.metadata = None
        self.cointegrated_pairs = []
        
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CointegratedPairsFinder")
        print("   –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã:")
        print("   - –¢–µ—Å—Ç –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Engle-Granger (coint)")
        print("   - ADF —Ç–µ—Å—Ç –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å (adfuller)")
        print("   - –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è hedge ratio")
        print(f"\n   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        print(f"   - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {min_correlation}")
        print(f"   - Max p-value –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {coint_pvalue_threshold}")
        print(f"   - Max p-value ADF —Ç–µ—Å—Ç–∞: {adf_pvalue_threshold}")
        print(f"   - –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –æ–±—â–∏—Ö –¥–Ω–µ–π: {min_common_days}")
    
    def find_latest_price_file(self) -> Optional[Path]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π CSV —Ñ–∞–π–ª —Å –º–∞—Ç—Ä–∏—Ü–µ–π —Ü–µ–Ω"""
        project_root = Path.cwd()
        price_files = list(project_root.glob("historical_prices_*.csv"))
        
        if not price_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª —Å –º–∞—Ç—Ä–∏—Ü–µ–π —Ü–µ–Ω (historical_prices_*.csv)")
            print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python src/data_feed/fetch_historical_prices.py")
            return None
        
        price_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        return price_files[0]
    
    def find_latest_metadata_file(self) -> Optional[Path]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π CSV —Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        project_root = Path.cwd()
        metadata_files = list(project_root.glob("historical_metadata_*.csv"))
        
        if not metadata_files:
            print("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (historical_metadata_*.csv)")
            return None
        
        metadata_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        return metadata_files[0]
    
    def load_data(self) -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        print("\nüìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É —Ü–µ–Ω
        price_file = self.find_latest_price_file()
        if not price_file:
            return None, None
        
        self.price_matrix = pd.read_csv(price_file, index_col='date', parse_dates=True)
        print(f"‚úÖ –ú–∞—Ç—Ä–∏—Ü–∞ —Ü–µ–Ω: {self.price_matrix.shape[0]} –¥–Ω–µ–π √ó {self.price_matrix.shape[1]} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
        print(f"   –ü–µ—Ä–∏–æ–¥: {self.price_matrix.index.min().date()} - {self.price_matrix.index.max().date()}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata_file = self.find_latest_metadata_file()
        if metadata_file:
            self.metadata = pd.read_csv(metadata_file)
            print(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {len(self.metadata)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
        
        return self.price_matrix, self.metadata
    
    def calculate_hedge_ratio(self, series1: pd.Series, series2: pd.Series) -> Tuple[float, float, float]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç hedge ratio (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è) —á–µ—Ä–µ–∑ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (hedge_ratio, r_squared, intercept)
        """
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –æ–±—â–∏–º –¥–∞—Ç–∞–º
        common_idx = series1.index.intersection(series2.index)
        if len(common_idx) < self.min_common_days:
            return np.nan, np.nan, np.nan
        
        x = series2.loc[common_idx].values
        y = series1.loc[common_idx].values
        
        # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è: y = hedge_ratio * x + intercept
        slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
        r_squared = r_value ** 2
        
        return slope, r_squared, intercept
    
    def test_cointegration(self, series1: pd.Series, series2: pd.Series) -> Tuple[float, float, bool]:
        """
        –¢–µ—Å—Ç –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Engle-Granger
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (test_statistic, p_value, is_cointegrated)
        """
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        common_idx = series1.index.intersection(series2.index)
        if len(common_idx) < self.min_common_days:
            return np.nan, np.nan, False
        
        s1 = series1.loc[common_idx].values
        s2 = series2.loc[common_idx].values
        
        # –¢–µ—Å—Ç –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        test_stat, p_value, _ = coint(s1, s2)
        is_cointegrated = p_value < self.coint_pvalue_threshold
        
        return test_stat, p_value, is_cointegrated
    
    def test_spread_stationarity(self, spread: pd.Series) -> Tuple[float, float, bool]:
        """
        ADF —Ç–µ—Å—Ç –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å —Å–ø—Ä–µ–¥–∞
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (adf_statistic, p_value, is_stationary)
        """
        if len(spread) < 50:  # ADF —Ç–µ—Å—Ç —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            return np.nan, np.nan, False
        
        # ADF —Ç–µ—Å—Ç (Augmented Dickey-Fuller)
        adf_stat, p_value, _, _, _, _ = adfuller(spread.dropna(), autolag='AIC')
        is_stationary = p_value < self.adf_pvalue_threshold
        
        return adf_stat, p_value, is_stationary
    
    def calculate_spread_metrics(self, spread: pd.Series) -> Dict:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —Å–ø—Ä–µ–¥–∞ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏"""
        if len(spread) < 10:
            return {}
        
        spread_series = spread.dropna()
        
        metrics = {
            'spread_mean': spread_series.mean(),
            'spread_std': spread_series.std(),
            'spread_min': spread_series.min(),
            'spread_max': spread_series.max(),
            'half_life': self.calculate_half_life(spread_series),
            'hurst_exponent': self.calculate_hurst_exponent(spread_series),
            'z_score_current': 0,  # –ë—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ –ø–æ–∑–∂–µ –ø—Ä–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ
            'entry_threshold_std': 2.0,  # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä–æ–≥ –≤—Ö–æ–¥–∞
            'exit_threshold_std': 0.5   # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä–æ–≥ –≤—ã—Ö–æ–¥–∞
        }
        
        return metrics
    
    def calculate_half_life(self, spread: pd.Series) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–∏–æ–¥ –ø–æ–ª—É—Ä–∞—Å–ø–∞–¥–∞ (half-life) –¥–ª—è —Å–ø—Ä–µ–¥–∞"""
        try:
            spread_lag = spread.shift(1)
            spread_ret = spread - spread_lag
            spread_lag = spread_lag.iloc[1:]
            spread_ret = spread_ret.iloc[1:]
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            model = stats.linregress(spread_lag.values, spread_ret.values)
            beta = model.slope
            
            if beta >= 0:
                return np.inf  # –ù–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å
                
            half_life = -np.log(2) / beta
            return half_life
            
        except:
            return np.nan
    
    def calculate_hurst_exponent(self, spread: pd.Series, max_lag: int = 20) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —ç–∫—Å–ø–æ–Ω–µ–Ω—Ç—É –•–µ—Ä—Å—Ç–∞ (–º–µ—Ä–∞ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏)"""
        try:
            lags = range(2, min(max_lag, len(spread)//2))
            tau = []
            
            for lag in lags:
                # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ—Å—Ç–µ–π
                spread_diff = spread.diff(lag).dropna()
                if len(spread_diff) > 0:
                    tau.append(np.std(spread_diff))
                else:
                    tau.append(np.nan)
            
            # –£–±–∏—Ä–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
            valid_lags = []
            valid_tau = []
            for lag, t in zip(lags, tau):
                if not np.isnan(t):
                    valid_lags.append(lag)
                    valid_tau.append(t)
            
            if len(valid_lags) < 3:
                return np.nan
            
            # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –≤ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–º –º–∞—Å—à—Ç–∞–±–µ
            x = np.log(valid_lags)
            y = np.log(valid_tau)
            
            slope, _, _, _, _ = stats.linregress(x, y)
            hurst = slope / 2.0
            
            return hurst
            
        except:
            return np.nan
    
    def find_all_pairs(self) -> List[Dict]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ä—ã –∏ –ø—Ä–æ–≤–æ–¥–∏—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        if self.price_matrix is None:
            print("‚ùå –ú–∞—Ç—Ä–∏—Ü–∞ —Ü–µ–Ω –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return []
        
        print(f"\nüîç –ü–æ–∏—Å–∫ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä —Å—Ä–µ–¥–∏ {self.price_matrix.shape[1]} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...")
        print("   –≠—Ç–∞–ø 1/3: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏")
        
        tickers = self.price_matrix.columns.tolist()
        n_tickers = len(tickers)
        pairs = []
        
        # –≠—Ç–∞–ø 1: –ë—ã—Å—Ç—Ä—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        for i in range(n_tickers):
            for j in range(i + 1, n_tickers):
                ticker1 = tickers[i]
                ticker2 = tickers[j]
                
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                data1 = self.price_matrix[ticker1].dropna()
                data2 = self.price_matrix[ticker2].dropna()
                
                # –ù–∞—Ö–æ–¥–∏–º –æ–±—â–∏–µ –¥–∞—Ç—ã
                common_idx = data1.index.intersection(data2.index)
                if len(common_idx) < self.min_common_days:
                    continue
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
                corr = data1.loc[common_idx].corr(data2.loc[common_idx])
                
                if abs(corr) >= self.min_correlation:
                    pairs.append({
                        'ticker1': ticker1,
                        'ticker2': ticker2,
                        'correlation': corr,
                        'common_days': len(common_idx)
                    })
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ {len(pairs)} –ø–∞—Ä —Å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π > {self.min_correlation}")
        print(f"   –≠—Ç–∞–ø 2/3: –¢–µ—Å—Ç –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Engle-Granger")
        
        # –≠—Ç–∞–ø 2: –¢–µ—Å—Ç –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        cointegrated_pairs = []
        for i, pair in enumerate(pairs):
            ticker1 = pair['ticker1']
            ticker2 = pair['ticker2']
            
            print(f"   –ü–∞—Ä–∞ {i+1}/{len(pairs)}: {ticker1} ‚Üî {ticker2}", end="", flush=True)
            
            series1 = self.price_matrix[ticker1].dropna()
            series2 = self.price_matrix[ticker2].dropna()
            
            # –¢–µ—Å—Ç –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
            coint_stat, coint_pvalue, is_cointegrated = self.test_cointegration(series1, series2)
            
            if is_cointegrated:
                print(f" ‚úÖ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ (p={coint_pvalue:.4f})")
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º hedge ratio
                hedge_ratio, r_squared, intercept = self.calculate_hedge_ratio(series1, series2)
                
                if not np.isnan(hedge_ratio):
                    # –°—Ç—Ä–æ–∏–º —Å–ø—Ä–µ–¥
                    common_idx = series1.index.intersection(series2.index)
                    spread = series1.loc[common_idx] - hedge_ratio * series2.loc[common_idx]
                    
                    # ADF —Ç–µ—Å—Ç —Å–ø—Ä–µ–¥–∞
                    adf_stat, adf_pvalue, is_stationary = self.test_spread_stationarity(spread)
                    
                    if is_stationary:
                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å–ø—Ä–µ–¥–∞
                        spread_metrics = self.calculate_spread_metrics(spread)
                        
                        # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                        pair_data = {
                            **pair,
                            'coint_statistic': coint_stat,
                            'coint_pvalue': coint_pvalue,
                            'adf_statistic': adf_stat,
                            'adf_pvalue': adf_pvalue,
                            'hedge_ratio': hedge_ratio,
                            'regression_intercept': intercept,
                            'regression_r_squared': r_squared,
                            'is_cointegrated': is_cointegrated,
                            'is_spread_stationary': is_stationary,
                            **spread_metrics
                        }
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                        if self.metadata is not None:
                            metadata_dict = self.metadata.set_index('ticker').to_dict('index')
                            
                            for field in ['type', 'currency', 'name']:
                                if field in metadata_dict.get(ticker1, {}):
                                    pair_data[f'ticker1_{field}'] = metadata_dict[ticker1].get(field, 'N/A')
                                    pair_data[f'ticker2_{field}'] = metadata_dict[ticker2].get(field, 'N/A')
                        
                        cointegrated_pairs.append(pair_data)
            else:
                print(f" ‚ùå –Ω–µ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ (p={coint_pvalue:.4f})" if not np.isnan(coint_pvalue) else " ‚ùå –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö")
        
        print(f"   –≠—Ç–∞–ø 3/3: ADF —Ç–µ—Å—Ç —Å–ø—Ä–µ–¥–∞")
        print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(cointegrated_pairs)} –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä —Å–æ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º —Å–ø—Ä–µ–¥–æ–º")
        
        return cointegrated_pairs
    
    def save_results(self, pairs: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""
        if not pairs:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞—Ö
        pairs_df = pd.DataFrame(pairs)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É (–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)
        if 'coint_pvalue' in pairs_df.columns and 'adf_pvalue' in pairs_df.columns:
            # –ß–µ–º –º–µ–Ω—å—à–µ p-value, —Ç–µ–º –ª—É—á—à–µ
            pairs_df['quality_score'] = 1 / (pairs_df['coint_pvalue'] * pairs_df['adf_pvalue'])
            pairs_df = pairs_df.sort_values('quality_score', ascending=False)
        
        pairs_file = f"cointegrated_pairs_{timestamp}.csv"
        pairs_df.to_csv(pairs_file, index=False)
        print(f"\nüíæ –ö–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {pairs_file}")
        print(f"   –í—Å–µ–≥–æ –ø–∞—Ä: {len(pairs_df)}")
        
        # 2. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        rec_file = f"trading_recommendations_{timestamp}.txt"
        with open(rec_file, 'w', encoding='utf-8') as f:
            f.write("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ö–û–ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ú –ü–ê–†–ê–ú\n")
            f.write("=" * 70 + "\n\n")
            
            f.write(f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–í—Å–µ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: {self.price_matrix.shape[1]}\n")
            f.write(f"–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞: {self.price_matrix.index.min().date()} - {self.price_matrix.index.max().date()}\n")
            f.write(f"–¢–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π: {self.price_matrix.shape[0]}\n")
            f.write(f"–ù–∞–π–¥–µ–Ω–æ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä: {len(pairs_df)}\n\n")
            
            f.write("–ö–†–ò–¢–ï–†–ò–ò –û–¢–ë–û–†–ê:\n")
            f.write(f"- –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {self.min_correlation}\n")
            f.write(f"- –ú–∞–∫—Å p-value –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {self.coint_pvalue_threshold}\n")
            f.write(f"- –ú–∞–∫—Å p-value ADF —Ç–µ—Å—Ç–∞: {self.adf_pvalue_threshold}\n")
            f.write(f"- –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –æ–±—â–∏—Ö –¥–Ω–µ–π: {self.min_common_days}\n\n")
            
            f.write("–¢–û–ü-10 –ü–ê–† –î–õ–Ø –¢–û–†–ì–û–í–õ–ò:\n")
            f.write("=" * 70 + "\n")
            
            for i, (_, row) in enumerate(pairs_df.head(10).iterrows(), 1):
                f.write(f"\n{i}. {row['ticker1']} ‚Üî {row['ticker2']}\n")
                f.write(f"   –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {row['correlation']:.3f}\n")
                f.write(f"   –ö–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è p-value: {row.get('coint_pvalue', 'N/A'):.4f}\n")
                f.write(f"   ADF —Ç–µ—Å—Ç p-value: {row.get('adf_pvalue', 'N/A'):.4f}\n")
                f.write(f"   Hedge ratio: {row.get('hedge_ratio', 'N/A'):.4f}\n")
                f.write(f"   R¬≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏: {row.get('regression_r_squared', 'N/A'):.3f}\n")
                
                if 'half_life' in row and not pd.isna(row['half_life']):
                    f.write(f"   Half-life: {row['half_life']:.1f} –¥–Ω–µ–π\n")
                if 'hurst_exponent' in row and not pd.isna(row['hurst_exponent']):
                    hurst = row['hurst_exponent']
                    if hurst < 0.5:
                        f.write(f"   –≠–∫—Å–ø–æ–Ω–µ–Ω—Ç–∞ –•–µ—Ä—Å—Ç–∞: {hurst:.3f} (mean-reverting)\n")
                    elif hurst > 0.5:
                        f.write(f"   –≠–∫—Å–ø–æ–Ω–µ–Ω—Ç–∞ –•–µ—Ä—Å—Ç–∞: {hurst:.3f} (trending)\n")
                    else:
                        f.write(f"   –≠–∫—Å–ø–æ–Ω–µ–Ω—Ç–∞ –•–µ—Ä—Å—Ç–∞: {hurst:.3f} (random walk)\n")
                
                f.write(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Å–ø—Ä–µ–¥–∞: {row.get('spread_std', 'N/A'):.3f}\n")
                f.write(f"   –†–µ–∫. –ø–æ—Ä–æ–≥ –≤—Ö–æ–¥–∞: {row.get('entry_threshold_std', 2.0)}œÉ\n")
                f.write(f"   –†–µ–∫. –ø–æ—Ä–æ–≥ –≤—ã—Ö–æ–¥–∞: {row.get('exit_threshold_std', 0.5)}œÉ\n")
        
        print(f"üíæ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {rec_file}")
        
        # 3. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        stats_file = f"cointegration_stats_{timestamp}.txt"
        with open(stats_file, 'w') as f:
            f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê –ö–û–ò–ù–¢–ï–ì–†–ê–¶–ò–ò\n")
            f.write("=" * 50 + "\n")
            
            stats = {
                'timestamp': timestamp,
                'total_instruments': self.price_matrix.shape[1],
                'trading_days': self.price_matrix.shape[0],
                'cointegrated_pairs_found': len(pairs_df),
                'min_correlation': self.min_correlation,
                'coint_pvalue_threshold': self.coint_pvalue_threshold,
                'adf_pvalue_threshold': self.adf_pvalue_threshold,
                'min_common_days': self.min_common_days,
                'pairs_file': pairs_file,
                'recommendations_file': rec_file
            }
            
            for key, value in stats.items():
                f.write(f"{key:30}: {value}\n")
        
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {stats_file}")
        
        return {
            'pairs_file': pairs_file,
            'recommendations_file': rec_file,
            'stats_file': stats_file
        }
    
    def print_summary(self, pairs: List[Dict], files: dict):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É"""
        print("\n" + "=" * 80)
        print("üéØ –ò–¢–û–ì–ò –ê–ù–ê–õ–ò–ó–ê –ö–û–ò–ù–¢–ï–ì–†–ê–¶–ò–ò")
        print("=" * 80)
        
        if not pairs:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä")
            return
        
        pairs_df = pd.DataFrame(pairs)
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(pairs_df)} –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä —Å–æ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º —Å–ø—Ä–µ–¥–æ–º")
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\nüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –°—Ä–µ–¥–Ω—è—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {pairs_df['correlation'].mean():.3f}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π p-value –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {pairs_df['coint_pvalue'].mean():.4f}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π p-value ADF —Ç–µ—Å—Ç–∞: {pairs_df['adf_pvalue'].mean():.4f}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π hedge ratio: {pairs_df['hedge_ratio'].mean():.3f}")
        
        # –¢–æ–ø –ø–∞—Ä –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        print(f"\nüèÜ –¢–û–ü-3 –ø–∞—Ä—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É:")
        
        for i, (_, row) in enumerate(pairs_df.head(3).iterrows(), 1):
            print(f"\n   {i}. {row['ticker1']} ‚Üî {row['ticker2']}")
            print(f"      –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {row['correlation']:.3f}")
            print(f"      –ö–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è: p={row.get('coint_pvalue', 'N/A'):.4f}")
            print(f"      ADF —Ç–µ—Å—Ç: p={row.get('adf_pvalue', 'N/A'):.4f}")
            print(f"      Hedge ratio: {row.get('hedge_ratio', 'N/A'):.4f}")
            
            if 'half_life' in row and not pd.isna(row['half_life']):
                if row['half_life'] < np.inf:
                    print(f"      Half-life: {row['half_life']:.1f} –¥–Ω–µ–π")
            
            if 'spread_std' in row:
                print(f"      Std —Å–ø—Ä–µ–¥–∞: {row['spread_std']:.3f}")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º
        if 'ticker1_type' in pairs_df.columns:
            print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º –ø–∞—Ä:")
            type_counts = pairs_df.apply(
                lambda x: f"{x['ticker1_type']}-{x['ticker2_type']}", axis=1
            ).value_counts()
            
            for pair_type, count in type_counts.head(5).items():
                print(f"   {pair_type:15}: {count} –ø–∞—Ä")
        
        print(f"\nüíæ –§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        for key, value in files.items():
            print(f"   {key:25}: {value}")
        
        print(f"\nüéØ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print(f"   1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å {files['pairs_file']} –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–∞—Ä")
        print(f"   2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ half-life –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏")
        print(f"   3. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–∫—Ä–∏–Ω–µ—Ä —Å–ø—Ä–µ–¥–∞ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–∞—Ä")
        print("=" * 80)
    
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        print("=" * 80)
        print("üî¨ –ê–ù–ê–õ–ò–ó –ö–û–ò–ù–¢–ï–ì–†–ê–¶–ò–ò –î–õ–Ø –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–û–ì–û –ê–†–ë–ò–¢–†–ê–ñ–ê")
        print("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è: Engle-Granger —Ç–µ—Å—Ç + ADF —Ç–µ—Å—Ç + –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è")
        print("=" * 80)
        
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        price_matrix, metadata = self.load_data()
        if price_matrix is None:
            return
        
        # 2. –ù–∞—Ö–æ–¥–∏–º –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã
        pairs = self.find_all_pairs()
        
        if not pairs:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä")
            print("   –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
            print("   - –£–º–µ–Ω—å—à–∏—Ç—å min_correlation")
            print("   - –£–≤–µ–ª–∏—á–∏—Ç—å coint_pvalue_threshold")
            print("   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
            return
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        files = self.save_results(pairs)
        
        # 4. –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        self.print_summary(pairs, files)

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    try:
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
        finder = CointegratedPairsFinder(
            min_correlation=0.65,           # –ß—É—Ç—å –Ω–∏–∂–µ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –æ—Ö–≤–∞—Ç–∞
            coint_pvalue_threshold=0.05,    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π 5% —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
            adf_pvalue_threshold=0.05,      # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π 5% —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
            min_common_days=100             # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        )
        finder.run()
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
