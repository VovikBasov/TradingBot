
================================================================================
–ú–û–ù–û–õ–ò–¢–ù–´–ô –≠–ö–°–ü–û–†–¢ –ü–†–û–ï–ö–¢–ê: python_trading
================================================================================

üìÖ –î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: 2025-12-06 22:03:58
üìÅ –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞: /Users/vladimirbasov/Desktop/python_trading
üë§ –≠–∫—Å–ø–æ—Ä—Ç—ë—Ä: MonolithicProjectExporter v1.0

================================================================================
–ü–†–ò–ú–ï–ß–ê–ù–ò–Ø:
1. –§–∞–π–ª—ã —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ —Å '======'
2. –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–∫–µ–Ω—ã, –∫–ª—é—á–∏) –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ [SECRET_REMOVED]
3. –ë–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–ø—É—â–µ–Ω—ã, —Ç–æ–ª—å–∫–æ –∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
4. –í—Å–µ –ø—É—Ç–∏ —É–∫–∞–∑–∞–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
================================================================================



================================================================================
–§–ê–ô–õ: .env
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/.env
================================================================================

# Tinkoff Invest API
INVEST_TOKEN=[SECRET_REMOVED]

# –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (sandbox –∏–ª–∏ real)
SANDBOX=true

# –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å account_id, –µ—Å–ª–∏ –∑–Ω–∞–µ—Ç–µ
# ACCOUNT_ID=your_account_id


================================================================================
–§–ê–ô–õ: .gitignore
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/.gitignore
================================================================================

# Virtual environment
trading_env/

# Environment variables
.env
.env.local

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Logs
*.log
logs/

# IDE
.vscode/
.idea/
*.swp
*.swo

# Data files
*.csv
*.json
*.pkl
*.feather
*.parquet
data/

# Jupyter
.ipynb_checkpoints

# OS
.DS_Store
Thumbs.db


================================================================================
–§–ê–ô–õ: PROJECT_FULL_EXPORT_20251206_220358.txt
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/PROJECT_FULL_EXPORT_20251206_220358.txt
================================================================================



================================================================================
–§–ê–ô–õ: README.md
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/README.md
================================================================================

# Python Trading Bot

–¢–æ—Ä–≥–æ–≤—ã–π —Ä–æ–±–æ—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏ –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –±–∏—Ä–∂–∞—Ö (MOEX) —á–µ—Ä–µ–∑ Tinkoff Invest API.

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞–ø–∫–∏:
- **`src/`** - –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞
  - **`data_feed/`** - –º–æ–¥—É–ª–∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Å—Ç–∞–∫–∞–Ω—ã, –∫–æ—Ç–∏—Ä–æ–≤–∫–∏)
  - **`strategies/`** - —Ç–æ—Ä–≥–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–ø–æ–∫–∞ –ø—É—Å—Ç–æ)
  - **`execution/`** - –º–æ–¥—É–ª–∏ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞—è–≤–æ–∫ (–ø–æ–∫–∞ –ø—É—Å—Ç–æ)  
  - **`risk_management/`** - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏ (–ø–æ–∫–∞ –ø—É—Å—Ç–æ)
  - **`utils/`** - –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã (–ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ)

- **`tests/`** - —Ç–µ—Å—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
- **`scripts/`** - –ø–æ–ª–µ–∑–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã (—Å–∫—Ä–∏–Ω–µ—Ä—ã, —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö)
- **`project_utils/`** - —É—Ç–∏–ª–∏—Ç—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–º (—ç–∫—Å–ø–æ—Ä—Ç/–∏–º–ø–æ—Ä—Ç)
- **`config/`** - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
- **`notebooks/`** - Jupyter –Ω–æ—É—Ç–±—É–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
- **`data/`** - –¥–∞–Ω–Ω—ã–µ (–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∫–æ—Ç–∏—Ä–æ–≤–∫–∏)
- **`logs/`** - –ª–æ–≥–∏ —Ä–∞–±–æ—Ç—ã

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python -m venv trading_env

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è (Linux/Mac)
source trading_env/bin/activate

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è (Windows)  
trading_env\Scripts\activate

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt
2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –Ω–∞ –æ—Å–Ω–æ–≤–µ .env.example:

env
INVEST_TOKEN=your_tinkoff_invest_token_here
SANDBOX=true
3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

bash
python test_setup.py
üîß –£—Ç–∏–ª–∏—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞

–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–µ–∫—Ç–∞

bash
python project_utils/export_project.py
–°–æ–∑–¥–∞–µ—Ç JSON —Ñ–∞–π–ª —Å–æ –≤—Å–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –ø—Ä–æ–µ–∫—Ç–∞.

–ò–º–ø–æ—Ä—Ç –ø—Ä–æ–µ–∫—Ç–∞

bash
python project_utils/import_project.py project_export_YYYYMMDD_HHMMSS.json
–†–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç –∏–∑ —Ñ–∞–π–ª–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞.

üìä –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å

–†–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥—É–ª–∏:

‚úÖ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞–∫–∞–Ω–æ–≤ —Å MOEX
‚úÖ –†–∞–±–æ—Ç–∞ —Å Tinkoff Invest API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)
‚úÖ –°–∫—Ä–∏–Ω–µ—Ä—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
‚úÖ –í—ã–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ:

üîÑ –¢–æ—Ä–≥–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
üîÑ –ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞—è–≤–æ–∫
üîÑ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏
üîÑ –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥
üõ† –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

Python 3.8+
Tinkoff Invest API
MOEX ISS API
pandas, numpy –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
backtrader –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
loguru –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
üìà –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–Ω–µ—Ä–∞ —Å—Ç–∞–∫–∞–Ω–æ–≤:

bash
python scripts/scanner_gazp.py
–¢–µ—Å—Ç Tinkoff API:

bash
python test_tinkoff_simple.py
‚ö†Ô∏è –í–∞–∂–Ω–æ

–ü—Ä–æ–µ–∫—Ç –≤ –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ
–¢–æ—Ä–≥–æ–≤–ª—è —Å–æ–ø—Ä—è–∂–µ–Ω–∞ —Å —Ä–∏—Å–∫–∞–º–∏
–í—Å–µ–≥–¥–∞ —Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –≤ sandbox —Ä–µ–∂–∏–º–µ
–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –±—ç–∫–∞–ø—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏


================================================================================
–§–ê–ô–õ: check_install.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/check_install.py
================================================================================

print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É –æ—Å–Ω–æ–≤–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫...")

libs_to_check = [
    "pandas", "numpy", "requests", "ccxt", 
    "moexalex", "backtrader", "loguru", "python-dotenv"
]

for lib in libs_to_check:
    try:
        __import__(lib)
        print(f"‚úÖ {lib}")
    except ImportError as e:
        print(f"‚ùå {lib}: {e}")

print("\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–π:")
import pandas as pd
import numpy as np
import ccxt

print(f"Pandas: {pd.__version__}")
print(f"Numpy: {np.__version__}")
print(f"CCXT: {ccxt.__version__}")

print("\nüéØ –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


================================================================================
–§–ê–ô–õ: check_project_structure.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/check_project_structure.py
================================================================================

import os
import sys

def check_structure():
    print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞...")
    
    # –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    expected_dirs = [
        'src',
        'src/data_feed', 
        'src/strategies',
        'src/execution',
        'src/risk_management',
        'src/utils',
        'tests',
        'config',
        'notebooks',
        'scripts',
        'data',
        'logs'
    ]
    
    expected_files = [
        'src/__init__.py',
        'src/data_feed/__init__.py',
        'src/strategies/__init__.py', 
        'src/execution/__init__.py',
        'src/risk_management/__init__.py',
        'src/utils/__init__.py',
        'tests/__init__.py',
        'requirements.txt',
        '.env'
    ]
    
    missing_dirs = []
    missing_files = []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫–∏
    for dir_path in expected_dirs:
        if not os.path.exists(dir_path):
            missing_dirs.append(dir_path)
        else:
            print(f"‚úÖ –ü–∞–ø–∫–∞: {dir_path}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
    for file_path in expected_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
        else:
            print(f"‚úÖ –§–∞–π–ª: {file_path}")
    
    # –í—ã–≤–æ–¥–∏–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
    if missing_dirs:
        print("\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞–ø–∫–∏:")
        for dir_path in missing_dirs:
            print(f"   - {dir_path}")
    
    if missing_files:
        print("\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã:")
        for file_path in missing_files:
            print(f"   - {file_path}")
    
    if not missing_dirs and not missing_files:
        print("\nüéâ –í—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞!")
    else:
        print(f"\nüìù –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å: {len(missing_dirs)} –ø–∞–ø–æ–∫, {len(missing_files)} —Ñ–∞–π–ª–æ–≤")

if __name__ == "__main__":
    check_structure()


================================================================================
–§–ê–ô–õ: create_monolithic_export.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/create_monolithic_export.py
================================================================================

#!/usr/bin/env python3
"""
–°–æ–∑–¥–∞—ë—Ç –º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º –∫–æ–¥–æ–º –ø—Ä–æ–µ–∫—Ç–∞
–ó–∞–ø—É—Å–∫: python create_monolithic_export.py [–ø—É—Ç—å_–∫_–ø—Ä–æ–µ–∫—Ç—É]
"""

import os
import sys
from pathlib import Path
from datetime import datetime

class MonolithicProjectExporter:
    def __init__(self, project_root="."):
        self.project_root = Path(project_root).resolve()
        self.output_file = None
        self.file_count = 0
        self.total_size = 0
        
        # –ü–∞–ø–∫–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ)
        self.exclude_dirs = {
            '.git', '__pycache__', '.pytest_cache', '.mypy_cache',
            'trading_env', 'venv', '.venv', 'env', 'virtualenv',
            'node_modules', '.vscode', '.idea', 'logs', 'data',
            'build', 'dist', '.eggs', '*.egg-info'
        }
        
        # –§–∞–π–ª—ã –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        self.exclude_files = {
            '.DS_Store', 'Thumbs.db', 'desktop.ini',
            '*.pyc', '*.pyo', '*.pyd', '*.so', '*.dll',
            '*.log', '*.tmp', '*.temp', '.coverage',
            '*.db', '*.sqlite', '*.db-journal'
        }
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Ö–æ—Ç–∏–º –≤–∫–ª—é—á–∏—Ç—å (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å)
        self.include_extensions = {
            '.py', '.txt', '.md', '.json', '.yaml', '.yml',
            '.toml', '.ini', '.cfg', '.env', '.sh', '.bat',
            '.html', '.css', '.js', '.ts', '.sql', '.csv'
        }
        
    def should_include(self, path: Path) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –≤–∫–ª—é—á–∞—Ç—å —Ñ–∞–π–ª"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫–∏
        if path.is_dir():
            return path.name not in self.exclude_dirs and not any(
                path.match(pattern) for pattern in self.exclude_dirs if '*' in pattern
            )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
        if any(path.match(pattern) for pattern in self.exclude_files):
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ)
        if path.suffix:
            return path.suffix in self.include_extensions
        
        # –§–∞–π–ª—ã –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∏–º–µ–Ω–∏
        if path.name in ['.env', '.gitignore', 'Dockerfile', 'docker-compose.yml']:
            return True
            
        return False
    
    def sanitize_content(self, content: str, file_path: Path) -> str:
        """–û—á–∏—â–∞–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        relative_path = str(file_path.relative_to(self.project_root))
        
        if file_path.name == '.env':
            lines = content.split('\n')
            cleaned_lines = []
            for line in lines:
                if any(keyword in line.upper() for keyword in 
                       ['TOKEN=', 'KEY=', 'SECRET=', 'PASSWORD=', 'API_']):
                    if '=' in line:
                        key = line.split('=')[0].strip()
                        cleaned_lines.append(f"{key}=[SECRET_REMOVED]")
                    else:
                        cleaned_lines.append(line)
                else:
                    cleaned_lines.append(line)
            return '\n'.join(cleaned_lines)
        
        return content
    
    def write_file_header(self, file_path: Path, relative_path: str):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ñ–∞–π–ª–∞"""
        separator = "=" * 80
        self.output_file.write(f"\n\n{separator}\n")
        self.output_file.write(f"–§–ê–ô–õ: {relative_path}\n")
        self.output_file.write(f"–ü–û–õ–ù–´–ô –ü–£–¢–¨: {file_path}\n")
        self.output_file.write(f"{separator}\n\n")
    
    def process_file(self, file_path: Path):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–¥–∏–Ω —Ñ–∞–π–ª"""
        try:
            relative_path = str(file_path.relative_to(self.project_root))
            
            # –ü–∏—à–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            self.write_file_header(file_path, relative_path)
            
            # –ß–∏—Ç–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # –û—á–∏—â–∞–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                content = self.sanitize_content(content, file_path)
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                self.output_file.write(content)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self.file_count += 1
                self.total_size += len(content)
                
                print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω: {relative_path} ({len(content)} –±–∞–π—Ç)")
                
            except UnicodeDecodeError:
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                try:
                    with open(file_path, 'r', encoding='latin-1') as f:
                        content = f.read()
                    self.output_file.write(f"# –§–∞–π–ª –≤ –∫–æ–¥–∏—Ä–æ–≤–∫–µ latin-1\n{content}")
                    self.file_count += 1
                except:
                    self.output_file.write(f"# –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∫–∞–∫ —Ç–µ–∫—Å—Ç (–±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª)\n")
                    self.output_file.write(f"# –†–∞–∑–º–µ—Ä: {file_path.stat().st_size} –±–∞–π—Ç\n")
                    
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path}: {e}")
    
    def export_project(self, output_filename=None):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        if not output_filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_filename = self.project_root / f"PROJECT_FULL_EXPORT_{timestamp}.txt"
        
        print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–µ–∫—Ç–∞")
        print(f"üìÅ –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞: {self.project_root}")
        print(f"üíæ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_filename}")
        print("=" * 60)
        
        try:
            self.output_file = open(output_filename, 'w', encoding='utf-8')
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —ç–∫—Å–ø–æ—Ä—Ç–∞
            self.write_export_header()
            
            # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã
            for root, dirs, files in os.walk(self.project_root):
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º root –≤ Path
                root_path = Path(root)
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–∞–ø–∫–∏
                dirs[:] = [d for d in dirs if self.should_include(root_path / d)]
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                dirs.sort()
                files.sort()
                
                for file in files:
                    file_path = root_path / file
                    if self.should_include(file_path):
                        self.process_file(file_path)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.write_statistics()
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª
            self.output_file.close()
            
            print("\n" + "=" * 60)
            print(f"üéâ –≠–ö–°–ü–û–†–¢ –ó–ê–í–ï–†–®–Å–ù!")
            print(f"üìä –§–∞–π–ª–æ–≤ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {self.file_count}")
            print(f"üì¶ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–¥–∞: {self.total_size / 1024:.1f} –ö–ë")
            print(f"üíæ –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: {output_filename}")
            print(f"üìè –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {output_filename.stat().st_size / 1024 / 1024:.2f} –ú–ë")
            print("=" * 60)
            
            return output_filename
            
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            if self.output_file:
                self.output_file.close()
            return None
    
    def write_export_header(self):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        header = f"""
{'=' * 80}
–ú–û–ù–û–õ–ò–¢–ù–´–ô –≠–ö–°–ü–û–†–¢ –ü–†–û–ï–ö–¢–ê: {self.project_root.name}
{'=' * 80}

üìÖ –î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
üìÅ –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞: {self.project_root}
üë§ –≠–∫—Å–ø–æ—Ä—Ç—ë—Ä: MonolithicProjectExporter v1.0

{'=' * 80}
–ü–†–ò–ú–ï–ß–ê–ù–ò–Ø:
1. –§–∞–π–ª—ã —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ —Å '======'
2. –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–∫–µ–Ω—ã, –∫–ª—é—á–∏) –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ [SECRET_REMOVED]
3. –ë–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–ø—É—â–µ–Ω—ã, —Ç–æ–ª—å–∫–æ –∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
4. –í—Å–µ –ø—É—Ç–∏ —É–∫–∞–∑–∞–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
{'=' * 80}

"""
        self.output_file.write(header)
    
    def write_statistics(self):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞"""
        stats = f"""

{'=' * 80}
üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –≠–ö–°–ü–û–†–¢–ê
{'=' * 80}
–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {self.file_count}
–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–¥–∞: {self.total_size} –±–∞–π—Ç ({self.total_size / 1024:.1f} –ö–ë)
–î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'=' * 80}

üéØ –ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
1. –ò—â–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ —Å—Ç—Ä–æ–∫–µ "–§–ê–ô–õ: "
2. –í—Å–µ –ø—É—Ç–∏ —É–∫–∞–∑–∞–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ: {self.project_root}
3. –î–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
4. .env —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã –æ—Ç —Å–µ–∫—Ä–µ—Ç–æ–≤

{'=' * 80}
–ö–û–ù–ï–¶ –≠–ö–°–ü–û–†–¢–ê
{'=' * 80}
"""
        self.output_file.write(stats)


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    print("üîß Monolithic Project Exporter v1.0")
    print("–°–æ–∑–¥–∞—ë—Ç –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º –∫–æ–¥–æ–º –ø—Ä–æ–µ–∫—Ç–∞")
    print("=" * 60)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
    if len(sys.argv) > 1:
        project_path = sys.argv[1]
        if not os.path.exists(project_path):
            print(f"‚ùå –ü—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {project_path}")
            return
    else:
        project_path = "."
    
    # –°–æ–∑–¥–∞—ë–º —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä –∏ –∑–∞–ø—É—Å–∫–∞–µ–º
    exporter = MonolithicProjectExporter(project_path)
    
    # –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –≤—Ç–æ—Ä—ã–º –∞—Ä–≥—É–º–µ–Ω—Ç–æ–º
    output_file = None
    if len(sys.argv) > 2:
        output_file = Path(sys.argv[2])
    
    result = exporter.export_project(output_file)
    
    if result:
        print(f"\n‚úÖ –≠–∫—Å–ø–æ—Ä—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {result}")
        print("\nüìã –ë—ã—Å—Ç—Ä—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   –ü—Ä–æ—Å–º–æ—Ç—Ä: type {result} | more")
        print(f"   –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞: findstr /n \"–§–ê–ô–õ: main.py\" {result}")
        print(f"   –ü–æ–¥—Å—á—ë—Ç —Å—Ç—Ä–æ–∫: find /c /v \"\" {result}")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–∫—Å–ø–æ—Ä—Ç")

if __name__ == "__main__":
    main()

================================================================================
–§–ê–ô–õ: debug_imports.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/debug_imports.py
================================================================================

import sys
import os

print("üîß Debug –ø—É—Ç–µ–π Python:")
print(f"–¢–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞: {os.getcwd()}")
print(f"–ü—É—Ç–∏ Python:")
for path in sys.path:
    print(f"  - {path}")

print(f"\nüìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ src/utils/:")
try:
    print(os.listdir("src/utils"))
except Exception as e:
    print(f"–û—à–∏–±–∫–∞: {e}")

print(f"\nüìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ src/data_feed/:")
try:
    print(os.listdir("src/data_feed"))
except Exception as e:
    print(f"–û—à–∏–±–∫–∞: {e}")

# –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç
print(f"\nüîÑ –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç...")
try:
    import importlib.util
    spec = importlib.util.spec_from_file_location("logger", "src/utils/logger.py")
    logger_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(logger_module)
    print("‚úÖ –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç logger.py - –£–°–ü–ï–•")
except Exception as e:
    print(f"‚ùå –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç logger.py: {e}")


================================================================================
–§–ê–ô–õ: debug_installation.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/debug_installation.py
================================================================================

import sys
print("Python –ø—É—Ç—å:", sys.executable)
print("–í–µ—Ä—Å–∏—è Python:", sys.version)

try:
    import pip
    installed_packages = [p.key for p in pip.get_installed_distributions()]
    print("–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ 'tinkoff':", 
          [p for p in installed_packages if 'tinkoff' in p])
except:
    pass

# –ü—Ä–æ–≤–µ—Ä–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏
import pkgutil
all_modules = [name for importer, name, ispkg in pkgutil.iter_modules()]
print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏:", [m for m in all_modules if 'tinkoff' in m or 'invest' in m])


================================================================================
–§–ê–ô–õ: main.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/main.py
================================================================================

#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª trading –±–æ—Ç–∞
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from utils.logger import log
from data_feed.moex_client import MOEXClient

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    log.info("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º trading –±–æ—Ç...")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    client = MOEXClient()
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ SBER
    sber_info = client.get_security_info("SBER")
    if sber_info:
        log.info("‚úÖ MOEX API —Ä–∞–±–æ—Ç–∞–µ—Ç")
    
    log.info("üéØ Trading –±–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: moex_direct.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/moex_direct.py
================================================================================

import requests
import pandas as pd
from loguru import logger

class MOEXClient:
    def __init__(self):
        self.base_url = "https://iss.moex.com/iss"
        self.session = requests.Session()
        logger.info("MOEX –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def get_security_info(self, ticker):
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É–º–∞–≥–µ"""
        url = f"{self.base_url}/securities/{ticker}.json"
        try:
            response = self.session.get(url)
            response.raise_for_status()
            data = response.json()
            logger.info(f"–î–∞–Ω–Ω—ã–µ –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω—ã")
            return data
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ {ticker}: {e}")
            return None
    
    def get_current_price(self, ticker):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É (—É–ø—Ä–æ—â—ë–Ω–Ω–æ)"""
        url = f"{self.base_url}/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json"
        try:
            response = self.session.get(url)
            data = response.json()
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ü–µ–Ω—É –∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            market_data = data['marketdata']['data']
            if market_data:
                last_price = market_data[0][12]  # LAST —Ü–µ–Ω–∞
                return last_price
            return None
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω—ã {ticker}: {e}")
            return None

if __name__ == "__main__":
    client = MOEXClient()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ SBER
    sber_info = client.get_security_info("SBER")
    if sber_info:
        print("‚úÖ –î–∞–Ω–Ω—ã–µ SBER –ø–æ–ª—É—á–µ–Ω—ã")
    
    sber_price = client.get_current_price("SBER")
    if sber_price:
        print(f"‚úÖ –¶–µ–Ω–∞ SBER: {sber_price}")


================================================================================
–§–ê–ô–õ: project_export_20251119_152100.json
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/project_export_20251119_152100.json
================================================================================

{
  "export_date": "2025-11-19T15:21:00.554349",
  "project_name": "Python Trading Bot",
  "files": {
    "working_requirements.txt": {
      "content": "pandas>=2.0.0\nnumpy>=1.24.0\nrequests>=2.28.0\nccxt>=4.0.0\npython-binance>=1.0.19\naiohttp>=3.8.0\nwebsocket-client>=1.5.0\nbacktrader>=1.9.78\nloguru>=0.7.0\npython-dotenv>=1.0.0\npydantic>=2.0.0\nscipy>=1.10.0\nscikit-learn>=1.2.0\nmatplotlib>=3.7.0\nplotly>=5.13.0\nseaborn>=0.12.0\n",
      "size": 272,
      "encoding": "utf-8"
    },
    "test_setup.py": {
      "content": "print(\"üéâ –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!\")\nprint(\"–í—ã –≤ –ø–∞–ø–∫–µ:\", __file__)\n\nimport sys\nprint(\"Python –ø—É—Ç—å:\", sys.executable)\n\n# –ü—Ä–æ–≤–µ—Ä–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\ntry:\n    import pandas as pd\n    print(\"‚úÖ pandas —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\nexcept ImportError:\n    print(\"‚ùå pandas –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n\ntry:\n    import numpy as np\n    print(\"‚úÖ numpy —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\") \nexcept ImportError:\n    print(\"‚ùå numpy –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
      "size": 391,
      "encoding": "utf-8"
    },
    "debug_imports.py": {
      "content": "import sys\nimport os\n\nprint(\"üîß Debug –ø—É—Ç–µ–π Python:\")\nprint(f\"–¢–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞: {os.getcwd()}\")\nprint(f\"–ü—É—Ç–∏ Python:\")\nfor path in sys.path:\n    print(f\"  - {path}\")\n\nprint(f\"\\nüìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ src/utils/:\")\ntry:\n    print(os.listdir(\"src/utils\"))\nexcept Exception as e:\n    print(f\"–û—à–∏–±–∫–∞: {e}\")\n\nprint(f\"\\nüìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ src/data_feed/:\")\ntry:\n    print(os.listdir(\"src/data_feed\"))\nexcept Exception as e:\n    print(f\"–û—à–∏–±–∫–∞: {e}\")\n\n# –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç\nprint(f\"\\nüîÑ –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç...\")\ntry:\n    import importlib.util\n    spec = importlib.util.spec_from_file_location(\"logger\", \"src/utils/logger.py\")\n    logger_module = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(logger_module)\n    print(\"‚úÖ –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç logger.py - –£–°–ü–ï–•\")\nexcept Exception as e:\n    print(f\"‚ùå –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç logger.py: {e}\")\n",
      "size": 802,
      "encoding": "utf-8"
    },
    "test_debug.py": {
      "content": "import os\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom tinkoff.invest import Client\n\ntoken = os.getenv('INVEST_TOKEN')\nwith Client(token) as client:\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–∑–æ–≤–∞\n    from tinkoff.invest.schemas import GetOrderBookRequest\n    \n    # –í–∞—Ä–∏–∞–Ω—Ç 1\n    try:\n        request = GetOrderBookRequest(figi=\"BBG004730N88\", depth=5)\n        result = client.market_data.get_order_book(request)\n        print(\"‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 1 —Å GetOrderBookRequest —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n    except Exception as e:\n        print(f\"‚ùå –í–∞—Ä–∏–∞–Ω—Ç 1: {e}\")\n    \n    # –í–∞—Ä–∏–∞–Ω—Ç 2  \n    try:\n        result = client.market_data.get_order_book(figi=\"BBG004730N88\", depth=5)\n        print(\"‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 2 —Å –ø—Ä—è–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n    except Exception as e:\n        print(f\"‚ùå –í–∞—Ä–∏–∞–Ω—Ç 2: {e}\")\n\n",
      "size": 769,
      "encoding": "utf-8"
    },
    "requirements.txt": {
      "content": "pandas>=2.0.0\nnumpy>=1.24.0\nrequests>=2.28.0\nccxt>=4.0.0\nmoexalex>=0.7.0\nbacktrader>=1.9.78\nloguru>=0.7.0\npython-dotenv>=1.0.0\ntinkoff-invest>=2.1.0\n",
      "size": 149,
      "encoding": "utf-8"
    },
    "test_orderbook.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç —Å—Ç–∞–∫–∞–Ω–∞ - –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞\n\"\"\"\n\nimport sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nfrom data_feed.orderbook import MOEXOrderbook\n\ndef main():\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞–∫–∞–Ω...\")\n    \n    client = MOEXOrderbook()\n    \n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER (–æ–Ω –≤—Å–µ–≥–¥–∞ —Ç–æ—Ä–≥—É–µ—Ç—Å—è)\n    print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω SBER...\")\n    client.print_pretty_orderbook(\"SBER\")\n    \n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ GAZP\n    print(\"\\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω GAZP...\")\n    client.print_pretty_orderbook(\"GAZP\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 624,
      "encoding": "utf-8"
    },
    "check_install.py": {
      "content": "print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É –æ—Å–Ω–æ–≤–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫...\")\n\nlibs_to_check = [\n    \"pandas\", \"numpy\", \"requests\", \"ccxt\", \n    \"moexalex\", \"backtrader\", \"loguru\", \"python-dotenv\"\n]\n\nfor lib in libs_to_check:\n    try:\n        __import__(lib)\n        print(f\"‚úÖ {lib}\")\n    except ImportError as e:\n        print(f\"‚ùå {lib}: {e}\")\n\nprint(\"\\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–π:\")\nimport pandas as pd\nimport numpy as np\nimport ccxt\n\nprint(f\"Pandas: {pd.__version__}\")\nprint(f\"Numpy: {np.__version__}\")\nprint(f\"CCXT: {ccxt.__version__}\")\n\nprint(\"\\nüéØ –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
      "size": 549,
      "encoding": "utf-8"
    },
    "check_project_structure.py": {
      "content": "import os\nimport sys\n\ndef check_structure():\n    print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞...\")\n    \n    # –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\n    expected_dirs = [\n        'src',\n        'src/data_feed', \n        'src/strategies',\n        'src/execution',\n        'src/risk_management',\n        'src/utils',\n        'tests',\n        'config',\n        'notebooks',\n        'scripts',\n        'data',\n        'logs'\n    ]\n    \n    expected_files = [\n        'src/__init__.py',\n        'src/data_feed/__init__.py',\n        'src/strategies/__init__.py', \n        'src/execution/__init__.py',\n        'src/risk_management/__init__.py',\n        'src/utils/__init__.py',\n        'tests/__init__.py',\n        'requirements.txt',\n        '.env'\n    ]\n    \n    missing_dirs = []\n    missing_files = []\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫–∏\n    for dir_path in expected_dirs:\n        if not os.path.exists(dir_path):\n            missing_dirs.append(dir_path)\n        else:\n            print(f\"‚úÖ –ü–∞–ø–∫–∞: {dir_path}\")\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã\n    for file_path in expected_files:\n        if not os.path.exists(file_path):\n            missing_files.append(file_path)\n        else:\n            print(f\"‚úÖ –§–∞–π–ª: {file_path}\")\n    \n    # –í—ã–≤–æ–¥–∏–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã\n    if missing_dirs:\n        print(\"\\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞–ø–∫–∏:\")\n        for dir_path in missing_dirs:\n            print(f\"   - {dir_path}\")\n    \n    if missing_files:\n        print(\"\\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã:\")\n        for file_path in missing_files:\n            print(f\"   - {file_path}\")\n    \n    if not missing_dirs and not missing_files:\n        print(\"\\nüéâ –í—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞!\")\n    else:\n        print(f\"\\nüìù –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å: {len(missing_dirs)} –ø–∞–ø–æ–∫, {len(missing_files)} —Ñ–∞–π–ª–æ–≤\")\n\nif __name__ == \"__main__\":\n    check_structure()\n",
      "size": 1790,
      "encoding": "utf-8"
    },
    "moex_direct.py": {
      "content": "import requests\nimport pandas as pd\nfrom loguru import logger\n\nclass MOEXClient:\n    def __init__(self):\n        self.base_url = \"https://iss.moex.com/iss\"\n        self.session = requests.Session()\n        logger.info(\"MOEX –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def get_security_info(self, ticker):\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É–º–∞–≥–µ\"\"\"\n        url = f\"{self.base_url}/securities/{ticker}.json\"\n        try:\n            response = self.session.get(url)\n            response.raise_for_status()\n            data = response.json()\n            logger.info(f\"–î–∞–Ω–Ω—ã–µ –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω—ã\")\n            return data\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ {ticker}: {e}\")\n            return None\n    \n    def get_current_price(self, ticker):\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É (—É–ø—Ä–æ—â—ë–Ω–Ω–æ)\"\"\"\n        url = f\"{self.base_url}/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json\"\n        try:\n            response = self.session.get(url)\n            data = response.json()\n            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ü–µ–Ω—É –∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n            market_data = data['marketdata']['data']\n            if market_data:\n                last_price = market_data[0][12]  # LAST —Ü–µ–Ω–∞\n                return last_price\n            return None\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω—ã {ticker}: {e}\")\n            return None\n\nif __name__ == \"__main__\":\n    client = MOEXClient()\n    \n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ SBER\n    sber_info = client.get_security_info(\"SBER\")\n    if sber_info:\n        print(\"‚úÖ –î–∞–Ω–Ω—ã–µ SBER –ø–æ–ª—É—á–µ–Ω—ã\")\n    \n    sber_price = client.get_current_price(\"SBER\")\n    if sber_price:\n        print(f\"‚úÖ –¶–µ–Ω–∞ SBER: {sber_price}\")\n",
      "size": 1723,
      "encoding": "utf-8"
    },
    "test_tinkoff.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–¢–µ—Å—Ç Tinkoff API - –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞\n\"\"\"\n\nimport sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nfrom data_feed.tinkoff_client import TinkoffAPIClient\n\ndef main():\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º Tinkoff API...\")\n    \n    try:\n        client = TinkoffAPIClient()\n        \n        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER\n        print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω SBER...\")\n        client.print_pretty_orderbook(\"SBER\")\n        \n        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ GAZP\n        print(\"\\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω GAZP...\")\n        client.print_pretty_orderbook(\"GAZP\")\n        \n    except Exception as e:\n        print(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\")\n        print(\"‚ÑπÔ∏è  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\")\n        print(\"   - –¢–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n        print(\"   - –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É\")\n        print(\"   - –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–æ–∫–µ–Ω–∞\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 908,
      "encoding": "utf-8"
    },
    "debug_installation.py": {
      "content": "import sys\nprint(\"Python –ø—É—Ç—å:\", sys.executable)\nprint(\"–í–µ—Ä—Å–∏—è Python:\", sys.version)\n\ntry:\n    import pip\n    installed_packages = [p.key for p in pip.get_installed_distributions()]\n    print(\"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ 'tinkoff':\", \n          [p for p in installed_packages if 'tinkoff' in p])\nexcept:\n    pass\n\n# –ü—Ä–æ–≤–µ—Ä–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏\nimport pkgutil\nall_modules = [name for importer, name, ispkg in pkgutil.iter_modules()]\nprint(\"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏:\", [m for m in all_modules if 'tinkoff' in m or 'invest' in m])\n",
      "size": 523,
      "encoding": "utf-8"
    },
    ".gitignore": {
      "content": "# Virtual environment\ntrading_env/\n\n# Environment variables\n.env\n.env.local\n\n# Python\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# Logs\n*.log\nlogs/\n\n# IDE\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# Data files\n*.csv\n*.json\n*.pkl\n*.feather\n*.parquet\ndata/\n\n# Jupyter\n.ipynb_checkpoints\n\n# OS\n.DS_Store\nThumbs.db\n",
      "size": 426,
      "encoding": "utf-8"
    },
    ".env": {
      "content": "# Tinkoff Invest API\nINVEST_TOKEN=–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω\n\n# –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (sandbox –∏–ª–∏ real)\nSANDBOX=true\n\n# –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å account_id, –µ—Å–ª–∏ –∑–Ω–∞–µ—Ç–µ\n# ACCOUNT_ID=your_account_id\n",
      "size": 171,
      "encoding": "utf-8"
    },
    "test_tinkoff_simple.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç Tinkoff API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\n\"\"\"\n\nimport os\nimport sys\nfrom dotenv import load_dotenv\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nload_dotenv()\n\ndef main():\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Tinkoff API...\")\n    \n    token = os.getenv('INVEST_TOKEN')\n    if not token:\n        print(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n        return\n    \n    try:\n        from tinkoff.invest import Client\n        \n        with Client(token) as client:\n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—á–µ—Ç–∞\n            accounts = client.users.get_accounts()\n            print(\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!\")\n            print(f\"üìã –ù–∞–π–¥–µ–Ω–æ —Å—á–µ—Ç–æ–≤: {len(accounts.accounts)}\")\n            \n            for account in accounts.accounts:\n                print(f\"   - {account.name} (ID: {account.id})\")\n                \n    except Exception as e:\n        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 983,
      "encoding": "utf-8"
    },
    "test_instruments.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤\n\"\"\"\n\nimport os\nimport sys\nfrom dotenv import load_dotenv\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nload_dotenv()\n\ndef main():\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...\")\n    \n    token = os.getenv('INVEST_TOKEN')\n    if not token:\n        print(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        return\n    \n    try:\n        from tinkoff.invest import Client\n        from tinkoff.invest.schemas import InstrumentStatus\n        \n        with Client(token) as client:\n            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ SBER\n            instruments = client.instruments.find_instrument(query=\"SBER\")\n            print(f\"üîç –ù–∞–π–¥–µ–Ω–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ SBER: {len(instruments.instruments)}\")\n            \n            for i, instrument in enumerate(instruments.instruments[:3]):  # –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 3\n                print(f\"\\n–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {i+1}:\")\n                print(f\"  –¢–∏–∫–µ—Ä: {instrument.ticker}\")\n                print(f\"  –ù–∞–∑–≤–∞–Ω–∏–µ: {instrument.name}\")\n                print(f\"  FIGI: {instrument.figi}\")\n                print(f\"  State: {instrument.state}\")\n                print(f\"  Status: {InstrumentStatus(instrument.state).name}\")\n                \n                # –ü–æ–∫–∞–∂–µ–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã –æ–±—ä–µ–∫—Ç–∞\n                print(f\"  –í—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã: {[attr for attr in dir(instrument) if not attr.startswith('_')]}\")\n                \n    except Exception as e:\n        print(f\"‚ùå –û—à–∏–±–∫–∞: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 1484,
      "encoding": "utf-8"
    },
    ".env.example": {
      "content": "# –ü—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤ .env –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è\nLOG_LEVEL=INFO\nLOG_FILE=logs/trading_bot.log\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏ (MOEX)\nMOEX_TIMEOUT=30\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫—Ä–∏–ø—Ç–æ–±–∏—Ä–∂ (–ø–æ–∫–∞ –æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º–∏)\nBINANCE_API_KEY=your_binance_api_key_here\nBINANCE_SECRET_KEY=your_binance_secret_here\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∏—Å–∫–æ–≤\nMAX_POSITION_SIZE=100000\nMAX_DRAWDOWN=0.05\n",
      "size": 399,
      "encoding": "utf-8"
    },
    "main.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª trading –±–æ—Ç–∞\n\"\"\"\n\nimport sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nfrom utils.logger import log\nfrom data_feed.moex_client import MOEXClient\n\ndef main():\n    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è\"\"\"\n    log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º trading –±–æ—Ç...\")\n    \n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n    client = MOEXClient()\n    \n    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ SBER\n    sber_info = client.get_security_info(\"SBER\")\n    if sber_info:\n        log.info(\"‚úÖ MOEX API —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n    \n    log.info(\"üéØ Trading –±–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 625,
      "encoding": "utf-8"
    },
    "test_vscode.py": {
      "content": "import sys\nprint(\"üéØ VSCode —Ç–µ—Å—Ç –∑–∞–ø—É—â–µ–Ω!\")\nprint(f\"Python –ø—É—Ç—å: {sys.executable}\")\nprint(f\"–í–µ—Ä—Å–∏—è Python: {sys.version}\")\n\nif \"trading_env\" in sys.executable:\n    print(\"‚úÖ –†–∞–±–æ—Ç–∞–µ–º –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏!\")\nelse:\n    print(\"‚ùå –ù–ï –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏!\")\n\nimport os\nprint(f\"üìÅ –ü—É—Ç—å: {os.getcwd()}\")\n",
      "size": 300,
      "encoding": "utf-8"
    },
    "tests/test_basic.py": {
      "content": "# test_basic.py\nimport pandas as pd\nimport numpy as np\nimport requests\nimport ccxt\n\nprint(\"‚úÖ –í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Ä–∞–±–æ—Ç–∞—é—Ç!\")\n\n# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ\ndata = pd.DataFrame({\n    'price': [100, 101, 102, 101, 103],\n    'volume': [1000, 1500, 1200, 1800, 2000]\n})\n\nprint(\"üìä –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:\")\nprint(data)\nprint(f\"üìà –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {data['price'].mean():.2f}\")\n\n# –ü—Ä–æ–≤–µ—Ä—è–µ–º requests\nresponse = requests.get('https://httpbin.org/json')\nprint(f\"üåê HTTP –∑–∞–ø—Ä–æ—Å: {response.status_code}\")",
      "size": 474,
      "encoding": "utf-8"
    },
    "tests/final_structure_test.py": {
      "content": "import sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))\n\ndef test_imports():\n    \"\"\"–¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à–∏ –º–æ–¥—É–ª–∏\"\"\"\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã...\")\n    \n    try:\n        from src.utils.logger import log\n        print(\"‚úÖ src.utils.logger - –û–ö\")\n    except ImportError as e:\n        print(f\"‚ùå src.utils.logger: {e}\")\n    \n    try:\n        from src.data_feed.moex_client import MOEXClient\n        print(\"‚úÖ src.data_feed.moex_client - –û–ö\")\n    except ImportError as e:\n        print(f\"‚ùå src.data_feed.moex_client: {e}\")\n    \n    try:\n        import pandas as pd\n        print(\"‚úÖ pandas - –û–ö\")\n    except ImportError as e:\n        print(f\"‚ùå pandas: {e}\")\n    \n    print(\"\\nüéØ –¢–µ—Å—Ç –∏–º–ø–æ—Ä—Ç–æ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω\")\n\nif __name__ == \"__main__\":\n    test_imports()\n",
      "size": 827,
      "encoding": "utf-8"
    },
    "tests/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "scripts/hhru_data_export_v2.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö HeadHunter (HHRU) - –ø–µ—Ä–∏–æ–¥ —Å 26.09.2024\n\"\"\"\n\nimport os\nimport sys\nimport csv\nfrom datetime import datetime, timedelta\nfrom dotenv import load_dotenv\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nload_dotenv()\n\nfrom tinkoff.invest import Client, CandleInterval\nfrom tinkoff.invest.utils import now\nfrom utils.logger import log\n\nclass HHDataExporter:\n    def __init__(self):\n        self.token = os.getenv('INVEST_TOKEN')\n        if not self.token:\n            log.error(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n            raise ValueError(\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        log.info(\"HeadHunter Data Exporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def find_hhru_instrument(self):\n        \"\"\"–ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter –ø–æ —Ç–∏–∫–µ—Ä—É\"\"\"\n        with Client(self.token) as client:\n            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–∏–∫–µ—Ä–æ–≤ HeadHunter\n            tickers_to_try = [\"HEAD\"]\n            \n            for ticker in tickers_to_try:\n                log.info(f\"üîç –ò—â–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º: {ticker}\")\n                instruments = client.instruments.find_instrument(query=ticker)\n                \n                for instrument in instruments.instruments:\n                    if instrument.ticker.upper() == ticker.upper():\n                        log.info(f\"‚úÖ –ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker})\")\n                        log.info(f\"   FIGI: {instrument.figi}\")\n                        log.info(f\"   –¢–∏–ø: {instrument.instrument_type}\")\n                        return instrument\n            \n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter\")\n            return None\n    \n    def get_historical_candles(self, figi, from_date, to_date):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥\"\"\"\n        candles_data = []\n        \n        with Client(self.token) as client:\n            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –ø–æ –¥–Ω—è–º\n            response = client.market_data.get_candles(\n                figi=figi,\n                from_=from_date,\n                to=to_date,\n                interval=CandleInterval.CANDLE_INTERVAL_DAY\n            )\n            \n            for candle in response.candles:\n                candles_data.append({\n                    'time': candle.time.strftime('%Y-%m-%d %H:%M:%S'),\n                    'open': self.quotation_to_float(candle.open),\n                    'high': self.quotation_to_float(candle.high),\n                    'low': self.quotation_to_float(candle.low),\n                    'close': self.quotation_to_float(candle.close),\n                    'volume': candle.volume,\n                    'is_complete': candle.is_complete\n                })\n            \n            log.info(f\"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(candles_data)} —Å–≤–µ—á–µ–π\")\n            return candles_data\n    \n    def quotation_to_float(self, quotation):\n        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float\"\"\"\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\n            return quotation.units + quotation.nano / 1e9\n        return float(quotation) if quotation else 0.0\n    \n    def export_to_csv(self, candles_data, output_path):\n        \"\"\"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV\"\"\"\n        if not candles_data:\n            log.error(\"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞\")\n            return False\n        \n        try:\n            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n                fieldnames = ['time', 'open', 'high', 'low', 'close', 'volume', 'is_complete']\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                \n                writer.writeheader()\n                for candle in candles_data:\n                    writer.writerow(candle)\n            \n            log.info(f\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}\")\n            return True\n            \n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}\")\n            return False\n    \n    def run_export(self):\n        \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞\"\"\"\n        log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö HeadHunter...\")\n        \n        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç\n        instrument = self.find_hhru_instrument()\n        if not instrument:\n            return False\n        \n        # –ù–û–í–´–ô –ü–ï–†–ò–û–î: —Å 26.09.2024 –ø–æ 16.11.2025\n        from_date = datetime(2024, 9, 26)\n        to_date = datetime(2025, 11, 16)\n        \n        log.info(f\"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {from_date.strftime('%d.%m.%Y')} - {to_date.strftime('%d.%m.%Y')}\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\n        candles_data = self.get_historical_candles(\n            instrument.figi, \n            from_date, \n            to_date\n        )\n        \n        if not candles_data:\n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\")\n            return False\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª —Å –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ú –∏–º–µ–Ω–µ–º\n        desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n        # –•–ê–†–î–ö–û–î–ò–ú –∏–º—è —Ñ–∞–π–ª–∞\n        output_filename = \"headhunter_data_sep2024_nov2025.csv\"\n        output_path = os.path.join(desktop_path, output_filename)\n        \n        success = self.export_to_csv(candles_data, output_path)\n        \n        if success:\n            log.info(\"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n            print(f\"\\nüìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}\")\n            print(f\"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(candles_data)}\")\n            print(f\"üìÖ –ü–µ—Ä–∏–æ–¥: 26.09.2024 - 16.11.2025\")\n        \n        return success\n\ndef main():\n    \"\"\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞\"\"\"\n    try:\n        exporter = HHDataExporter()\n        exporter.run_export()\n        \n    except Exception as e:\n        log.error(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\")\n        print(\"\\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:\")\n        print(\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n        print(\"   - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ç–æ—Ä–≥–∏ –ø–æ HHRU –∏–¥—É—Ç\")\n        print(\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 5866,
      "encoding": "utf-8"
    },
    "scripts/scanner_gazp.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–°–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–∞ –ø–æ –ì–∞–∑–ø—Ä–æ–º—É\n–ó–∞–ø—É—Å–∫: python scripts/scanner_gazp.py\n\"\"\"\n\nimport sys\nimport os\nimport time\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom data_feed.orderbook import MOEXOrderbook\nfrom utils.logger import log\n\ndef main():\n    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–Ω–µ—Ä–∞\"\"\"\n    log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–∞...\")\n    \n    client = MOEXOrderbook()\n    \n    # –°–Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER (–æ–Ω –≤—Å–µ–≥–¥–∞ —Ç–æ—Ä–≥—É–µ—Ç—Å—è)\n    log.info(\"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ SBER...\")\n    test_orderbook = client.get_orderbook(\"SBER\")\n    if test_orderbook and ('bids' in test_orderbook or 'asks' in test_orderbook):\n        log.info(\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MOEX —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n    else:\n        log.error(\"‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ MOEX\")\n        return\n    \n    try:\n        while True:\n            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Å–æ–ª—å\n            os.system('clear' if os.name == 'posix' else 'cls')\n            \n            print(\"üéØ –°–ö–†–ò–ù–ï–† –°–¢–ê–ö–ê–ù–ê - –ì–ê–ó–ü–†–û–ú (GAZP)\")\n            print(\"–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\\n\")\n            \n            # –ü–æ–ª—É—á–∞–µ–º –∏ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω\n            client.print_pretty_orderbook(\"GAZP\")\n            \n            # –ñ–¥—ë–º 5 —Å–µ–∫—É–Ω–¥ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n            print(\"\\nüîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...\")\n            time.sleep(5)\n            \n    except KeyboardInterrupt:\n        log.info(\"‚èπÔ∏è  –°–∫—Ä–∏–Ω–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\")\n    except Exception as e:\n        log.error(f\"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–∫—Ä–∏–Ω–µ—Ä–µ: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 1522,
      "encoding": "utf-8"
    },
    "scripts/tinkoff_scanner.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–°–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–æ–≤ –Ω–∞ Tinkoff API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\n\"\"\"\n\nimport sys\nimport os\nimport time\nfrom dotenv import load_dotenv\n\n# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞\nload_dotenv()\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom data_feed.tinkoff_client_simple import TinkoffAPIClientSimple\nfrom utils.logger import log\n\ndef main():\n    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–Ω–µ—Ä–∞\"\"\"\n    log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–Ω–µ—Ä –Ω–∞ Tinkoff API (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)...\")\n    \n    try:\n        client = TinkoffAPIClientSimple()\n        \n        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ\n        test_data = client.get_orderbook(\"SBER\")\n        if test_data:\n            log.info(\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Tinkoff API —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n        else:\n            log.error(\"‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ Tinkoff API\")\n            return\n    \n    except Exception as e:\n        log.error(f\"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}\")\n        return\n    \n    # –°–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\n    tickers = [\"SBER\", \"GAZP\", \"LKOH\", \"ROSN\", \"YNDX\"]\n    \n    try:\n        while True:\n            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Å–æ–ª—å\n            os.system('clear' if os.name == 'posix' else 'cls')\n            \n            print(\"üéØ –°–ö–†–ò–ù–ï–† –°–¢–ê–ö–ê–ù–û–í - TINKOFF API (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)\")\n            print(\"–î–ê–ù–ù–´–ï –†–ï–ê–õ–¨–ù–´–ï - –ë–£–î–¨–¢–ï –û–°–¢–û–†–û–ñ–ù–´!\")\n            print(\"–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\\n\")\n            \n            for ticker in tickers:\n                client.print_pretty_orderbook(ticker, depth=3)\n                print()\n            \n            print(\"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥...\")\n            time.sleep(10)\n            \n    except KeyboardInterrupt:\n        log.info(\"‚èπÔ∏è  –°–∫—Ä–∏–Ω–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\")\n    except Exception as e:\n        log.error(f\"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–∫—Ä–∏–Ω–µ—Ä–µ: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 1798,
      "encoding": "utf-8"
    },
    "scripts/auto_ru_parser.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–ü–∞—Ä—Å–µ—Ä –¥–ª—è auto.ru - —Å–±–æ—Ä –º–∞—Ä–æ–∫ –∏ –º–æ–¥–µ–ª–µ–π –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π\n\"\"\"\n\nimport requests\nimport csv\nimport time\nimport os\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\nimport sys\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –ª–æ–≥–≥–µ—Ä–∞\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom utils.logger import log\n\nclass AutoRuParser:\n    def __init__(self):\n        self.session = requests.Session()\n        self.session.headers.update({\n            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n            'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',\n            'Accept-Encoding': 'gzip, deflate, br',\n            'Connection': 'keep-alive',\n            'Upgrade-Insecure-Requests': '1',\n        })\n        self.base_url = \"https://auto.ru\"\n        \n    def get_page(self, url):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É\"\"\"\n        try:\n            log.info(f\"üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}\")\n            response = self.session.get(url, timeout=10)\n            response.raise_for_status()\n            return response.text\n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}\")\n            return None\n    \n    def parse_brands_and_models(self, url, vehicle_type):\n        \"\"\"–ü–∞—Ä—Å–∏–º –º–∞—Ä–∫–∏ –∏ –º–æ–¥–µ–ª–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã\"\"\"\n        html = self.get_page(url)\n        if not html:\n            return []\n        \n        soup = BeautifulSoup(html, 'html.parser')\n        brands_data = []\n        \n        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –º–∞—Ä–∫–∞–º–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ)\n        brand_selectors = [\n            'select[name=\"mark\"] option',\n            '.Select[data-ga-name=\"mark\"] option',\n            '[data-ftid=\"sales__filter_mark\"] option',\n            'select[data-ftid=\"sales__filter_mark\"] option'\n        ]\n        \n        brand_options = None\n        for selector in brand_selectors:\n            brand_options = soup.select(selector)\n            if brand_options:\n                log.info(f\"‚úÖ –ù–∞—à–ª–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä –º–∞—Ä–æ–∫: {selector}\")\n                break\n        \n        if not brand_options:\n            log.warning(f\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–ø–∏—Å–æ–∫ –º–∞—Ä–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {url}\")\n            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–∞—Ä–∫–∏ –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º\n            brand_links = soup.select('a[href*=\"/cars/\"]')\n            log.info(f\"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –º–∞—Ä–∫–∏: {len(brand_links)}\")\n            return []\n        \n        log.info(f\"üè∑Ô∏è –ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–æ–∫: {len(brand_links)}\")\n        \n        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é –º–∞—Ä–∫—É\n        for option in brand_links:\n            brand_name = option.get_text(strip=True)\n            brand_value = option.get('value') or option.get('href', '')\n            \n            if not brand_name or brand_name in ['–õ—é–±–∞—è', '–í—Å–µ –º–∞—Ä–∫–∏', '']:\n                continue\n                \n            log.info(f\"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Ä–∫—É: {brand_name}\")\n            \n            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è —ç—Ç–æ–π –º–∞—Ä–∫–∏\n            models = self.get_models_for_brand(brand_name, brand_value, vehicle_type)\n            \n            for model_name in models:\n                brands_data.append({\n                    'brand': brand_name,\n                    'model': model_name,\n                    'vehicle_type': vehicle_type\n                })\n            \n            # –ó–∞–¥–µ—Ä–∂–∫–∞ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Å–µ—Ä–≤–µ—Ä\n            time.sleep(1)\n        \n        return brands_data\n    \n    def get_models_for_brand(self, brand_name, brand_value, vehicle_type):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–∞—Ä–∫–∏\"\"\"\n        models = []\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –º–æ–¥–µ–ª—è–º–∏\n        if 'cars' in vehicle_type.lower():\n            model_url = f\"https://auto.ru/nizhniy_novgorod/cars/{brand_name.lower()}/all/\"\n        else:\n            model_url = f\"https://auto.ru/nizhniy_novgorod/lcv/{brand_name.lower()}/all/\"\n        \n        html = self.get_page(model_url)\n        if not html:\n            return models\n        \n        soup = BeautifulSoup(html, 'html.parser')\n        \n        # –ò—â–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä –º–æ–¥–µ–ª–µ–π\n        model_selectors = [\n            'select[name=\"model\"] option',\n            '.Select[data-ga-name=\"model\"] option',\n            '[data-ftid=\"sales__filter_model\"] option',\n            'select[data-ftid=\"sales__filter_model\"] option'\n        ]\n        \n        model_options = None\n        for selector in model_selectors:\n            model_options = soup.select(selector)\n            if model_options:\n                break\n        \n        if model_options:\n            for option in model_options:\n                model_name = option.get_text(strip=True)\n                if model_name and model_name not in ['–õ—é–±–∞—è', '–í—Å–µ –º–æ–¥–µ–ª–∏', '']:\n                    models.append(model_name)\n        \n        log.info(f\"   üöó –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è {brand_name}: {len(models)}\")\n        return models\n    \n    def save_to_csv(self, data, filename):\n        \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª\"\"\"\n        desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n        filepath = os.path.join(desktop_path, filename)\n        \n        try:\n            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\n                fieldnames = ['brand', 'model', 'vehicle_type']\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                \n                writer.writeheader()\n                for row in data:\n                    writer.writerow(row)\n            \n            log.info(f\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filepath}\")\n            log.info(f\"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(data)}\")\n            return True\n            \n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}\")\n            return False\n    \n    def run_parser(self):\n        \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞\"\"\"\n        log.info(\"üöó –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä Auto.ru...\")\n        \n        all_data = []\n        \n        # –ü–∞—Ä—Å–∏–º –ª–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\n        log.info(\"üîç –ü–∞—Ä—Å–∏–º —Ä–∞–∑–¥–µ–ª '–õ–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ'...\")\n        cars_url = \"https://auto.ru/nizhniy_novgorod/cars/all/\"\n        cars_data = self.parse_brands_and_models(cars_url, \"–õ–µ–≥–∫–æ–≤–æ–π\")\n        all_data.extend(cars_data)\n        \n        # –ü–∞—Ä—Å–∏–º –ª–µ–≥–∫–∏–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\n        log.info(\"üîç –ü–∞—Ä—Å–∏–º —Ä–∞–∑–¥–µ–ª '–õ—ë–≥–∫–∏–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ'...\")\n        lcv_url = \"https://auto.ru/nizhniy_novgorod/lcv/all/\"\n        lcv_data = self.parse_brands_and_models(lcv_url, \"–ì—Ä—É–∑–æ–≤–æ–π\")\n        all_data.extend(lcv_data)\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n        if all_data:\n            self.save_to_csv(all_data, \"auto_ru_brands_models.csv\")\n            log.info(\"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n        else:\n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\")\n        \n        return all_data\n\ndef main():\n    \"\"\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞\"\"\"\n    try:\n        parser = AutoRuParser()\n        parser.run_parser()\n        \n    except Exception as e:\n        log.error(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 7071,
      "encoding": "utf-8"
    },
    "scripts/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "scripts/hhru_data_export.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö HeadHunter (HHRU)\n\"\"\"\n\nimport os\nimport sys\nimport csv\nfrom datetime import datetime, timedelta\nfrom dotenv import load_dotenv\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nload_dotenv()\n\nfrom tinkoff.invest import Client, CandleInterval\nfrom tinkoff.invest.utils import now\nfrom utils.logger import log\n\nclass HHDataExporter:\n    def __init__(self):\n        self.token = os.getenv('INVEST_TOKEN')\n        if not self.token:\n            log.error(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n            raise ValueError(\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        log.info(\"HeadHunter Data Exporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def find_hhru_instrument(self):\n        \"\"\"–ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter –ø–æ —Ç–∏–∫–µ—Ä—É\"\"\"\n        with Client(self.token) as client:\n            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–∏–∫–µ—Ä–æ–≤ HeadHunter\n            tickers_to_try = [\"HHRU\", \"HHRS\", \"HH\", \"HHR\"]\n            \n            for ticker in tickers_to_try:\n                log.info(f\"üîç –ò—â–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º: {ticker}\")\n                instruments = client.instruments.find_instrument(query=ticker)\n                \n                for instrument in instruments.instruments:\n                    if instrument.ticker.upper() == ticker.upper():\n                        log.info(f\"‚úÖ –ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker})\")\n                        log.info(f\"   FIGI: {instrument.figi}\")\n                        log.info(f\"   –¢–∏–ø: {instrument.instrument_type}\")\n                        return instrument\n            \n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter\")\n            return None\n    \n    def get_historical_candles(self, figi, from_date, to_date):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥\"\"\"\n        candles_data = []\n        \n        with Client(self.token) as client:\n            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –ø–æ –¥–Ω—è–º\n            response = client.market_data.get_candles(\n                figi=figi,\n                from_=from_date,\n                to=to_date,\n                interval=CandleInterval.CANDLE_INTERVAL_DAY\n            )\n            \n            for candle in response.candles:\n                candles_data.append({\n                    'time': candle.time.strftime('%Y-%m-%d %H:%M:%S'),\n                    'open': self.quotation_to_float(candle.open),\n                    'high': self.quotation_to_float(candle.high),\n                    'low': self.quotation_to_float(candle.low),\n                    'close': self.quotation_to_float(candle.close),\n                    'volume': candle.volume,\n                    'is_complete': candle.is_complete\n                })\n            \n            log.info(f\"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(candles_data)} —Å–≤–µ—á–µ–π\")\n            return candles_data\n    \n    def quotation_to_float(self, quotation):\n        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float\"\"\"\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\n            return quotation.units + quotation.nano / 1e9\n        return float(quotation) if quotation else 0.0\n    \n    def export_to_csv(self, candles_data, output_path):\n        \"\"\"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV\"\"\"\n        if not candles_data:\n            log.error(\"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞\")\n            return False\n        \n        try:\n            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n                fieldnames = ['time', 'open', 'high', 'low', 'close', 'volume', 'is_complete']\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                \n                writer.writeheader()\n                for candle in candles_data:\n                    writer.writerow(candle)\n            \n            log.info(f\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}\")\n            return True\n            \n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}\")\n            return False\n    \n    def run_export(self):\n        \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞\"\"\"\n        log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö HeadHunter...\")\n        \n        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç\n        instrument = self.find_hhru_instrument()\n        if not instrument:\n            return False\n        \n        # –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö\n        from_date = datetime(2024, 1, 1)\n        to_date = datetime(2025, 11, 16)\n        \n        log.info(f\"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {from_date.strftime('%d.%m.%Y')} - {to_date.strftime('%d.%m.%Y')}\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\n        candles_data = self.get_historical_candles(\n            instrument.figi, \n            from_date, \n            to_date\n        )\n        \n        if not candles_data:\n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\")\n            return False\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª\n        desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n        output_filename = f\"headhunter_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n        output_path = os.path.join(desktop_path, output_filename)\n        \n        success = self.export_to_csv(candles_data, output_path)\n        \n        if success:\n            log.info(\"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n            print(f\"\\nüìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}\")\n            print(f\"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(candles_data)}\")\n        \n        return success\n\ndef main():\n    \"\"\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞\"\"\"\n    try:\n        exporter = HHDataExporter()\n        exporter.run_export()\n        \n    except Exception as e:\n        log.error(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\")\n        print(\"\\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:\")\n        print(\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n        print(\"   - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ç–æ—Ä–≥–∏ –ø–æ HHRU –∏–¥—É—Ç\")\n        print(\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 5756,
      "encoding": "utf-8"
    },
    "scripts/auto_ru_parser_simple.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è auto.ru\n\"\"\"\n\nimport requests\nimport csv\nimport os\nimport sys\nimport json\nimport time\n\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom utils.logger import log\n\nclass SimpleAutoRuParser:\n    def __init__(self):\n        self.session = requests.Session()\n        self.session.headers.update({\n            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',\n            'Accept': 'application/json, text/plain, */*',\n        })\n    \n    def get_api_data(self, category):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API auto.ru\"\"\"\n        url = f\"https://auto.ru/-/ajax/desktop/listing/\"\n        params = {\n            'section': 'all',\n            'category': category,\n            'sort': 'fresh_relevance_1-desc'\n        }\n        \n        try:\n            log.info(f\"üîß –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ API –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category}\")\n            response = self.session.get(url, params=params, timeout=10)\n            response.raise_for_status()\n            \n            data = response.json()\n            return data\n            \n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ API –¥–ª—è {category}: {e}\")\n            return None\n    \n    def extract_brands_from_api(self, api_data, vehicle_type):\n        \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ–º –±—Ä–µ–Ω–¥—ã –∏–∑ API –¥–∞–Ω–Ω—ã—Ö\"\"\"\n        brands_data = []\n        \n        if not api_data or 'state' not in api_data:\n            return brands_data\n        \n        state = api_data['state']\n        \n        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –æ –±—Ä–µ–Ω–¥–∞—Ö\n        possible_paths = [\n            state.get('listing', {}).get('data', {}).get('filters', {}).get('mark', []),\n            state.get('filters', {}).get('mark', []),\n            state.get('mark', [])\n        ]\n        \n        marks = []\n        for path in possible_paths:\n            if path and isinstance(path, list) and len(path) > 0:\n                marks = path\n                break\n        \n        log.info(f\"üè∑Ô∏è –ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–æ–∫ –≤ API: {len(marks)}\")\n        \n        for mark in marks:\n            if isinstance(mark, dict):\n                brand_name = mark.get('name', mark.get('title', ''))\n                if brand_name and brand_name not in ['–õ—é–±–∞—è', '–í—Å–µ –º–∞—Ä–∫–∏']:\n                    # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫—É –±–µ–∑ –º–æ–¥–µ–ª–µ–π\n                    brands_data.append({\n                        'brand': brand_name,\n                        'model': '–í—Å–µ –º–æ–¥–µ–ª–∏',\n                        'vehicle_type': vehicle_type\n                    })\n        \n        return brands_data\n    \n    def run_parser(self):\n        \"\"\"–ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä\"\"\"\n        log.info(\"üöó –ó–∞–ø—É—Å–∫–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä Auto.ru...\")\n        \n        all_data = []\n        \n        # –õ–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\n        cars_data = self.get_api_data('cars')\n        if cars_data:\n            cars_brands = self.extract_brands_from_api(cars_data, \"–õ–µ–≥–∫–æ–≤–æ–π\")\n            all_data.extend(cars_brands)\n        \n        time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏\n        \n        # –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\n        lcv_data = self.get_api_data('lcv')\n        if lcv_data:\n            lcv_brands = self.extract_brands_from_api(lcv_data, \"–ì—Ä—É–∑–æ–≤–æ–π\")\n            all_data.extend(lcv_brands)\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV\n        if all_data:\n            desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n            filepath = os.path.join(desktop_path, \"auto_ru_brands_simple.csv\")\n            \n            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\n                writer = csv.DictWriter(csvfile, fieldnames=['brand', 'model', 'vehicle_type'])\n                writer.writeheader()\n                writer.writerows(all_data)\n            \n            log.info(f\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filepath}\")\n            log.info(f\"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(all_data)}\")\n        else:\n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\")\n        \n        return all_data\n\ndef main():\n    try:\n        parser = SimpleAutoRuParser()\n        parser.run_parser()\n    except Exception as e:\n        log.error(f\"‚ùå –û—à–∏–±–∫–∞: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 4113,
      "encoding": "utf-8"
    },
    ".vscode/settings.json": {
      "content": "{\n    \"python.defaultInterpreterPath\": \"${workspaceFolder}/trading_env/bin/python\",\n    \"python.terminal.activateEnvironment\": true,\n    \"python.linting.enabled\": true,\n    \"python.formatting.provider\": \"black\",\n    \"python.formatting.blackArgs\": [\"--line-length\", \"100\"],\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n        \"source.organizeImports\": \"explicit\"\n    },\n    \"python.analysis.extraPaths\": [\"./src\"],\n    \"files.autoSave\": \"onFocusChange\",\n    \"terminal.integrated.shellArgs.osx\": [\"-l\"],\n    \"[python]\": {\n        \"editor.defaultFormatter\": \"ms-python.python\"\n    }\n}\n",
      "size": 605,
      "encoding": "utf-8"
    },
    "src/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/strategies/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/utils/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/utils/logger.py": {
      "content": "from loguru import logger\nimport sys\nimport os\n\ndef setup_logger():\n    \"\"\"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è trading –±–æ—Ç–∞\"\"\"\n    \n    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\n    os.makedirs(\"logs\", exist_ok=True)\n    \n    # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π handler\n    logger.remove()\n    \n    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π handler\n    logger.add(\n        sys.stdout,\n        format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>\",\n        level=\"INFO\",\n        colorize=True\n    )\n    \n    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª–æ–≤—ã–π handler\n    logger.add(\n        \"logs/trading_bot.log\",\n        rotation=\"10 MB\",\n        retention=\"10 days\",\n        level=\"DEBUG\",\n        format=\"{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}\"\n    )\n    \n    return logger\n\n# –°–æ–∑–¥–∞—ë–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä\nlog = setup_logger()\n\nif __name__ == \"__main__\":\n    log.info(\"–õ–æ–≥–≥–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!\")\n    log.debug(\"–û—Ç–ª–∞–¥–æ—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\")\n    log.warning(\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ\")\n",
      "size": 1049,
      "encoding": "utf-8"
    },
    "src/risk_management/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/execution/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/data_feed/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/data_feed/tinkoff_client_simple.py": {
      "content": "import os\nimport sys\nfrom datetime import datetime\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nsrc_root = os.path.dirname(current_dir)\nsys.path.insert(0, src_root)\n\nfrom tinkoff.invest import Client\nfrom utils.logger import log\n\nclass TinkoffAPIClientSimple:\n    def __init__(self):\n        self.token = os.getenv('INVEST_TOKEN')\n        if not self.token:\n            log.error(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n            raise ValueError(\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        log.info(\"Tinkoff API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)\")\n    \n    def find_instrument_by_ticker(self, ticker):\n        with Client(self.token) as client:\n            instruments = client.instruments.find_instrument(query=ticker)\n            for instrument in instruments.instruments:\n                if instrument.ticker == ticker:\n                    log.info(f\"–ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker}), FIGI: {instrument.figi}\")\n                    # –£–ë–ò–†–ê–ï–ú –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã\n                    return instrument\n            log.error(f\"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º {ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n            return None\n    \n    def get_orderbook(self, ticker: str, depth: int = 5):\n        instrument = self.find_instrument_by_ticker(ticker)\n        if not instrument:\n            return None\n            \n        try:\n            with Client(self.token) as client:\n                log.info(f\"–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å—Ç–∞–∫–∞–Ω –¥–ª—è FIGI: {instrument.figi}, –≥–ª—É–±–∏–Ω–∞: {depth}\")\n                orderbook = client.market_data.get_order_book(figi=instrument.figi, depth=depth)\n                \n                # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ç–∞–∫–∞–Ω–∞\n                log.info(f\"–°—Ç–∞–∫–∞–Ω –ø–æ–ª—É—á–µ–Ω: {orderbook}\")\n                log.info(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ bids: {len(orderbook.bids)}\")\n                log.info(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ asks: {len(orderbook.asks)}\")\n                \n                return {\n                    'ticker': ticker,\n                    'instrument': instrument,\n                    'orderbook': orderbook,\n                    'timestamp': datetime.now()\n                }\n                \n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}\")\n            return None\n    \n    def print_pretty_orderbook(self, ticker: str, depth: int = 5):\n        data = self.get_orderbook(ticker, depth)\n        \n        if not data:\n            print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}\")\n            return\n        \n        orderbook = data['orderbook']\n        instrument = data['instrument']\n        \n        print(f\"\\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker} ({instrument.name}):\")\n        print(\"=\" * 60)\n        \n        if orderbook.asks:\n            print(\"üí∞ –ü–†–û–î–ê–ñ–ò (asks):\")\n            for ask in orderbook.asks:\n                price = self.quotation_to_float(ask.price)\n                quantity = ask.quantity\n                print(f\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        else:\n            print(\"üí∞ –ü–†–û–î–ê–ñ–ò (asks): –ø—É—Å—Ç–æ\")\n        \n        print(\"-\" * 30)\n        \n        if orderbook.bids:\n            print(\"üõí –ü–û–ö–£–ü–ö–ò (bids):\")\n            for bid in orderbook.bids:\n                price = self.quotation_to_float(bid.price)\n                quantity = bid.quantity\n                print(f\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        else:\n            print(\"üõí –ü–û–ö–£–ü–ö–ò (bids): –ø—É—Å—Ç–æ\")\n        \n        print(\"=\" * 60)\n        if hasattr(orderbook, 'best_bid_price') and orderbook.best_bid_price:\n            print(f\"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: {self.quotation_to_float(orderbook.best_bid_price):.2f}\")\n        else:\n            print(f\"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö\")\n            \n        if hasattr(orderbook, 'best_ask_price') and orderbook.best_ask_price:\n            print(f\"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {self.quotation_to_float(orderbook.best_ask_price):.2f}\")\n        else:\n            print(f\"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö\")\n            \n        print(f\"‚è∞ –í—Ä–µ–º—è: {data['timestamp'].strftime('%H:%M:%S')}\")\n    \n    def quotation_to_float(self, quotation):\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\n            return quotation.units + quotation.nano / 1e9\n        return float(quotation) if quotation else 0.0\n\nif __name__ == \"__main__\":\n    client = TinkoffAPIClientSimple()\n    client.print_pretty_orderbook(\"SBER\")\n",
      "size": 4292,
      "encoding": "utf-8"
    },
    "src/data_feed/orderbook.py": {
      "content": "import requests\nimport pandas as pd\nimport sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nsrc_root = os.path.dirname(current_dir)\nsys.path.insert(0, src_root)\n\nfrom utils.logger import log\n\nclass MOEXOrderbook:\n    \"\"\"–ö–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ –∑–∞—è–≤–æ–∫ —Å MOEX\"\"\"\n    \n    def __init__(self):\n        self.base_url = \"https://iss.moex.com/iss\"\n        self.session = requests.Session()\n        log.info(\"MOEX Orderbook –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def get_orderbook(self, ticker: str) -> dict:\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –∑–∞—è–≤–æ–∫ –ø–æ —Ç–∏–∫–µ—Ä—É\"\"\"\n        url = f\"{self.base_url}/engines/stock/markets/shares/securities/{ticker}/orderbook.json\"\n        \n        try:\n            response = self.session.get(url)\n            response.raise_for_status()\n            data = response.json()\n            \n            # –ü–∞—Ä—Å–∏–º —Å—Ç–∞–∫–∞–Ω\n            orderbook_data = self._parse_orderbook(data)\n            log.info(f\"–°—Ç–∞–∫–∞–Ω –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω\")\n            return orderbook_data\n            \n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}\")\n            log.error(f\"URL –±—ã–ª: {url}\")\n            return {}\n    \n    def _parse_orderbook(self, data: dict) -> dict:\n        \"\"\"–ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞–∫–∞–Ω–∞\"\"\"\n        result = {}\n        \n        # –ü–∞—Ä—Å–∏–º –ø–æ–∫—É–ø–∫–∏ (bids)\n        if 'orderbook' in data and 'bids' in data['orderbook']:\n            bids_data = data['orderbook']['bids']\n            if bids_data:\n                result['bids'] = pd.DataFrame(bids_data)\n        \n        # –ü–∞—Ä—Å–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks)  \n        if 'orderbook' in data and 'asks' in data['orderbook']:\n            asks_data = data['orderbook']['asks']\n            if asks_data:\n                result['asks'] = pd.DataFrame(asks_data)\n        \n        return result\n    \n    def print_pretty_orderbook(self, ticker: str, levels: int = 5):\n        \"\"\"–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω\"\"\"\n        orderbook = self.get_orderbook(ticker)\n        \n        if not orderbook or ('bids' not in orderbook and 'asks' not in orderbook):\n            print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}\")\n            print(\"‚ÑπÔ∏è  –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\")\n            print(\"   - –¢–æ—Ä–≥–∏ –ø–æ —ç—Ç–æ–π –±—É–º–∞–≥–µ –Ω–µ –∏–¥—É—Ç\")\n            print(\"   - –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ MOEX\")\n            print(\"   - –¢–∏–∫–µ—Ä —É–∫–∞–∑–∞–Ω –Ω–µ–≤–µ—Ä–Ω–æ\")\n            return\n        \n        print(f\"\\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker}:\")\n        print(\"=\" * 50)\n        \n        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks) - —Å–≤–µ—Ä—Ö—É\n        if 'asks' in orderbook and not orderbook['asks'].empty:\n            print(\"üí∞ –ü–†–û–î–ê–ñ–ò (asks):\")\n            asks_df = orderbook['asks'].head(levels)\n            for _, row in asks_df.iterrows():\n                price = row[0]  # –¶–µ–Ω–∞\n                quantity = row[1]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ\n                print(f\"   {price:8.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        \n        print(\"-\" * 30)\n        \n        # –í—ã–≤–æ–¥–∏–º –ø–æ–∫—É–ø–∫–∏ (bids) - —Å–Ω–∏–∑—É\n        if 'bids' in orderbook and not orderbook['bids'].empty:\n            print(\"üõí –ü–û–ö–£–ü–ö–ò (bids):\")\n            bids_df = orderbook['bids'].head(levels)\n            for _, row in bids_df.iterrows():\n                price = row[0]  # –¶–µ–Ω–∞\n                quantity = row[1]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ\n                print(f\"   {price:8.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        \n        print(\"=\" * 50)\n\nif __name__ == \"__main__\":\n    client = MOEXOrderbook()\n    client.print_pretty_orderbook(\"SBER\")\n",
      "size": 3403,
      "encoding": "utf-8"
    },
    "src/data_feed/tinkoff_client.py": {
      "content": "import os\nimport sys\nfrom datetime import datetime\nfrom dotenv import load_dotenv\n\n# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env\nload_dotenv()\n\n# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nsrc_root = os.path.dirname(current_dir)\nsys.path.insert(0, src_root)\n\nfrom tinkoff.invest import Client, GetOrderBookRequest\nfrom tinkoff.invest.schemas import InstrumentStatus\nfrom utils.logger import log\n\nclass TinkoffAPIClient:\n    \"\"\"–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Tinkoff Invest API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\"\"\"\n    \n    def __init__(self):\n        self.token = os.getenv('INVEST_TOKEN')\n        if not self.token:\n            log.error(\"‚ùå –¢–æ–∫–µ–Ω Tinkoff Invest API –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n            raise ValueError(\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        \n        log.info(\"Tinkoff API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)\")\n    \n    def find_instrument_by_ticker(self, ticker):\n        \"\"\"–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ —Ç–∏–∫–µ—Ä—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ FIGI\"\"\"\n        with Client(self.token) as client:\n            instruments = client.instruments.find_instrument(query=ticker)\n            for instrument in instruments.instruments:\n                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º instrument.state –≤–º–µ—Å—Ç–æ instrument.instrument_status\n                if instrument.ticker == ticker and instrument.state == InstrumentStatus.INSTRUMENT_STATUS_BASE:\n                    log.info(f\"–ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker}), FIGI: {instrument.figi}\")\n                    return instrument\n            log.error(f\"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º {ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n            return None\n    \n    def get_orderbook(self, ticker: str, depth: int = 5):\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –∑–∞—è–≤–æ–∫ –ø–æ —Ç–∏–∫–µ—Ä—É\"\"\"\n        instrument = self.find_instrument_by_ticker(ticker)\n        if not instrument:\n            return None\n            \n        try:\n            with Client(self.token) as client:\n                request = GetOrderBookRequest(figi=instrument.figi, depth=depth)\n                orderbook = client.market_data.get_order_book(request)\n                \n                return {\n                    'ticker': ticker,\n                    'instrument': instrument,\n                    'orderbook': orderbook,\n                    'timestamp': datetime.now()\n                }\n                \n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}\")\n            return None\n    \n    def print_pretty_orderbook(self, ticker: str, depth: int = 5):\n        \"\"\"–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω\"\"\"\n        data = self.get_orderbook(ticker, depth)\n        \n        if not data:\n            print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}\")\n            return\n        \n        orderbook = data['orderbook']\n        instrument = data['instrument']\n        \n        print(f\"\\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker} ({instrument.name}):\")\n        print(\"=\" * 60)\n        \n        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks) - —Å–≤–µ—Ä—Ö—É\n        if orderbook.asks:\n            print(\"üí∞ –ü–†–û–î–ê–ñ–ò (asks):\")\n            for ask in orderbook.asks:\n                price = self.quotation_to_float(ask.price)\n                quantity = ask.quantity\n                print(f\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        \n        print(\"-\" * 30)\n        \n        # –í—ã–≤–æ–¥–∏–º –ø–æ–∫—É–ø–∫–∏ (bids) - —Å–Ω–∏–∑—É  \n        if orderbook.bids:\n            print(\"üõí –ü–û–ö–£–ü–ö–ò (bids):\")\n            for bid in orderbook.bids:\n                price = self.quotation_to_float(bid.price)\n                quantity = bid.quantity\n                print(f\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        \n        print(\"=\" * 60)\n        if hasattr(orderbook, 'best_bid') and orderbook.best_bid:\n            print(f\"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: {self.quotation_to_float(orderbook.best_bid):.2f}\")\n        if hasattr(orderbook, 'best_ask') and orderbook.best_ask:\n            print(f\"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {self.quotation_to_float(orderbook.best_ask):.2f}\")\n        print(f\"‚è∞ –í—Ä–µ–º—è: {data['timestamp'].strftime('%H:%M:%S')}\")\n    \n    def quotation_to_float(self, quotation):\n        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float\"\"\"\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\n            return quotation.units + quotation.nano / 1e9\n        return float(quotation) if quotation else 0.0\n\nif __name__ == \"__main__\":\n    client = TinkoffAPIClient()\n    client.print_pretty_orderbook(\"SBER\")\n",
      "size": 4306,
      "encoding": "utf-8"
    },
    "src/data_feed/moex_client.py": {
      "content": "import requests\nimport pandas as pd\nfrom src.utils.logger import log\n\nclass MOEXClient:\n    \"\"\"\n    –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å API –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏\n    \"\"\"\n    \n    def __init__(self):\n        self.base_url = \"https://iss.moex.com/iss\"\n        self.session = requests.Session()\n        log.info(\"MOEX –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def get_security_info(self, ticker: str) -> dict:\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É–º–∞–≥–µ\"\"\"\n        url = f\"{self.base_url}/securities/{ticker}.json\"\n        try:\n            response = self.session.get(url)\n            response.raise_for_status()\n            data = response.json()\n            log.info(f\"–î–∞–Ω–Ω—ã–µ –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω—ã\")\n            return data\n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ {ticker}: {e}\")\n            return {}\n    \n    def get_current_market_data(self, ticker: str) -> dict:\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\"\"\"\n        url = f\"{self.base_url}/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json\"\n        try:\n            response = self.session.get(url)\n            data = response.json()\n            \n            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n            market_data = data.get('marketdata', {}).get('data', [])\n            if market_data:\n                # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è –∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n                last_trade = market_data[0]\n                return {\n                    'last_price': last_trade[12],  # LAST\n                    'change': last_trade[13],      # CHANGE\n                    'volume': last_trade[9]        # VOLUME\n                }\n            return {}\n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö {ticker}: {e}\")\n            return {}\n\nif __name__ == \"__main__\":\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç\n    client = MOEXClient()\n    \n    # –¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ SBER\n    sber_info = client.get_security_info(\"SBER\")\n    if sber_info:\n        log.info(\"‚úÖ MOEX –∫–ª–∏–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç - –¥–∞–Ω–Ω—ã–µ SBER –ø–æ–ª—É—á–µ–Ω—ã\")\n    \n    sber_market = client.get_current_market_data(\"SBER\")\n    if sber_market:\n        log.info(f\"‚úÖ –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ SBER: {sber_market}\")\n",
      "size": 2126,
      "encoding": "utf-8"
    }
  }
}

================================================================================
–§–ê–ô–õ: project_export_20251206_195759.json
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/project_export_20251206_195759.json
================================================================================

{
  "export_date": "2025-12-06T19:57:59.301901",
  "project_name": "Python Trading Bot",
  "files": {
    "working_requirements.txt": {
      "content": "pandas>=2.0.0\nnumpy>=1.24.0\nrequests>=2.28.0\nccxt>=4.0.0\npython-binance>=1.0.19\naiohttp>=3.8.0\nwebsocket-client>=1.5.0\nbacktrader>=1.9.78\nloguru>=0.7.0\npython-dotenv>=1.0.0\npydantic>=2.0.0\nscipy>=1.10.0\nscikit-learn>=1.2.0\nmatplotlib>=3.7.0\nplotly>=5.13.0\nseaborn>=0.12.0\n",
      "size": 272,
      "encoding": "utf-8"
    },
    "test_setup.py": {
      "content": "print(\"üéâ –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!\")\nprint(\"–í—ã –≤ –ø–∞–ø–∫–µ:\", __file__)\n\nimport sys\nprint(\"Python –ø—É—Ç—å:\", sys.executable)\n\n# –ü—Ä–æ–≤–µ—Ä–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\ntry:\n    import pandas as pd\n    print(\"‚úÖ pandas —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\nexcept ImportError:\n    print(\"‚ùå pandas –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n\ntry:\n    import numpy as np\n    print(\"‚úÖ numpy —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\") \nexcept ImportError:\n    print(\"‚ùå numpy –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
      "size": 391,
      "encoding": "utf-8"
    },
    "debug_imports.py": {
      "content": "import sys\nimport os\n\nprint(\"üîß Debug –ø—É—Ç–µ–π Python:\")\nprint(f\"–¢–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞: {os.getcwd()}\")\nprint(f\"–ü—É—Ç–∏ Python:\")\nfor path in sys.path:\n    print(f\"  - {path}\")\n\nprint(f\"\\nüìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ src/utils/:\")\ntry:\n    print(os.listdir(\"src/utils\"))\nexcept Exception as e:\n    print(f\"–û—à–∏–±–∫–∞: {e}\")\n\nprint(f\"\\nüìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ src/data_feed/:\")\ntry:\n    print(os.listdir(\"src/data_feed\"))\nexcept Exception as e:\n    print(f\"–û—à–∏–±–∫–∞: {e}\")\n\n# –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç\nprint(f\"\\nüîÑ –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç...\")\ntry:\n    import importlib.util\n    spec = importlib.util.spec_from_file_location(\"logger\", \"src/utils/logger.py\")\n    logger_module = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(logger_module)\n    print(\"‚úÖ –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç logger.py - –£–°–ü–ï–•\")\nexcept Exception as e:\n    print(f\"‚ùå –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç logger.py: {e}\")\n",
      "size": 802,
      "encoding": "utf-8"
    },
    "test_debug.py": {
      "content": "import os\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom tinkoff.invest import Client\n\ntoken = os.getenv('INVEST_TOKEN')\nwith Client(token) as client:\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–∑–æ–≤–∞\n    from tinkoff.invest.schemas import GetOrderBookRequest\n    \n    # –í–∞—Ä–∏–∞–Ω—Ç 1\n    try:\n        request = GetOrderBookRequest(figi=\"BBG004730N88\", depth=5)\n        result = client.market_data.get_order_book(request)\n        print(\"‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 1 —Å GetOrderBookRequest —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n    except Exception as e:\n        print(f\"‚ùå –í–∞—Ä–∏–∞–Ω—Ç 1: {e}\")\n    \n    # –í–∞—Ä–∏–∞–Ω—Ç 2  \n    try:\n        result = client.market_data.get_order_book(figi=\"BBG004730N88\", depth=5)\n        print(\"‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 2 —Å –ø—Ä—è–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n    except Exception as e:\n        print(f\"‚ùå –í–∞—Ä–∏–∞–Ω—Ç 2: {e}\")\n\n",
      "size": 769,
      "encoding": "utf-8"
    },
    "requirements.txt": {
      "content": "pandas>=2.0.0\nnumpy>=1.24.0\nrequests>=2.28.0\nccxt>=4.0.0\nmoexalex>=0.7.0\nbacktrader>=1.9.78\nloguru>=0.7.0\npython-dotenv>=1.0.0\ntinkoff-invest>=2.1.0\n",
      "size": 149,
      "encoding": "utf-8"
    },
    "test_orderbook.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç —Å—Ç–∞–∫–∞–Ω–∞ - –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞\n\"\"\"\n\nimport sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nfrom data_feed.orderbook import MOEXOrderbook\n\ndef main():\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞–∫–∞–Ω...\")\n    \n    client = MOEXOrderbook()\n    \n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER (–æ–Ω –≤—Å–µ–≥–¥–∞ —Ç–æ—Ä–≥—É–µ—Ç—Å—è)\n    print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω SBER...\")\n    client.print_pretty_orderbook(\"SBER\")\n    \n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ GAZP\n    print(\"\\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω GAZP...\")\n    client.print_pretty_orderbook(\"GAZP\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 624,
      "encoding": "utf-8"
    },
    "check_install.py": {
      "content": "print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É –æ—Å–Ω–æ–≤–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫...\")\n\nlibs_to_check = [\n    \"pandas\", \"numpy\", \"requests\", \"ccxt\", \n    \"moexalex\", \"backtrader\", \"loguru\", \"python-dotenv\"\n]\n\nfor lib in libs_to_check:\n    try:\n        __import__(lib)\n        print(f\"‚úÖ {lib}\")\n    except ImportError as e:\n        print(f\"‚ùå {lib}: {e}\")\n\nprint(\"\\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–π:\")\nimport pandas as pd\nimport numpy as np\nimport ccxt\n\nprint(f\"Pandas: {pd.__version__}\")\nprint(f\"Numpy: {np.__version__}\")\nprint(f\"CCXT: {ccxt.__version__}\")\n\nprint(\"\\nüéØ –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
      "size": 549,
      "encoding": "utf-8"
    },
    "check_project_structure.py": {
      "content": "import os\nimport sys\n\ndef check_structure():\n    print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞...\")\n    \n    # –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\n    expected_dirs = [\n        'src',\n        'src/data_feed', \n        'src/strategies',\n        'src/execution',\n        'src/risk_management',\n        'src/utils',\n        'tests',\n        'config',\n        'notebooks',\n        'scripts',\n        'data',\n        'logs'\n    ]\n    \n    expected_files = [\n        'src/__init__.py',\n        'src/data_feed/__init__.py',\n        'src/strategies/__init__.py', \n        'src/execution/__init__.py',\n        'src/risk_management/__init__.py',\n        'src/utils/__init__.py',\n        'tests/__init__.py',\n        'requirements.txt',\n        '.env'\n    ]\n    \n    missing_dirs = []\n    missing_files = []\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫–∏\n    for dir_path in expected_dirs:\n        if not os.path.exists(dir_path):\n            missing_dirs.append(dir_path)\n        else:\n            print(f\"‚úÖ –ü–∞–ø–∫–∞: {dir_path}\")\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã\n    for file_path in expected_files:\n        if not os.path.exists(file_path):\n            missing_files.append(file_path)\n        else:\n            print(f\"‚úÖ –§–∞–π–ª: {file_path}\")\n    \n    # –í—ã–≤–æ–¥–∏–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã\n    if missing_dirs:\n        print(\"\\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞–ø–∫–∏:\")\n        for dir_path in missing_dirs:\n            print(f\"   - {dir_path}\")\n    \n    if missing_files:\n        print(\"\\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã:\")\n        for file_path in missing_files:\n            print(f\"   - {file_path}\")\n    \n    if not missing_dirs and not missing_files:\n        print(\"\\nüéâ –í—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞!\")\n    else:\n        print(f\"\\nüìù –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å: {len(missing_dirs)} –ø–∞–ø–æ–∫, {len(missing_files)} —Ñ–∞–π–ª–æ–≤\")\n\nif __name__ == \"__main__\":\n    check_structure()\n",
      "size": 1790,
      "encoding": "utf-8"
    },
    "moex_direct.py": {
      "content": "import requests\nimport pandas as pd\nfrom loguru import logger\n\nclass MOEXClient:\n    def __init__(self):\n        self.base_url = \"https://iss.moex.com/iss\"\n        self.session = requests.Session()\n        logger.info(\"MOEX –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def get_security_info(self, ticker):\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É–º–∞–≥–µ\"\"\"\n        url = f\"{self.base_url}/securities/{ticker}.json\"\n        try:\n            response = self.session.get(url)\n            response.raise_for_status()\n            data = response.json()\n            logger.info(f\"–î–∞–Ω–Ω—ã–µ –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω—ã\")\n            return data\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ {ticker}: {e}\")\n            return None\n    \n    def get_current_price(self, ticker):\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É (—É–ø—Ä–æ—â—ë–Ω–Ω–æ)\"\"\"\n        url = f\"{self.base_url}/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json\"\n        try:\n            response = self.session.get(url)\n            data = response.json()\n            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ü–µ–Ω—É –∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n            market_data = data['marketdata']['data']\n            if market_data:\n                last_price = market_data[0][12]  # LAST —Ü–µ–Ω–∞\n                return last_price\n            return None\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω—ã {ticker}: {e}\")\n            return None\n\nif __name__ == \"__main__\":\n    client = MOEXClient()\n    \n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ SBER\n    sber_info = client.get_security_info(\"SBER\")\n    if sber_info:\n        print(\"‚úÖ –î–∞–Ω–Ω—ã–µ SBER –ø–æ–ª—É—á–µ–Ω—ã\")\n    \n    sber_price = client.get_current_price(\"SBER\")\n    if sber_price:\n        print(f\"‚úÖ –¶–µ–Ω–∞ SBER: {sber_price}\")\n",
      "size": 1723,
      "encoding": "utf-8"
    },
    "test_tinkoff.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–¢–µ—Å—Ç Tinkoff API - –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞\n\"\"\"\n\nimport sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nfrom data_feed.tinkoff_client import TinkoffAPIClient\n\ndef main():\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º Tinkoff API...\")\n    \n    try:\n        client = TinkoffAPIClient()\n        \n        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER\n        print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω SBER...\")\n        client.print_pretty_orderbook(\"SBER\")\n        \n        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ GAZP\n        print(\"\\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω GAZP...\")\n        client.print_pretty_orderbook(\"GAZP\")\n        \n    except Exception as e:\n        print(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\")\n        print(\"‚ÑπÔ∏è  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\")\n        print(\"   - –¢–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n        print(\"   - –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É\")\n        print(\"   - –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–æ–∫–µ–Ω–∞\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 908,
      "encoding": "utf-8"
    },
    "README.md": {
      "content": "# Python Trading Bot\n\n–¢–æ—Ä–≥–æ–≤—ã–π —Ä–æ–±–æ—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏ –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –±–∏—Ä–∂–∞—Ö (MOEX) —á–µ—Ä–µ–∑ Tinkoff Invest API.\n\n## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞\n\n### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞–ø–∫–∏:\n- **`src/`** - –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞\n  - **`data_feed/`** - –º–æ–¥—É–ª–∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Å—Ç–∞–∫–∞–Ω—ã, –∫–æ—Ç–∏—Ä–æ–≤–∫–∏)\n  - **`strategies/`** - —Ç–æ—Ä–≥–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–ø–æ–∫–∞ –ø—É—Å—Ç–æ)\n  - **`execution/`** - –º–æ–¥—É–ª–∏ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞—è–≤–æ–∫ (–ø–æ–∫–∞ –ø—É—Å—Ç–æ)  \n  - **`risk_management/`** - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏ (–ø–æ–∫–∞ –ø—É—Å—Ç–æ)\n  - **`utils/`** - –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã (–ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ)\n\n- **`tests/`** - —Ç–µ—Å—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞\n- **`scripts/`** - –ø–æ–ª–µ–∑–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã (—Å–∫—Ä–∏–Ω–µ—Ä—ã, —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö)\n- **`project_utils/`** - —É—Ç–∏–ª–∏—Ç—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–º (—ç–∫—Å–ø–æ—Ä—Ç/–∏–º–ø–æ—Ä—Ç)\n- **`config/`** - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n- **`notebooks/`** - Jupyter –Ω–æ—É—Ç–±—É–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n- **`data/`** - –¥–∞–Ω–Ω—ã–µ (–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∫–æ—Ç–∏—Ä–æ–≤–∫–∏)\n- **`logs/`** - –ª–æ–≥–∏ —Ä–∞–±–æ—Ç—ã\n\n## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n\n### 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n```bash\n# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è\npython -m venv trading_env\n\n# –ê–∫—Ç–∏–≤–∞—Ü–∏—è (Linux/Mac)\nsource trading_env/bin/activate\n\n# –ê–∫—Ç–∏–≤–∞—Ü–∏—è (Windows)  \ntrading_env\\Scripts\\activate\n\n# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\npip install -r requirements.txt\n2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API\n\n–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –Ω–∞ –æ—Å–Ω–æ–≤–µ .env.example:\n\nenv\nINVEST_TOKEN=your_tinkoff_invest_token_here\nSANDBOX=true\n3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏\n\nbash\npython test_setup.py\nüîß –£—Ç–∏–ª–∏—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞\n\n–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–µ–∫—Ç–∞\n\nbash\npython project_utils/export_project.py\n–°–æ–∑–¥–∞–µ—Ç JSON —Ñ–∞–π–ª —Å–æ –≤—Å–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –ø—Ä–æ–µ–∫—Ç–∞.\n\n–ò–º–ø–æ—Ä—Ç –ø—Ä–æ–µ–∫—Ç–∞\n\nbash\npython project_utils/import_project.py project_export_YYYYMMDD_HHMMSS.json\n–†–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç –∏–∑ —Ñ–∞–π–ª–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞.\n\nüìä –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å\n\n–†–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥—É–ª–∏:\n\n‚úÖ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞–∫–∞–Ω–æ–≤ —Å MOEX\n‚úÖ –†–∞–±–æ—Ç–∞ —Å Tinkoff Invest API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\n‚úÖ –°–∫—Ä–∏–Ω–µ—Ä—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n‚úÖ –í—ã–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ:\n\nüîÑ –¢–æ—Ä–≥–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏\nüîÑ –ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞—è–≤–æ–∫\nüîÑ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏\nüîÑ –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥\nüõ† –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\n\nPython 3.8+\nTinkoff Invest API\nMOEX ISS API\npandas, numpy –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\nbacktrader –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞\nloguru –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\nüìà –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n\n–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–Ω–µ—Ä–∞ —Å—Ç–∞–∫–∞–Ω–æ–≤:\n\nbash\npython scripts/scanner_gazp.py\n–¢–µ—Å—Ç Tinkoff API:\n\nbash\npython test_tinkoff_simple.py\n‚ö†Ô∏è –í–∞–∂–Ω–æ\n\n–ü—Ä–æ–µ–∫—Ç –≤ –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ\n–¢–æ—Ä–≥–æ–≤–ª—è —Å–æ–ø—Ä—è–∂–µ–Ω–∞ —Å —Ä–∏—Å–∫–∞–º–∏\n–í—Å–µ–≥–¥–∞ —Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –≤ sandbox —Ä–µ–∂–∏–º–µ\n–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –±—ç–∫–∞–ø—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n",
      "size": 2273,
      "encoding": "utf-8"
    },
    "debug_installation.py": {
      "content": "import sys\nprint(\"Python –ø—É—Ç—å:\", sys.executable)\nprint(\"–í–µ—Ä—Å–∏—è Python:\", sys.version)\n\ntry:\n    import pip\n    installed_packages = [p.key for p in pip.get_installed_distributions()]\n    print(\"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ 'tinkoff':\", \n          [p for p in installed_packages if 'tinkoff' in p])\nexcept:\n    pass\n\n# –ü—Ä–æ–≤–µ—Ä–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏\nimport pkgutil\nall_modules = [name for importer, name, ispkg in pkgutil.iter_modules()]\nprint(\"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏:\", [m for m in all_modules if 'tinkoff' in m or 'invest' in m])\n",
      "size": 523,
      "encoding": "utf-8"
    },
    ".gitignore": {
      "content": "# Virtual environment\ntrading_env/\n\n# Environment variables\n.env\n.env.local\n\n# Python\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# Logs\n*.log\nlogs/\n\n# IDE\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# Data files\n*.csv\n*.json\n*.pkl\n*.feather\n*.parquet\ndata/\n\n# Jupyter\n.ipynb_checkpoints\n\n# OS\n.DS_Store\nThumbs.db\n",
      "size": 426,
      "encoding": "utf-8"
    },
    ".env": {
      "content": "# Tinkoff Invest API\nINVEST_TOKEN=–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω\n\n# –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (sandbox –∏–ª–∏ real)\nSANDBOX=true\n\n# –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å account_id, –µ—Å–ª–∏ –∑–Ω–∞–µ—Ç–µ\n# ACCOUNT_ID=your_account_id\n",
      "size": 171,
      "encoding": "utf-8"
    },
    "test_tinkoff_simple.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç Tinkoff API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\n\"\"\"\n\nimport os\nimport sys\nfrom dotenv import load_dotenv\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nload_dotenv()\n\ndef main():\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Tinkoff API...\")\n    \n    token = os.getenv('INVEST_TOKEN')\n    if not token:\n        print(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n        return\n    \n    try:\n        from tinkoff.invest import Client\n        \n        with Client(token) as client:\n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—á–µ—Ç–∞\n            accounts = client.users.get_accounts()\n            print(\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!\")\n            print(f\"üìã –ù–∞–π–¥–µ–Ω–æ —Å—á–µ—Ç–æ–≤: {len(accounts.accounts)}\")\n            \n            for account in accounts.accounts:\n                print(f\"   - {account.name} (ID: {account.id})\")\n                \n    except Exception as e:\n        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 983,
      "encoding": "utf-8"
    },
    "test_instruments.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤\n\"\"\"\n\nimport os\nimport sys\nfrom dotenv import load_dotenv\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nload_dotenv()\n\ndef main():\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...\")\n    \n    token = os.getenv('INVEST_TOKEN')\n    if not token:\n        print(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        return\n    \n    try:\n        from tinkoff.invest import Client\n        from tinkoff.invest.schemas import InstrumentStatus\n        \n        with Client(token) as client:\n            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ SBER\n            instruments = client.instruments.find_instrument(query=\"SBER\")\n            print(f\"üîç –ù–∞–π–¥–µ–Ω–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ SBER: {len(instruments.instruments)}\")\n            \n            for i, instrument in enumerate(instruments.instruments[:3]):  # –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 3\n                print(f\"\\n–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {i+1}:\")\n                print(f\"  –¢–∏–∫–µ—Ä: {instrument.ticker}\")\n                print(f\"  –ù–∞–∑–≤–∞–Ω–∏–µ: {instrument.name}\")\n                print(f\"  FIGI: {instrument.figi}\")\n                print(f\"  State: {instrument.state}\")\n                print(f\"  Status: {InstrumentStatus(instrument.state).name}\")\n                \n                # –ü–æ–∫–∞–∂–µ–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã –æ–±—ä–µ–∫—Ç–∞\n                print(f\"  –í—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã: {[attr for attr in dir(instrument) if not attr.startswith('_')]}\")\n                \n    except Exception as e:\n        print(f\"‚ùå –û—à–∏–±–∫–∞: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 1484,
      "encoding": "utf-8"
    },
    ".env.example": {
      "content": "# –ü—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤ .env –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è\nLOG_LEVEL=INFO\nLOG_FILE=logs/trading_bot.log\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏ (MOEX)\nMOEX_TIMEOUT=30\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫—Ä–∏–ø—Ç–æ–±–∏—Ä–∂ (–ø–æ–∫–∞ –æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º–∏)\nBINANCE_API_KEY=your_binance_api_key_here\nBINANCE_SECRET_KEY=your_binance_secret_here\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∏—Å–∫–æ–≤\nMAX_POSITION_SIZE=100000\nMAX_DRAWDOWN=0.05\n",
      "size": 399,
      "encoding": "utf-8"
    },
    "main.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª trading –±–æ—Ç–∞\n\"\"\"\n\nimport sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\n\nfrom utils.logger import log\nfrom data_feed.moex_client import MOEXClient\n\ndef main():\n    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è\"\"\"\n    log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º trading –±–æ—Ç...\")\n    \n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n    client = MOEXClient()\n    \n    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ SBER\n    sber_info = client.get_security_info(\"SBER\")\n    if sber_info:\n        log.info(\"‚úÖ MOEX API —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n    \n    log.info(\"üéØ Trading –±–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 625,
      "encoding": "utf-8"
    },
    "project_export_20251119_152100.json": {
      "content": "{\n  \"export_date\": \"2025-11-19T15:21:00.554349\",\n  \"project_name\": \"Python Trading Bot\",\n  \"files\": {\n    \"working_requirements.txt\": {\n      \"content\": \"pandas>=2.0.0\\nnumpy>=1.24.0\\nrequests>=2.28.0\\nccxt>=4.0.0\\npython-binance>=1.0.19\\naiohttp>=3.8.0\\nwebsocket-client>=1.5.0\\nbacktrader>=1.9.78\\nloguru>=0.7.0\\npython-dotenv>=1.0.0\\npydantic>=2.0.0\\nscipy>=1.10.0\\nscikit-learn>=1.2.0\\nmatplotlib>=3.7.0\\nplotly>=5.13.0\\nseaborn>=0.12.0\\n\",\n      \"size\": 272,\n      \"encoding\": \"utf-8\"\n    },\n    \"test_setup.py\": {\n      \"content\": \"print(\\\"üéâ –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!\\\")\\nprint(\\\"–í—ã –≤ –ø–∞–ø–∫–µ:\\\", __file__)\\n\\nimport sys\\nprint(\\\"Python –ø—É—Ç—å:\\\", sys.executable)\\n\\n# –ü—Ä–æ–≤–µ—Ä–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\\ntry:\\n    import pandas as pd\\n    print(\\\"‚úÖ pandas —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\\\")\\nexcept ImportError:\\n    print(\\\"‚ùå pandas –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\\\")\\n\\ntry:\\n    import numpy as np\\n    print(\\\"‚úÖ numpy —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\\\") \\nexcept ImportError:\\n    print(\\\"‚ùå numpy –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\\\")\\n\",\n      \"size\": 391,\n      \"encoding\": \"utf-8\"\n    },\n    \"debug_imports.py\": {\n      \"content\": \"import sys\\nimport os\\n\\nprint(\\\"üîß Debug –ø—É—Ç–µ–π Python:\\\")\\nprint(f\\\"–¢–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞: {os.getcwd()}\\\")\\nprint(f\\\"–ü—É—Ç–∏ Python:\\\")\\nfor path in sys.path:\\n    print(f\\\"  - {path}\\\")\\n\\nprint(f\\\"\\\\nüìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ src/utils/:\\\")\\ntry:\\n    print(os.listdir(\\\"src/utils\\\"))\\nexcept Exception as e:\\n    print(f\\\"–û—à–∏–±–∫–∞: {e}\\\")\\n\\nprint(f\\\"\\\\nüìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ src/data_feed/:\\\")\\ntry:\\n    print(os.listdir(\\\"src/data_feed\\\"))\\nexcept Exception as e:\\n    print(f\\\"–û—à–∏–±–∫–∞: {e}\\\")\\n\\n# –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç\\nprint(f\\\"\\\\nüîÑ –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç...\\\")\\ntry:\\n    import importlib.util\\n    spec = importlib.util.spec_from_file_location(\\\"logger\\\", \\\"src/utils/logger.py\\\")\\n    logger_module = importlib.util.module_from_spec(spec)\\n    spec.loader.exec_module(logger_module)\\n    print(\\\"‚úÖ –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç logger.py - –£–°–ü–ï–•\\\")\\nexcept Exception as e:\\n    print(f\\\"‚ùå –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç logger.py: {e}\\\")\\n\",\n      \"size\": 802,\n      \"encoding\": \"utf-8\"\n    },\n    \"test_debug.py\": {\n      \"content\": \"import os\\nfrom dotenv import load_dotenv\\nload_dotenv()\\n\\nfrom tinkoff.invest import Client\\n\\ntoken = os.getenv('INVEST_TOKEN')\\nwith Client(token) as client:\\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–∑–æ–≤–∞\\n    from tinkoff.invest.schemas import GetOrderBookRequest\\n    \\n    # –í–∞—Ä–∏–∞–Ω—Ç 1\\n    try:\\n        request = GetOrderBookRequest(figi=\\\"BBG004730N88\\\", depth=5)\\n        result = client.market_data.get_order_book(request)\\n        print(\\\"‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 1 —Å GetOrderBookRequest —Ä–∞–±–æ—Ç–∞–µ—Ç\\\")\\n    except Exception as e:\\n        print(f\\\"‚ùå –í–∞—Ä–∏–∞–Ω—Ç 1: {e}\\\")\\n    \\n    # –í–∞—Ä–∏–∞–Ω—Ç 2  \\n    try:\\n        result = client.market_data.get_order_book(figi=\\\"BBG004730N88\\\", depth=5)\\n        print(\\\"‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 2 —Å –ø—Ä—è–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç\\\")\\n    except Exception as e:\\n        print(f\\\"‚ùå –í–∞—Ä–∏–∞–Ω—Ç 2: {e}\\\")\\n\\n\",\n      \"size\": 769,\n      \"encoding\": \"utf-8\"\n    },\n    \"requirements.txt\": {\n      \"content\": \"pandas>=2.0.0\\nnumpy>=1.24.0\\nrequests>=2.28.0\\nccxt>=4.0.0\\nmoexalex>=0.7.0\\nbacktrader>=1.9.78\\nloguru>=0.7.0\\npython-dotenv>=1.0.0\\ntinkoff-invest>=2.1.0\\n\",\n      \"size\": 149,\n      \"encoding\": \"utf-8\"\n    },\n    \"test_orderbook.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç —Å—Ç–∞–∫–∞–Ω–∞ - –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞\\n\\\"\\\"\\\"\\n\\nimport sys\\nimport os\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\\n\\nfrom data_feed.orderbook import MOEXOrderbook\\n\\ndef main():\\n    print(\\\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞–∫–∞–Ω...\\\")\\n    \\n    client = MOEXOrderbook()\\n    \\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER (–æ–Ω –≤—Å–µ–≥–¥–∞ —Ç–æ—Ä–≥—É–µ—Ç—Å—è)\\n    print(\\\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω SBER...\\\")\\n    client.print_pretty_orderbook(\\\"SBER\\\")\\n    \\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ GAZP\\n    print(\\\"\\\\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω GAZP...\\\")\\n    client.print_pretty_orderbook(\\\"GAZP\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 624,\n      \"encoding\": \"utf-8\"\n    },\n    \"check_install.py\": {\n      \"content\": \"print(\\\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É –æ—Å–Ω–æ–≤–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫...\\\")\\n\\nlibs_to_check = [\\n    \\\"pandas\\\", \\\"numpy\\\", \\\"requests\\\", \\\"ccxt\\\", \\n    \\\"moexalex\\\", \\\"backtrader\\\", \\\"loguru\\\", \\\"python-dotenv\\\"\\n]\\n\\nfor lib in libs_to_check:\\n    try:\\n        __import__(lib)\\n        print(f\\\"‚úÖ {lib}\\\")\\n    except ImportError as e:\\n        print(f\\\"‚ùå {lib}: {e}\\\")\\n\\nprint(\\\"\\\\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–π:\\\")\\nimport pandas as pd\\nimport numpy as np\\nimport ccxt\\n\\nprint(f\\\"Pandas: {pd.__version__}\\\")\\nprint(f\\\"Numpy: {np.__version__}\\\")\\nprint(f\\\"CCXT: {ccxt.__version__}\\\")\\n\\nprint(\\\"\\\\nüéØ –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\\\")\\n\",\n      \"size\": 549,\n      \"encoding\": \"utf-8\"\n    },\n    \"check_project_structure.py\": {\n      \"content\": \"import os\\nimport sys\\n\\ndef check_structure():\\n    print(\\\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞...\\\")\\n    \\n    # –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\\n    expected_dirs = [\\n        'src',\\n        'src/data_feed', \\n        'src/strategies',\\n        'src/execution',\\n        'src/risk_management',\\n        'src/utils',\\n        'tests',\\n        'config',\\n        'notebooks',\\n        'scripts',\\n        'data',\\n        'logs'\\n    ]\\n    \\n    expected_files = [\\n        'src/__init__.py',\\n        'src/data_feed/__init__.py',\\n        'src/strategies/__init__.py', \\n        'src/execution/__init__.py',\\n        'src/risk_management/__init__.py',\\n        'src/utils/__init__.py',\\n        'tests/__init__.py',\\n        'requirements.txt',\\n        '.env'\\n    ]\\n    \\n    missing_dirs = []\\n    missing_files = []\\n    \\n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫–∏\\n    for dir_path in expected_dirs:\\n        if not os.path.exists(dir_path):\\n            missing_dirs.append(dir_path)\\n        else:\\n            print(f\\\"‚úÖ –ü–∞–ø–∫–∞: {dir_path}\\\")\\n    \\n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã\\n    for file_path in expected_files:\\n        if not os.path.exists(file_path):\\n            missing_files.append(file_path)\\n        else:\\n            print(f\\\"‚úÖ –§–∞–π–ª: {file_path}\\\")\\n    \\n    # –í—ã–≤–æ–¥–∏–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã\\n    if missing_dirs:\\n        print(\\\"\\\\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞–ø–∫–∏:\\\")\\n        for dir_path in missing_dirs:\\n            print(f\\\"   - {dir_path}\\\")\\n    \\n    if missing_files:\\n        print(\\\"\\\\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã:\\\")\\n        for file_path in missing_files:\\n            print(f\\\"   - {file_path}\\\")\\n    \\n    if not missing_dirs and not missing_files:\\n        print(\\\"\\\\nüéâ –í—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞!\\\")\\n    else:\\n        print(f\\\"\\\\nüìù –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å: {len(missing_dirs)} –ø–∞–ø–æ–∫, {len(missing_files)} —Ñ–∞–π–ª–æ–≤\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    check_structure()\\n\",\n      \"size\": 1790,\n      \"encoding\": \"utf-8\"\n    },\n    \"moex_direct.py\": {\n      \"content\": \"import requests\\nimport pandas as pd\\nfrom loguru import logger\\n\\nclass MOEXClient:\\n    def __init__(self):\\n        self.base_url = \\\"https://iss.moex.com/iss\\\"\\n        self.session = requests.Session()\\n        logger.info(\\\"MOEX –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\\\")\\n    \\n    def get_security_info(self, ticker):\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É–º–∞–≥–µ\\\"\\\"\\\"\\n        url = f\\\"{self.base_url}/securities/{ticker}.json\\\"\\n        try:\\n            response = self.session.get(url)\\n            response.raise_for_status()\\n            data = response.json()\\n            logger.info(f\\\"–î–∞–Ω–Ω—ã–µ –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω—ã\\\")\\n            return data\\n        except Exception as e:\\n            logger.error(f\\\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ {ticker}: {e}\\\")\\n            return None\\n    \\n    def get_current_price(self, ticker):\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É (—É–ø—Ä–æ—â—ë–Ω–Ω–æ)\\\"\\\"\\\"\\n        url = f\\\"{self.base_url}/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json\\\"\\n        try:\\n            response = self.session.get(url)\\n            data = response.json()\\n            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ü–µ–Ω—É –∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\\n            market_data = data['marketdata']['data']\\n            if market_data:\\n                last_price = market_data[0][12]  # LAST —Ü–µ–Ω–∞\\n                return last_price\\n            return None\\n        except Exception as e:\\n            logger.error(f\\\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω—ã {ticker}: {e}\\\")\\n            return None\\n\\nif __name__ == \\\"__main__\\\":\\n    client = MOEXClient()\\n    \\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ SBER\\n    sber_info = client.get_security_info(\\\"SBER\\\")\\n    if sber_info:\\n        print(\\\"‚úÖ –î–∞–Ω–Ω—ã–µ SBER –ø–æ–ª—É—á–µ–Ω—ã\\\")\\n    \\n    sber_price = client.get_current_price(\\\"SBER\\\")\\n    if sber_price:\\n        print(f\\\"‚úÖ –¶–µ–Ω–∞ SBER: {sber_price}\\\")\\n\",\n      \"size\": 1723,\n      \"encoding\": \"utf-8\"\n    },\n    \"test_tinkoff.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–¢–µ—Å—Ç Tinkoff API - –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞\\n\\\"\\\"\\\"\\n\\nimport sys\\nimport os\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\\n\\nfrom data_feed.tinkoff_client import TinkoffAPIClient\\n\\ndef main():\\n    print(\\\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º Tinkoff API...\\\")\\n    \\n    try:\\n        client = TinkoffAPIClient()\\n        \\n        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER\\n        print(\\\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω SBER...\\\")\\n        client.print_pretty_orderbook(\\\"SBER\\\")\\n        \\n        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ GAZP\\n        print(\\\"\\\\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω GAZP...\\\")\\n        client.print_pretty_orderbook(\\\"GAZP\\\")\\n        \\n    except Exception as e:\\n        print(f\\\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\\\")\\n        print(\\\"‚ÑπÔ∏è  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\\\")\\n        print(\\\"   - –¢–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\\\")\\n        print(\\\"   - –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É\\\")\\n        print(\\\"   - –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–æ–∫–µ–Ω–∞\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 908,\n      \"encoding\": \"utf-8\"\n    },\n    \"debug_installation.py\": {\n      \"content\": \"import sys\\nprint(\\\"Python –ø—É—Ç—å:\\\", sys.executable)\\nprint(\\\"–í–µ—Ä—Å–∏—è Python:\\\", sys.version)\\n\\ntry:\\n    import pip\\n    installed_packages = [p.key for p in pip.get_installed_distributions()]\\n    print(\\\"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ 'tinkoff':\\\", \\n          [p for p in installed_packages if 'tinkoff' in p])\\nexcept:\\n    pass\\n\\n# –ü—Ä–æ–≤–µ—Ä–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏\\nimport pkgutil\\nall_modules = [name for importer, name, ispkg in pkgutil.iter_modules()]\\nprint(\\\"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏:\\\", [m for m in all_modules if 'tinkoff' in m or 'invest' in m])\\n\",\n      \"size\": 523,\n      \"encoding\": \"utf-8\"\n    },\n    \".gitignore\": {\n      \"content\": \"# Virtual environment\\ntrading_env/\\n\\n# Environment variables\\n.env\\n.env.local\\n\\n# Python\\n__pycache__/\\n*.py[cod]\\n*$py.class\\n*.so\\n.Python\\nbuild/\\ndevelop-eggs/\\ndist/\\ndownloads/\\neggs/\\n.eggs/\\nlib/\\nlib64/\\nparts/\\nsdist/\\nvar/\\nwheels/\\n*.egg-info/\\n.installed.cfg\\n*.egg\\n\\n# Logs\\n*.log\\nlogs/\\n\\n# IDE\\n.vscode/\\n.idea/\\n*.swp\\n*.swo\\n\\n# Data files\\n*.csv\\n*.json\\n*.pkl\\n*.feather\\n*.parquet\\ndata/\\n\\n# Jupyter\\n.ipynb_checkpoints\\n\\n# OS\\n.DS_Store\\nThumbs.db\\n\",\n      \"size\": 426,\n      \"encoding\": \"utf-8\"\n    },\n    \".env\": {\n      \"content\": \"# Tinkoff Invest API\\nINVEST_TOKEN=–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω\\n\\n# –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (sandbox –∏–ª–∏ real)\\nSANDBOX=true\\n\\n# –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å account_id, –µ—Å–ª–∏ –∑–Ω–∞–µ—Ç–µ\\n# ACCOUNT_ID=your_account_id\\n\",\n      \"size\": 171,\n      \"encoding\": \"utf-8\"\n    },\n    \"test_tinkoff_simple.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç Tinkoff API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\\n\\\"\\\"\\\"\\n\\nimport os\\nimport sys\\nfrom dotenv import load_dotenv\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\\n\\nload_dotenv()\\n\\ndef main():\\n    print(\\\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Tinkoff API...\\\")\\n    \\n    token = os.getenv('INVEST_TOKEN')\\n    if not token:\\n        print(\\\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\\\")\\n        return\\n    \\n    try:\\n        from tinkoff.invest import Client\\n        \\n        with Client(token) as client:\\n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—á–µ—Ç–∞\\n            accounts = client.users.get_accounts()\\n            print(\\\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!\\\")\\n            print(f\\\"üìã –ù–∞–π–¥–µ–Ω–æ —Å—á–µ—Ç–æ–≤: {len(accounts.accounts)}\\\")\\n            \\n            for account in accounts.accounts:\\n                print(f\\\"   - {account.name} (ID: {account.id})\\\")\\n                \\n    except Exception as e:\\n        print(f\\\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 983,\n      \"encoding\": \"utf-8\"\n    },\n    \"test_instruments.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤\\n\\\"\\\"\\\"\\n\\nimport os\\nimport sys\\nfrom dotenv import load_dotenv\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\\n\\nload_dotenv()\\n\\ndef main():\\n    print(\\\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...\\\")\\n    \\n    token = os.getenv('INVEST_TOKEN')\\n    if not token:\\n        print(\\\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\\\")\\n        return\\n    \\n    try:\\n        from tinkoff.invest import Client\\n        from tinkoff.invest.schemas import InstrumentStatus\\n        \\n        with Client(token) as client:\\n            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ SBER\\n            instruments = client.instruments.find_instrument(query=\\\"SBER\\\")\\n            print(f\\\"üîç –ù–∞–π–¥–µ–Ω–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ SBER: {len(instruments.instruments)}\\\")\\n            \\n            for i, instrument in enumerate(instruments.instruments[:3]):  # –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 3\\n                print(f\\\"\\\\n–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {i+1}:\\\")\\n                print(f\\\"  –¢–∏–∫–µ—Ä: {instrument.ticker}\\\")\\n                print(f\\\"  –ù–∞–∑–≤–∞–Ω–∏–µ: {instrument.name}\\\")\\n                print(f\\\"  FIGI: {instrument.figi}\\\")\\n                print(f\\\"  State: {instrument.state}\\\")\\n                print(f\\\"  Status: {InstrumentStatus(instrument.state).name}\\\")\\n                \\n                # –ü–æ–∫–∞–∂–µ–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã –æ–±—ä–µ–∫—Ç–∞\\n                print(f\\\"  –í—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã: {[attr for attr in dir(instrument) if not attr.startswith('_')]}\\\")\\n                \\n    except Exception as e:\\n        print(f\\\"‚ùå –û—à–∏–±–∫–∞: {e}\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 1484,\n      \"encoding\": \"utf-8\"\n    },\n    \".env.example\": {\n      \"content\": \"# –ü—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\\n# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤ .env –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\\n\\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è\\nLOG_LEVEL=INFO\\nLOG_FILE=logs/trading_bot.log\\n\\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏ (MOEX)\\nMOEX_TIMEOUT=30\\n\\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫—Ä–∏–ø—Ç–æ–±–∏—Ä–∂ (–ø–æ–∫–∞ –æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º–∏)\\nBINANCE_API_KEY=your_binance_api_key_here\\nBINANCE_SECRET_KEY=your_binance_secret_here\\n\\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∏—Å–∫–æ–≤\\nMAX_POSITION_SIZE=100000\\nMAX_DRAWDOWN=0.05\\n\",\n      \"size\": 399,\n      \"encoding\": \"utf-8\"\n    },\n    \"main.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª trading –±–æ—Ç–∞\\n\\\"\\\"\\\"\\n\\nimport sys\\nimport os\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\\n\\nfrom utils.logger import log\\nfrom data_feed.moex_client import MOEXClient\\n\\ndef main():\\n    \\\"\\\"\\\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è\\\"\\\"\\\"\\n    log.info(\\\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º trading –±–æ—Ç...\\\")\\n    \\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\\n    client = MOEXClient()\\n    \\n    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ SBER\\n    sber_info = client.get_security_info(\\\"SBER\\\")\\n    if sber_info:\\n        log.info(\\\"‚úÖ MOEX API —Ä–∞–±–æ—Ç–∞–µ—Ç\\\")\\n    \\n    log.info(\\\"üéØ Trading –±–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 625,\n      \"encoding\": \"utf-8\"\n    },\n    \"test_vscode.py\": {\n      \"content\": \"import sys\\nprint(\\\"üéØ VSCode —Ç–µ—Å—Ç –∑–∞–ø—É—â–µ–Ω!\\\")\\nprint(f\\\"Python –ø—É—Ç—å: {sys.executable}\\\")\\nprint(f\\\"–í–µ—Ä—Å–∏—è Python: {sys.version}\\\")\\n\\nif \\\"trading_env\\\" in sys.executable:\\n    print(\\\"‚úÖ –†–∞–±–æ—Ç–∞–µ–º –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏!\\\")\\nelse:\\n    print(\\\"‚ùå –ù–ï –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏!\\\")\\n\\nimport os\\nprint(f\\\"üìÅ –ü—É—Ç—å: {os.getcwd()}\\\")\\n\",\n      \"size\": 300,\n      \"encoding\": \"utf-8\"\n    },\n    \"tests/test_basic.py\": {\n      \"content\": \"# test_basic.py\\nimport pandas as pd\\nimport numpy as np\\nimport requests\\nimport ccxt\\n\\nprint(\\\"‚úÖ –í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Ä–∞–±–æ—Ç–∞—é—Ç!\\\")\\n\\n# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ\\ndata = pd.DataFrame({\\n    'price': [100, 101, 102, 101, 103],\\n    'volume': [1000, 1500, 1200, 1800, 2000]\\n})\\n\\nprint(\\\"üìä –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:\\\")\\nprint(data)\\nprint(f\\\"üìà –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {data['price'].mean():.2f}\\\")\\n\\n# –ü—Ä–æ–≤–µ—Ä—è–µ–º requests\\nresponse = requests.get('https://httpbin.org/json')\\nprint(f\\\"üåê HTTP –∑–∞–ø—Ä–æ—Å: {response.status_code}\\\")\",\n      \"size\": 474,\n      \"encoding\": \"utf-8\"\n    },\n    \"tests/final_structure_test.py\": {\n      \"content\": \"import sys\\nimport os\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))\\n\\ndef test_imports():\\n    \\\"\\\"\\\"–¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à–∏ –º–æ–¥—É–ª–∏\\\"\\\"\\\"\\n    print(\\\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã...\\\")\\n    \\n    try:\\n        from src.utils.logger import log\\n        print(\\\"‚úÖ src.utils.logger - –û–ö\\\")\\n    except ImportError as e:\\n        print(f\\\"‚ùå src.utils.logger: {e}\\\")\\n    \\n    try:\\n        from src.data_feed.moex_client import MOEXClient\\n        print(\\\"‚úÖ src.data_feed.moex_client - –û–ö\\\")\\n    except ImportError as e:\\n        print(f\\\"‚ùå src.data_feed.moex_client: {e}\\\")\\n    \\n    try:\\n        import pandas as pd\\n        print(\\\"‚úÖ pandas - –û–ö\\\")\\n    except ImportError as e:\\n        print(f\\\"‚ùå pandas: {e}\\\")\\n    \\n    print(\\\"\\\\nüéØ –¢–µ—Å—Ç –∏–º–ø–æ—Ä—Ç–æ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    test_imports()\\n\",\n      \"size\": 827,\n      \"encoding\": \"utf-8\"\n    },\n    \"tests/__init__.py\": {\n      \"content\": \"\",\n      \"size\": 0,\n      \"encoding\": \"utf-8\"\n    },\n    \"scripts/hhru_data_export_v2.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö HeadHunter (HHRU) - –ø–µ—Ä–∏–æ–¥ —Å 26.09.2024\\n\\\"\\\"\\\"\\n\\nimport os\\nimport sys\\nimport csv\\nfrom datetime import datetime, timedelta\\nfrom dotenv import load_dotenv\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\\n\\nload_dotenv()\\n\\nfrom tinkoff.invest import Client, CandleInterval\\nfrom tinkoff.invest.utils import now\\nfrom utils.logger import log\\n\\nclass HHDataExporter:\\n    def __init__(self):\\n        self.token = os.getenv('INVEST_TOKEN')\\n        if not self.token:\\n            log.error(\\\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\\\")\\n            raise ValueError(\\\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\\\")\\n        log.info(\\\"HeadHunter Data Exporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\\\")\\n    \\n    def find_hhru_instrument(self):\\n        \\\"\\\"\\\"–ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter –ø–æ —Ç–∏–∫–µ—Ä—É\\\"\\\"\\\"\\n        with Client(self.token) as client:\\n            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–∏–∫–µ—Ä–æ–≤ HeadHunter\\n            tickers_to_try = [\\\"HEAD\\\"]\\n            \\n            for ticker in tickers_to_try:\\n                log.info(f\\\"üîç –ò—â–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º: {ticker}\\\")\\n                instruments = client.instruments.find_instrument(query=ticker)\\n                \\n                for instrument in instruments.instruments:\\n                    if instrument.ticker.upper() == ticker.upper():\\n                        log.info(f\\\"‚úÖ –ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker})\\\")\\n                        log.info(f\\\"   FIGI: {instrument.figi}\\\")\\n                        log.info(f\\\"   –¢–∏–ø: {instrument.instrument_type}\\\")\\n                        return instrument\\n            \\n            log.error(\\\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter\\\")\\n            return None\\n    \\n    def get_historical_candles(self, figi, from_date, to_date):\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥\\\"\\\"\\\"\\n        candles_data = []\\n        \\n        with Client(self.token) as client:\\n            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –ø–æ –¥–Ω—è–º\\n            response = client.market_data.get_candles(\\n                figi=figi,\\n                from_=from_date,\\n                to=to_date,\\n                interval=CandleInterval.CANDLE_INTERVAL_DAY\\n            )\\n            \\n            for candle in response.candles:\\n                candles_data.append({\\n                    'time': candle.time.strftime('%Y-%m-%d %H:%M:%S'),\\n                    'open': self.quotation_to_float(candle.open),\\n                    'high': self.quotation_to_float(candle.high),\\n                    'low': self.quotation_to_float(candle.low),\\n                    'close': self.quotation_to_float(candle.close),\\n                    'volume': candle.volume,\\n                    'is_complete': candle.is_complete\\n                })\\n            \\n            log.info(f\\\"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(candles_data)} —Å–≤–µ—á–µ–π\\\")\\n            return candles_data\\n    \\n    def quotation_to_float(self, quotation):\\n        \\\"\\\"\\\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float\\\"\\\"\\\"\\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\\n            return quotation.units + quotation.nano / 1e9\\n        return float(quotation) if quotation else 0.0\\n    \\n    def export_to_csv(self, candles_data, output_path):\\n        \\\"\\\"\\\"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV\\\"\\\"\\\"\\n        if not candles_data:\\n            log.error(\\\"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞\\\")\\n            return False\\n        \\n        try:\\n            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\\n                fieldnames = ['time', 'open', 'high', 'low', 'close', 'volume', 'is_complete']\\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\\n                \\n                writer.writeheader()\\n                for candle in candles_data:\\n                    writer.writerow(candle)\\n            \\n            log.info(f\\\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}\\\")\\n            return True\\n            \\n        except Exception as e:\\n            log.error(f\\\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}\\\")\\n            return False\\n    \\n    def run_export(self):\\n        \\\"\\\"\\\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞\\\"\\\"\\\"\\n        log.info(\\\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö HeadHunter...\\\")\\n        \\n        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç\\n        instrument = self.find_hhru_instrument()\\n        if not instrument:\\n            return False\\n        \\n        # –ù–û–í–´–ô –ü–ï–†–ò–û–î: —Å 26.09.2024 –ø–æ 16.11.2025\\n        from_date = datetime(2024, 9, 26)\\n        to_date = datetime(2025, 11, 16)\\n        \\n        log.info(f\\\"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {from_date.strftime('%d.%m.%Y')} - {to_date.strftime('%d.%m.%Y')}\\\")\\n        \\n        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\\n        candles_data = self.get_historical_candles(\\n            instrument.figi, \\n            from_date, \\n            to_date\\n        )\\n        \\n        if not candles_data:\\n            log.error(\\\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\\\")\\n            return False\\n        \\n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª —Å –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ú –∏–º–µ–Ω–µ–º\\n        desktop_path = os.path.join(os.path.expanduser(\\\"~\\\"), \\\"Desktop\\\")\\n        # –•–ê–†–î–ö–û–î–ò–ú –∏–º—è —Ñ–∞–π–ª–∞\\n        output_filename = \\\"headhunter_data_sep2024_nov2025.csv\\\"\\n        output_path = os.path.join(desktop_path, output_filename)\\n        \\n        success = self.export_to_csv(candles_data, output_path)\\n        \\n        if success:\\n            log.info(\\\"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\\\")\\n            print(f\\\"\\\\nüìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}\\\")\\n            print(f\\\"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(candles_data)}\\\")\\n            print(f\\\"üìÖ –ü–µ—Ä–∏–æ–¥: 26.09.2024 - 16.11.2025\\\")\\n        \\n        return success\\n\\ndef main():\\n    \\\"\\\"\\\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞\\\"\\\"\\\"\\n    try:\\n        exporter = HHDataExporter()\\n        exporter.run_export()\\n        \\n    except Exception as e:\\n        log.error(f\\\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\\\")\\n        print(\\\"\\\\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:\\\")\\n        print(\\\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\\\")\\n        print(\\\"   - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ç–æ—Ä–≥–∏ –ø–æ HHRU –∏–¥—É—Ç\\\")\\n        print(\\\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 5866,\n      \"encoding\": \"utf-8\"\n    },\n    \"scripts/scanner_gazp.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–°–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–∞ –ø–æ –ì–∞–∑–ø—Ä–æ–º—É\\n–ó–∞–ø—É—Å–∫: python scripts/scanner_gazp.py\\n\\\"\\\"\\\"\\n\\nimport sys\\nimport os\\nimport time\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\\n\\nfrom data_feed.orderbook import MOEXOrderbook\\nfrom utils.logger import log\\n\\ndef main():\\n    \\\"\\\"\\\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–Ω–µ—Ä–∞\\\"\\\"\\\"\\n    log.info(\\\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–∞...\\\")\\n    \\n    client = MOEXOrderbook()\\n    \\n    # –°–Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER (–æ–Ω –≤—Å–µ–≥–¥–∞ —Ç–æ—Ä–≥—É–µ—Ç—Å—è)\\n    log.info(\\\"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ SBER...\\\")\\n    test_orderbook = client.get_orderbook(\\\"SBER\\\")\\n    if test_orderbook and ('bids' in test_orderbook or 'asks' in test_orderbook):\\n        log.info(\\\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MOEX —Ä–∞–±–æ—Ç–∞–µ—Ç\\\")\\n    else:\\n        log.error(\\\"‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ MOEX\\\")\\n        return\\n    \\n    try:\\n        while True:\\n            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Å–æ–ª—å\\n            os.system('clear' if os.name == 'posix' else 'cls')\\n            \\n            print(\\\"üéØ –°–ö–†–ò–ù–ï–† –°–¢–ê–ö–ê–ù–ê - –ì–ê–ó–ü–†–û–ú (GAZP)\\\")\\n            print(\\\"–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\\\\n\\\")\\n            \\n            # –ü–æ–ª—É—á–∞–µ–º –∏ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω\\n            client.print_pretty_orderbook(\\\"GAZP\\\")\\n            \\n            # –ñ–¥—ë–º 5 —Å–µ–∫—É–Ω–¥ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\\n            print(\\\"\\\\nüîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...\\\")\\n            time.sleep(5)\\n            \\n    except KeyboardInterrupt:\\n        log.info(\\\"‚èπÔ∏è  –°–∫—Ä–∏–Ω–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\\\")\\n    except Exception as e:\\n        log.error(f\\\"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–∫—Ä–∏–Ω–µ—Ä–µ: {e}\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 1522,\n      \"encoding\": \"utf-8\"\n    },\n    \"scripts/tinkoff_scanner.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–°–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–æ–≤ –Ω–∞ Tinkoff API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\\n\\\"\\\"\\\"\\n\\nimport sys\\nimport os\\nimport time\\nfrom dotenv import load_dotenv\\n\\n# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞\\nload_dotenv()\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\\n\\nfrom data_feed.tinkoff_client_simple import TinkoffAPIClientSimple\\nfrom utils.logger import log\\n\\ndef main():\\n    \\\"\\\"\\\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–Ω–µ—Ä–∞\\\"\\\"\\\"\\n    log.info(\\\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–Ω–µ—Ä –Ω–∞ Tinkoff API (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)...\\\")\\n    \\n    try:\\n        client = TinkoffAPIClientSimple()\\n        \\n        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ\\n        test_data = client.get_orderbook(\\\"SBER\\\")\\n        if test_data:\\n            log.info(\\\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Tinkoff API —Ä–∞–±–æ—Ç–∞–µ—Ç\\\")\\n        else:\\n            log.error(\\\"‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ Tinkoff API\\\")\\n            return\\n    \\n    except Exception as e:\\n        log.error(f\\\"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}\\\")\\n        return\\n    \\n    # –°–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\\n    tickers = [\\\"SBER\\\", \\\"GAZP\\\", \\\"LKOH\\\", \\\"ROSN\\\", \\\"YNDX\\\"]\\n    \\n    try:\\n        while True:\\n            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Å–æ–ª—å\\n            os.system('clear' if os.name == 'posix' else 'cls')\\n            \\n            print(\\\"üéØ –°–ö–†–ò–ù–ï–† –°–¢–ê–ö–ê–ù–û–í - TINKOFF API (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)\\\")\\n            print(\\\"–î–ê–ù–ù–´–ï –†–ï–ê–õ–¨–ù–´–ï - –ë–£–î–¨–¢–ï –û–°–¢–û–†–û–ñ–ù–´!\\\")\\n            print(\\\"–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\\\\n\\\")\\n            \\n            for ticker in tickers:\\n                client.print_pretty_orderbook(ticker, depth=3)\\n                print()\\n            \\n            print(\\\"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥...\\\")\\n            time.sleep(10)\\n            \\n    except KeyboardInterrupt:\\n        log.info(\\\"‚èπÔ∏è  –°–∫—Ä–∏–Ω–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\\\")\\n    except Exception as e:\\n        log.error(f\\\"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–∫—Ä–∏–Ω–µ—Ä–µ: {e}\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 1798,\n      \"encoding\": \"utf-8\"\n    },\n    \"scripts/auto_ru_parser.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–ü–∞—Ä—Å–µ—Ä –¥–ª—è auto.ru - —Å–±–æ—Ä –º–∞—Ä–æ–∫ –∏ –º–æ–¥–µ–ª–µ–π –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π\\n\\\"\\\"\\\"\\n\\nimport requests\\nimport csv\\nimport time\\nimport os\\nfrom bs4 import BeautifulSoup\\nfrom urllib.parse import urljoin\\nimport sys\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –ª–æ–≥–≥–µ—Ä–∞\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\\n\\nfrom utils.logger import log\\n\\nclass AutoRuParser:\\n    def __init__(self):\\n        self.session = requests.Session()\\n        self.session.headers.update({\\n            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\\n            'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',\\n            'Accept-Encoding': 'gzip, deflate, br',\\n            'Connection': 'keep-alive',\\n            'Upgrade-Insecure-Requests': '1',\\n        })\\n        self.base_url = \\\"https://auto.ru\\\"\\n        \\n    def get_page(self, url):\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É\\\"\\\"\\\"\\n        try:\\n            log.info(f\\\"üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}\\\")\\n            response = self.session.get(url, timeout=10)\\n            response.raise_for_status()\\n            return response.text\\n        except Exception as e:\\n            log.error(f\\\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}\\\")\\n            return None\\n    \\n    def parse_brands_and_models(self, url, vehicle_type):\\n        \\\"\\\"\\\"–ü–∞—Ä—Å–∏–º –º–∞—Ä–∫–∏ –∏ –º–æ–¥–µ–ª–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã\\\"\\\"\\\"\\n        html = self.get_page(url)\\n        if not html:\\n            return []\\n        \\n        soup = BeautifulSoup(html, 'html.parser')\\n        brands_data = []\\n        \\n        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –º–∞—Ä–∫–∞–º–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ)\\n        brand_selectors = [\\n            'select[name=\\\"mark\\\"] option',\\n            '.Select[data-ga-name=\\\"mark\\\"] option',\\n            '[data-ftid=\\\"sales__filter_mark\\\"] option',\\n            'select[data-ftid=\\\"sales__filter_mark\\\"] option'\\n        ]\\n        \\n        brand_options = None\\n        for selector in brand_selectors:\\n            brand_options = soup.select(selector)\\n            if brand_options:\\n                log.info(f\\\"‚úÖ –ù–∞—à–ª–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä –º–∞—Ä–æ–∫: {selector}\\\")\\n                break\\n        \\n        if not brand_options:\\n            log.warning(f\\\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–ø–∏—Å–æ–∫ –º–∞—Ä–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {url}\\\")\\n            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–∞—Ä–∫–∏ –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º\\n            brand_links = soup.select('a[href*=\\\"/cars/\\\"]')\\n            log.info(f\\\"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –º–∞—Ä–∫–∏: {len(brand_links)}\\\")\\n            return []\\n        \\n        log.info(f\\\"üè∑Ô∏è –ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–æ–∫: {len(brand_links)}\\\")\\n        \\n        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é –º–∞—Ä–∫—É\\n        for option in brand_links:\\n            brand_name = option.get_text(strip=True)\\n            brand_value = option.get('value') or option.get('href', '')\\n            \\n            if not brand_name or brand_name in ['–õ—é–±–∞—è', '–í—Å–µ –º–∞—Ä–∫–∏', '']:\\n                continue\\n                \\n            log.info(f\\\"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Ä–∫—É: {brand_name}\\\")\\n            \\n            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è —ç—Ç–æ–π –º–∞—Ä–∫–∏\\n            models = self.get_models_for_brand(brand_name, brand_value, vehicle_type)\\n            \\n            for model_name in models:\\n                brands_data.append({\\n                    'brand': brand_name,\\n                    'model': model_name,\\n                    'vehicle_type': vehicle_type\\n                })\\n            \\n            # –ó–∞–¥–µ—Ä–∂–∫–∞ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Å–µ—Ä–≤–µ—Ä\\n            time.sleep(1)\\n        \\n        return brands_data\\n    \\n    def get_models_for_brand(self, brand_name, brand_value, vehicle_type):\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–∞—Ä–∫–∏\\\"\\\"\\\"\\n        models = []\\n        \\n        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –º–æ–¥–µ–ª—è–º–∏\\n        if 'cars' in vehicle_type.lower():\\n            model_url = f\\\"https://auto.ru/nizhniy_novgorod/cars/{brand_name.lower()}/all/\\\"\\n        else:\\n            model_url = f\\\"https://auto.ru/nizhniy_novgorod/lcv/{brand_name.lower()}/all/\\\"\\n        \\n        html = self.get_page(model_url)\\n        if not html:\\n            return models\\n        \\n        soup = BeautifulSoup(html, 'html.parser')\\n        \\n        # –ò—â–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä –º–æ–¥–µ–ª–µ–π\\n        model_selectors = [\\n            'select[name=\\\"model\\\"] option',\\n            '.Select[data-ga-name=\\\"model\\\"] option',\\n            '[data-ftid=\\\"sales__filter_model\\\"] option',\\n            'select[data-ftid=\\\"sales__filter_model\\\"] option'\\n        ]\\n        \\n        model_options = None\\n        for selector in model_selectors:\\n            model_options = soup.select(selector)\\n            if model_options:\\n                break\\n        \\n        if model_options:\\n            for option in model_options:\\n                model_name = option.get_text(strip=True)\\n                if model_name and model_name not in ['–õ—é–±–∞—è', '–í—Å–µ –º–æ–¥–µ–ª–∏', '']:\\n                    models.append(model_name)\\n        \\n        log.info(f\\\"   üöó –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è {brand_name}: {len(models)}\\\")\\n        return models\\n    \\n    def save_to_csv(self, data, filename):\\n        \\\"\\\"\\\"–°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª\\\"\\\"\\\"\\n        desktop_path = os.path.join(os.path.expanduser(\\\"~\\\"), \\\"Desktop\\\")\\n        filepath = os.path.join(desktop_path, filename)\\n        \\n        try:\\n            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\\n                fieldnames = ['brand', 'model', 'vehicle_type']\\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\\n                \\n                writer.writeheader()\\n                for row in data:\\n                    writer.writerow(row)\\n            \\n            log.info(f\\\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filepath}\\\")\\n            log.info(f\\\"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(data)}\\\")\\n            return True\\n            \\n        except Exception as e:\\n            log.error(f\\\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}\\\")\\n            return False\\n    \\n    def run_parser(self):\\n        \\\"\\\"\\\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞\\\"\\\"\\\"\\n        log.info(\\\"üöó –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä Auto.ru...\\\")\\n        \\n        all_data = []\\n        \\n        # –ü–∞—Ä—Å–∏–º –ª–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\\n        log.info(\\\"üîç –ü–∞—Ä—Å–∏–º —Ä–∞–∑–¥–µ–ª '–õ–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ'...\\\")\\n        cars_url = \\\"https://auto.ru/nizhniy_novgorod/cars/all/\\\"\\n        cars_data = self.parse_brands_and_models(cars_url, \\\"–õ–µ–≥–∫–æ–≤–æ–π\\\")\\n        all_data.extend(cars_data)\\n        \\n        # –ü–∞—Ä—Å–∏–º –ª–µ–≥–∫–∏–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\\n        log.info(\\\"üîç –ü–∞—Ä—Å–∏–º —Ä–∞–∑–¥–µ–ª '–õ—ë–≥–∫–∏–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ'...\\\")\\n        lcv_url = \\\"https://auto.ru/nizhniy_novgorod/lcv/all/\\\"\\n        lcv_data = self.parse_brands_and_models(lcv_url, \\\"–ì—Ä—É–∑–æ–≤–æ–π\\\")\\n        all_data.extend(lcv_data)\\n        \\n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\\n        if all_data:\\n            self.save_to_csv(all_data, \\\"auto_ru_brands_models.csv\\\")\\n            log.info(\\\"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\\\")\\n        else:\\n            log.error(\\\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\\\")\\n        \\n        return all_data\\n\\ndef main():\\n    \\\"\\\"\\\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞\\\"\\\"\\\"\\n    try:\\n        parser = AutoRuParser()\\n        parser.run_parser()\\n        \\n    except Exception as e:\\n        log.error(f\\\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 7071,\n      \"encoding\": \"utf-8\"\n    },\n    \"scripts/__init__.py\": {\n      \"content\": \"\",\n      \"size\": 0,\n      \"encoding\": \"utf-8\"\n    },\n    \"scripts/hhru_data_export.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö HeadHunter (HHRU)\\n\\\"\\\"\\\"\\n\\nimport os\\nimport sys\\nimport csv\\nfrom datetime import datetime, timedelta\\nfrom dotenv import load_dotenv\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\\n\\nload_dotenv()\\n\\nfrom tinkoff.invest import Client, CandleInterval\\nfrom tinkoff.invest.utils import now\\nfrom utils.logger import log\\n\\nclass HHDataExporter:\\n    def __init__(self):\\n        self.token = os.getenv('INVEST_TOKEN')\\n        if not self.token:\\n            log.error(\\\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\\\")\\n            raise ValueError(\\\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\\\")\\n        log.info(\\\"HeadHunter Data Exporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\\\")\\n    \\n    def find_hhru_instrument(self):\\n        \\\"\\\"\\\"–ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter –ø–æ —Ç–∏–∫–µ—Ä—É\\\"\\\"\\\"\\n        with Client(self.token) as client:\\n            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–∏–∫–µ—Ä–æ–≤ HeadHunter\\n            tickers_to_try = [\\\"HHRU\\\", \\\"HHRS\\\", \\\"HH\\\", \\\"HHR\\\"]\\n            \\n            for ticker in tickers_to_try:\\n                log.info(f\\\"üîç –ò—â–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º: {ticker}\\\")\\n                instruments = client.instruments.find_instrument(query=ticker)\\n                \\n                for instrument in instruments.instruments:\\n                    if instrument.ticker.upper() == ticker.upper():\\n                        log.info(f\\\"‚úÖ –ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker})\\\")\\n                        log.info(f\\\"   FIGI: {instrument.figi}\\\")\\n                        log.info(f\\\"   –¢–∏–ø: {instrument.instrument_type}\\\")\\n                        return instrument\\n            \\n            log.error(\\\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter\\\")\\n            return None\\n    \\n    def get_historical_candles(self, figi, from_date, to_date):\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥\\\"\\\"\\\"\\n        candles_data = []\\n        \\n        with Client(self.token) as client:\\n            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –ø–æ –¥–Ω—è–º\\n            response = client.market_data.get_candles(\\n                figi=figi,\\n                from_=from_date,\\n                to=to_date,\\n                interval=CandleInterval.CANDLE_INTERVAL_DAY\\n            )\\n            \\n            for candle in response.candles:\\n                candles_data.append({\\n                    'time': candle.time.strftime('%Y-%m-%d %H:%M:%S'),\\n                    'open': self.quotation_to_float(candle.open),\\n                    'high': self.quotation_to_float(candle.high),\\n                    'low': self.quotation_to_float(candle.low),\\n                    'close': self.quotation_to_float(candle.close),\\n                    'volume': candle.volume,\\n                    'is_complete': candle.is_complete\\n                })\\n            \\n            log.info(f\\\"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(candles_data)} —Å–≤–µ—á–µ–π\\\")\\n            return candles_data\\n    \\n    def quotation_to_float(self, quotation):\\n        \\\"\\\"\\\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float\\\"\\\"\\\"\\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\\n            return quotation.units + quotation.nano / 1e9\\n        return float(quotation) if quotation else 0.0\\n    \\n    def export_to_csv(self, candles_data, output_path):\\n        \\\"\\\"\\\"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV\\\"\\\"\\\"\\n        if not candles_data:\\n            log.error(\\\"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞\\\")\\n            return False\\n        \\n        try:\\n            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\\n                fieldnames = ['time', 'open', 'high', 'low', 'close', 'volume', 'is_complete']\\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\\n                \\n                writer.writeheader()\\n                for candle in candles_data:\\n                    writer.writerow(candle)\\n            \\n            log.info(f\\\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}\\\")\\n            return True\\n            \\n        except Exception as e:\\n            log.error(f\\\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}\\\")\\n            return False\\n    \\n    def run_export(self):\\n        \\\"\\\"\\\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞\\\"\\\"\\\"\\n        log.info(\\\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö HeadHunter...\\\")\\n        \\n        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç\\n        instrument = self.find_hhru_instrument()\\n        if not instrument:\\n            return False\\n        \\n        # –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö\\n        from_date = datetime(2024, 1, 1)\\n        to_date = datetime(2025, 11, 16)\\n        \\n        log.info(f\\\"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {from_date.strftime('%d.%m.%Y')} - {to_date.strftime('%d.%m.%Y')}\\\")\\n        \\n        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\\n        candles_data = self.get_historical_candles(\\n            instrument.figi, \\n            from_date, \\n            to_date\\n        )\\n        \\n        if not candles_data:\\n            log.error(\\\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\\\")\\n            return False\\n        \\n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\n        desktop_path = os.path.join(os.path.expanduser(\\\"~\\\"), \\\"Desktop\\\")\\n        output_filename = f\\\"headhunter_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\\\"\\n        output_path = os.path.join(desktop_path, output_filename)\\n        \\n        success = self.export_to_csv(candles_data, output_path)\\n        \\n        if success:\\n            log.info(\\\"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\\\")\\n            print(f\\\"\\\\nüìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}\\\")\\n            print(f\\\"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(candles_data)}\\\")\\n        \\n        return success\\n\\ndef main():\\n    \\\"\\\"\\\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞\\\"\\\"\\\"\\n    try:\\n        exporter = HHDataExporter()\\n        exporter.run_export()\\n        \\n    except Exception as e:\\n        log.error(f\\\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\\\")\\n        print(\\\"\\\\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:\\\")\\n        print(\\\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\\\")\\n        print(\\\"   - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ç–æ—Ä–≥–∏ –ø–æ HHRU –∏–¥—É—Ç\\\")\\n        print(\\\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 5756,\n      \"encoding\": \"utf-8\"\n    },\n    \"scripts/auto_ru_parser_simple.py\": {\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\n–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è auto.ru\\n\\\"\\\"\\\"\\n\\nimport requests\\nimport csv\\nimport os\\nimport sys\\nimport json\\nimport time\\n\\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\\n\\nfrom utils.logger import log\\n\\nclass SimpleAutoRuParser:\\n    def __init__(self):\\n        self.session = requests.Session()\\n        self.session.headers.update({\\n            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',\\n            'Accept': 'application/json, text/plain, */*',\\n        })\\n    \\n    def get_api_data(self, category):\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API auto.ru\\\"\\\"\\\"\\n        url = f\\\"https://auto.ru/-/ajax/desktop/listing/\\\"\\n        params = {\\n            'section': 'all',\\n            'category': category,\\n            'sort': 'fresh_relevance_1-desc'\\n        }\\n        \\n        try:\\n            log.info(f\\\"üîß –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ API –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category}\\\")\\n            response = self.session.get(url, params=params, timeout=10)\\n            response.raise_for_status()\\n            \\n            data = response.json()\\n            return data\\n            \\n        except Exception as e:\\n            log.error(f\\\"‚ùå –û—à–∏–±–∫–∞ API –¥–ª—è {category}: {e}\\\")\\n            return None\\n    \\n    def extract_brands_from_api(self, api_data, vehicle_type):\\n        \\\"\\\"\\\"–ò–∑–≤–ª–µ–∫–∞–µ–º –±—Ä–µ–Ω–¥—ã –∏–∑ API –¥–∞–Ω–Ω—ã—Ö\\\"\\\"\\\"\\n        brands_data = []\\n        \\n        if not api_data or 'state' not in api_data:\\n            return brands_data\\n        \\n        state = api_data['state']\\n        \\n        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –æ –±—Ä–µ–Ω–¥–∞—Ö\\n        possible_paths = [\\n            state.get('listing', {}).get('data', {}).get('filters', {}).get('mark', []),\\n            state.get('filters', {}).get('mark', []),\\n            state.get('mark', [])\\n        ]\\n        \\n        marks = []\\n        for path in possible_paths:\\n            if path and isinstance(path, list) and len(path) > 0:\\n                marks = path\\n                break\\n        \\n        log.info(f\\\"üè∑Ô∏è –ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–æ–∫ –≤ API: {len(marks)}\\\")\\n        \\n        for mark in marks:\\n            if isinstance(mark, dict):\\n                brand_name = mark.get('name', mark.get('title', ''))\\n                if brand_name and brand_name not in ['–õ—é–±–∞—è', '–í—Å–µ –º–∞—Ä–∫–∏']:\\n                    # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫—É –±–µ–∑ –º–æ–¥–µ–ª–µ–π\\n                    brands_data.append({\\n                        'brand': brand_name,\\n                        'model': '–í—Å–µ –º–æ–¥–µ–ª–∏',\\n                        'vehicle_type': vehicle_type\\n                    })\\n        \\n        return brands_data\\n    \\n    def run_parser(self):\\n        \\\"\\\"\\\"–ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä\\\"\\\"\\\"\\n        log.info(\\\"üöó –ó–∞–ø—É—Å–∫–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä Auto.ru...\\\")\\n        \\n        all_data = []\\n        \\n        # –õ–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\\n        cars_data = self.get_api_data('cars')\\n        if cars_data:\\n            cars_brands = self.extract_brands_from_api(cars_data, \\\"–õ–µ–≥–∫–æ–≤–æ–π\\\")\\n            all_data.extend(cars_brands)\\n        \\n        time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏\\n        \\n        # –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\\n        lcv_data = self.get_api_data('lcv')\\n        if lcv_data:\\n            lcv_brands = self.extract_brands_from_api(lcv_data, \\\"–ì—Ä—É–∑–æ–≤–æ–π\\\")\\n            all_data.extend(lcv_brands)\\n        \\n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV\\n        if all_data:\\n            desktop_path = os.path.join(os.path.expanduser(\\\"~\\\"), \\\"Desktop\\\")\\n            filepath = os.path.join(desktop_path, \\\"auto_ru_brands_simple.csv\\\")\\n            \\n            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\\n                writer = csv.DictWriter(csvfile, fieldnames=['brand', 'model', 'vehicle_type'])\\n                writer.writeheader()\\n                writer.writerows(all_data)\\n            \\n            log.info(f\\\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filepath}\\\")\\n            log.info(f\\\"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(all_data)}\\\")\\n        else:\\n            log.error(\\\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\\\")\\n        \\n        return all_data\\n\\ndef main():\\n    try:\\n        parser = SimpleAutoRuParser()\\n        parser.run_parser()\\n    except Exception as e:\\n        log.error(f\\\"‚ùå –û—à–∏–±–∫–∞: {e}\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n      \"size\": 4113,\n      \"encoding\": \"utf-8\"\n    },\n    \".vscode/settings.json\": {\n      \"content\": \"{\\n    \\\"python.defaultInterpreterPath\\\": \\\"${workspaceFolder}/trading_env/bin/python\\\",\\n    \\\"python.terminal.activateEnvironment\\\": true,\\n    \\\"python.linting.enabled\\\": true,\\n    \\\"python.formatting.provider\\\": \\\"black\\\",\\n    \\\"python.formatting.blackArgs\\\": [\\\"--line-length\\\", \\\"100\\\"],\\n    \\\"editor.formatOnSave\\\": true,\\n    \\\"editor.codeActionsOnSave\\\": {\\n        \\\"source.organizeImports\\\": \\\"explicit\\\"\\n    },\\n    \\\"python.analysis.extraPaths\\\": [\\\"./src\\\"],\\n    \\\"files.autoSave\\\": \\\"onFocusChange\\\",\\n    \\\"terminal.integrated.shellArgs.osx\\\": [\\\"-l\\\"],\\n    \\\"[python]\\\": {\\n        \\\"editor.defaultFormatter\\\": \\\"ms-python.python\\\"\\n    }\\n}\\n\",\n      \"size\": 605,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/__init__.py\": {\n      \"content\": \"\",\n      \"size\": 0,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/strategies/__init__.py\": {\n      \"content\": \"\",\n      \"size\": 0,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/utils/__init__.py\": {\n      \"content\": \"\",\n      \"size\": 0,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/utils/logger.py\": {\n      \"content\": \"from loguru import logger\\nimport sys\\nimport os\\n\\ndef setup_logger():\\n    \\\"\\\"\\\"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è trading –±–æ—Ç–∞\\\"\\\"\\\"\\n    \\n    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\\n    os.makedirs(\\\"logs\\\", exist_ok=True)\\n    \\n    # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π handler\\n    logger.remove()\\n    \\n    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π handler\\n    logger.add(\\n        sys.stdout,\\n        format=\\\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>\\\",\\n        level=\\\"INFO\\\",\\n        colorize=True\\n    )\\n    \\n    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª–æ–≤—ã–π handler\\n    logger.add(\\n        \\\"logs/trading_bot.log\\\",\\n        rotation=\\\"10 MB\\\",\\n        retention=\\\"10 days\\\",\\n        level=\\\"DEBUG\\\",\\n        format=\\\"{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}\\\"\\n    )\\n    \\n    return logger\\n\\n# –°–æ–∑–¥–∞—ë–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä\\nlog = setup_logger()\\n\\nif __name__ == \\\"__main__\\\":\\n    log.info(\\\"–õ–æ–≥–≥–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!\\\")\\n    log.debug(\\\"–û—Ç–ª–∞–¥–æ—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\\\")\\n    log.warning(\\\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ\\\")\\n\",\n      \"size\": 1049,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/risk_management/__init__.py\": {\n      \"content\": \"\",\n      \"size\": 0,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/execution/__init__.py\": {\n      \"content\": \"\",\n      \"size\": 0,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/data_feed/__init__.py\": {\n      \"content\": \"\",\n      \"size\": 0,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/data_feed/tinkoff_client_simple.py\": {\n      \"content\": \"import os\\nimport sys\\nfrom datetime import datetime\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\\nsrc_root = os.path.dirname(current_dir)\\nsys.path.insert(0, src_root)\\n\\nfrom tinkoff.invest import Client\\nfrom utils.logger import log\\n\\nclass TinkoffAPIClientSimple:\\n    def __init__(self):\\n        self.token = os.getenv('INVEST_TOKEN')\\n        if not self.token:\\n            log.error(\\\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\\\")\\n            raise ValueError(\\\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\\\")\\n        log.info(\\\"Tinkoff API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)\\\")\\n    \\n    def find_instrument_by_ticker(self, ticker):\\n        with Client(self.token) as client:\\n            instruments = client.instruments.find_instrument(query=ticker)\\n            for instrument in instruments.instruments:\\n                if instrument.ticker == ticker:\\n                    log.info(f\\\"–ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker}), FIGI: {instrument.figi}\\\")\\n                    # –£–ë–ò–†–ê–ï–ú –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã\\n                    return instrument\\n            log.error(f\\\"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º {ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω\\\")\\n            return None\\n    \\n    def get_orderbook(self, ticker: str, depth: int = 5):\\n        instrument = self.find_instrument_by_ticker(ticker)\\n        if not instrument:\\n            return None\\n            \\n        try:\\n            with Client(self.token) as client:\\n                log.info(f\\\"–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å—Ç–∞–∫–∞–Ω –¥–ª—è FIGI: {instrument.figi}, –≥–ª—É–±–∏–Ω–∞: {depth}\\\")\\n                orderbook = client.market_data.get_order_book(figi=instrument.figi, depth=depth)\\n                \\n                # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ç–∞–∫–∞–Ω–∞\\n                log.info(f\\\"–°—Ç–∞–∫–∞–Ω –ø–æ–ª—É—á–µ–Ω: {orderbook}\\\")\\n                log.info(f\\\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ bids: {len(orderbook.bids)}\\\")\\n                log.info(f\\\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ asks: {len(orderbook.asks)}\\\")\\n                \\n                return {\\n                    'ticker': ticker,\\n                    'instrument': instrument,\\n                    'orderbook': orderbook,\\n                    'timestamp': datetime.now()\\n                }\\n                \\n        except Exception as e:\\n            log.error(f\\\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}\\\")\\n            return None\\n    \\n    def print_pretty_orderbook(self, ticker: str, depth: int = 5):\\n        data = self.get_orderbook(ticker, depth)\\n        \\n        if not data:\\n            print(f\\\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}\\\")\\n            return\\n        \\n        orderbook = data['orderbook']\\n        instrument = data['instrument']\\n        \\n        print(f\\\"\\\\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker} ({instrument.name}):\\\")\\n        print(\\\"=\\\" * 60)\\n        \\n        if orderbook.asks:\\n            print(\\\"üí∞ –ü–†–û–î–ê–ñ–ò (asks):\\\")\\n            for ask in orderbook.asks:\\n                price = self.quotation_to_float(ask.price)\\n                quantity = ask.quantity\\n                print(f\\\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\\\")\\n        else:\\n            print(\\\"üí∞ –ü–†–û–î–ê–ñ–ò (asks): –ø—É—Å—Ç–æ\\\")\\n        \\n        print(\\\"-\\\" * 30)\\n        \\n        if orderbook.bids:\\n            print(\\\"üõí –ü–û–ö–£–ü–ö–ò (bids):\\\")\\n            for bid in orderbook.bids:\\n                price = self.quotation_to_float(bid.price)\\n                quantity = bid.quantity\\n                print(f\\\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\\\")\\n        else:\\n            print(\\\"üõí –ü–û–ö–£–ü–ö–ò (bids): –ø—É—Å—Ç–æ\\\")\\n        \\n        print(\\\"=\\\" * 60)\\n        if hasattr(orderbook, 'best_bid_price') and orderbook.best_bid_price:\\n            print(f\\\"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: {self.quotation_to_float(orderbook.best_bid_price):.2f}\\\")\\n        else:\\n            print(f\\\"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö\\\")\\n            \\n        if hasattr(orderbook, 'best_ask_price') and orderbook.best_ask_price:\\n            print(f\\\"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {self.quotation_to_float(orderbook.best_ask_price):.2f}\\\")\\n        else:\\n            print(f\\\"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö\\\")\\n            \\n        print(f\\\"‚è∞ –í—Ä–µ–º—è: {data['timestamp'].strftime('%H:%M:%S')}\\\")\\n    \\n    def quotation_to_float(self, quotation):\\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\\n            return quotation.units + quotation.nano / 1e9\\n        return float(quotation) if quotation else 0.0\\n\\nif __name__ == \\\"__main__\\\":\\n    client = TinkoffAPIClientSimple()\\n    client.print_pretty_orderbook(\\\"SBER\\\")\\n\",\n      \"size\": 4292,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/data_feed/orderbook.py\": {\n      \"content\": \"import requests\\nimport pandas as pd\\nimport sys\\nimport os\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils\\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\\nsrc_root = os.path.dirname(current_dir)\\nsys.path.insert(0, src_root)\\n\\nfrom utils.logger import log\\n\\nclass MOEXOrderbook:\\n    \\\"\\\"\\\"–ö–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ –∑–∞—è–≤–æ–∫ —Å MOEX\\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.base_url = \\\"https://iss.moex.com/iss\\\"\\n        self.session = requests.Session()\\n        log.info(\\\"MOEX Orderbook –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\\\")\\n    \\n    def get_orderbook(self, ticker: str) -> dict:\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –∑–∞—è–≤–æ–∫ –ø–æ —Ç–∏–∫–µ—Ä—É\\\"\\\"\\\"\\n        url = f\\\"{self.base_url}/engines/stock/markets/shares/securities/{ticker}/orderbook.json\\\"\\n        \\n        try:\\n            response = self.session.get(url)\\n            response.raise_for_status()\\n            data = response.json()\\n            \\n            # –ü–∞—Ä—Å–∏–º —Å—Ç–∞–∫–∞–Ω\\n            orderbook_data = self._parse_orderbook(data)\\n            log.info(f\\\"–°—Ç–∞–∫–∞–Ω –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω\\\")\\n            return orderbook_data\\n            \\n        except Exception as e:\\n            log.error(f\\\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}\\\")\\n            log.error(f\\\"URL –±—ã–ª: {url}\\\")\\n            return {}\\n    \\n    def _parse_orderbook(self, data: dict) -> dict:\\n        \\\"\\\"\\\"–ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞–∫–∞–Ω–∞\\\"\\\"\\\"\\n        result = {}\\n        \\n        # –ü–∞—Ä—Å–∏–º –ø–æ–∫—É–ø–∫–∏ (bids)\\n        if 'orderbook' in data and 'bids' in data['orderbook']:\\n            bids_data = data['orderbook']['bids']\\n            if bids_data:\\n                result['bids'] = pd.DataFrame(bids_data)\\n        \\n        # –ü–∞—Ä—Å–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks)  \\n        if 'orderbook' in data and 'asks' in data['orderbook']:\\n            asks_data = data['orderbook']['asks']\\n            if asks_data:\\n                result['asks'] = pd.DataFrame(asks_data)\\n        \\n        return result\\n    \\n    def print_pretty_orderbook(self, ticker: str, levels: int = 5):\\n        \\\"\\\"\\\"–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω\\\"\\\"\\\"\\n        orderbook = self.get_orderbook(ticker)\\n        \\n        if not orderbook or ('bids' not in orderbook and 'asks' not in orderbook):\\n            print(f\\\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}\\\")\\n            print(\\\"‚ÑπÔ∏è  –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\\\")\\n            print(\\\"   - –¢–æ—Ä–≥–∏ –ø–æ —ç—Ç–æ–π –±—É–º–∞–≥–µ –Ω–µ –∏–¥—É—Ç\\\")\\n            print(\\\"   - –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ MOEX\\\")\\n            print(\\\"   - –¢–∏–∫–µ—Ä —É–∫–∞–∑–∞–Ω –Ω–µ–≤–µ—Ä–Ω–æ\\\")\\n            return\\n        \\n        print(f\\\"\\\\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker}:\\\")\\n        print(\\\"=\\\" * 50)\\n        \\n        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks) - —Å–≤–µ—Ä—Ö—É\\n        if 'asks' in orderbook and not orderbook['asks'].empty:\\n            print(\\\"üí∞ –ü–†–û–î–ê–ñ–ò (asks):\\\")\\n            asks_df = orderbook['asks'].head(levels)\\n            for _, row in asks_df.iterrows():\\n                price = row[0]  # –¶–µ–Ω–∞\\n                quantity = row[1]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ\\n                print(f\\\"   {price:8.2f} | {quantity:6} –ª–æ—Ç–æ–≤\\\")\\n        \\n        print(\\\"-\\\" * 30)\\n        \\n        # –í—ã–≤–æ–¥–∏–º –ø–æ–∫—É–ø–∫–∏ (bids) - —Å–Ω–∏–∑—É\\n        if 'bids' in orderbook and not orderbook['bids'].empty:\\n            print(\\\"üõí –ü–û–ö–£–ü–ö–ò (bids):\\\")\\n            bids_df = orderbook['bids'].head(levels)\\n            for _, row in bids_df.iterrows():\\n                price = row[0]  # –¶–µ–Ω–∞\\n                quantity = row[1]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ\\n                print(f\\\"   {price:8.2f} | {quantity:6} –ª–æ—Ç–æ–≤\\\")\\n        \\n        print(\\\"=\\\" * 50)\\n\\nif __name__ == \\\"__main__\\\":\\n    client = MOEXOrderbook()\\n    client.print_pretty_orderbook(\\\"SBER\\\")\\n\",\n      \"size\": 3403,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/data_feed/tinkoff_client.py\": {\n      \"content\": \"import os\\nimport sys\\nfrom datetime import datetime\\nfrom dotenv import load_dotenv\\n\\n# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env\\nload_dotenv()\\n\\n# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils\\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\\nsrc_root = os.path.dirname(current_dir)\\nsys.path.insert(0, src_root)\\n\\nfrom tinkoff.invest import Client, GetOrderBookRequest\\nfrom tinkoff.invest.schemas import InstrumentStatus\\nfrom utils.logger import log\\n\\nclass TinkoffAPIClient:\\n    \\\"\\\"\\\"–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Tinkoff Invest API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.token = os.getenv('INVEST_TOKEN')\\n        if not self.token:\\n            log.error(\\\"‚ùå –¢–æ–∫–µ–Ω Tinkoff Invest API –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\\\")\\n            raise ValueError(\\\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\\\")\\n        \\n        log.info(\\\"Tinkoff API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)\\\")\\n    \\n    def find_instrument_by_ticker(self, ticker):\\n        \\\"\\\"\\\"–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ —Ç–∏–∫–µ—Ä—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ FIGI\\\"\\\"\\\"\\n        with Client(self.token) as client:\\n            instruments = client.instruments.find_instrument(query=ticker)\\n            for instrument in instruments.instruments:\\n                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º instrument.state –≤–º–µ—Å—Ç–æ instrument.instrument_status\\n                if instrument.ticker == ticker and instrument.state == InstrumentStatus.INSTRUMENT_STATUS_BASE:\\n                    log.info(f\\\"–ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker}), FIGI: {instrument.figi}\\\")\\n                    return instrument\\n            log.error(f\\\"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º {ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω\\\")\\n            return None\\n    \\n    def get_orderbook(self, ticker: str, depth: int = 5):\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –∑–∞—è–≤–æ–∫ –ø–æ —Ç–∏–∫–µ—Ä—É\\\"\\\"\\\"\\n        instrument = self.find_instrument_by_ticker(ticker)\\n        if not instrument:\\n            return None\\n            \\n        try:\\n            with Client(self.token) as client:\\n                request = GetOrderBookRequest(figi=instrument.figi, depth=depth)\\n                orderbook = client.market_data.get_order_book(request)\\n                \\n                return {\\n                    'ticker': ticker,\\n                    'instrument': instrument,\\n                    'orderbook': orderbook,\\n                    'timestamp': datetime.now()\\n                }\\n                \\n        except Exception as e:\\n            log.error(f\\\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}\\\")\\n            return None\\n    \\n    def print_pretty_orderbook(self, ticker: str, depth: int = 5):\\n        \\\"\\\"\\\"–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω\\\"\\\"\\\"\\n        data = self.get_orderbook(ticker, depth)\\n        \\n        if not data:\\n            print(f\\\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}\\\")\\n            return\\n        \\n        orderbook = data['orderbook']\\n        instrument = data['instrument']\\n        \\n        print(f\\\"\\\\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker} ({instrument.name}):\\\")\\n        print(\\\"=\\\" * 60)\\n        \\n        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks) - —Å–≤–µ—Ä—Ö—É\\n        if orderbook.asks:\\n            print(\\\"üí∞ –ü–†–û–î–ê–ñ–ò (asks):\\\")\\n            for ask in orderbook.asks:\\n                price = self.quotation_to_float(ask.price)\\n                quantity = ask.quantity\\n                print(f\\\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\\\")\\n        \\n        print(\\\"-\\\" * 30)\\n        \\n        # –í—ã–≤–æ–¥–∏–º –ø–æ–∫—É–ø–∫–∏ (bids) - —Å–Ω–∏–∑—É  \\n        if orderbook.bids:\\n            print(\\\"üõí –ü–û–ö–£–ü–ö–ò (bids):\\\")\\n            for bid in orderbook.bids:\\n                price = self.quotation_to_float(bid.price)\\n                quantity = bid.quantity\\n                print(f\\\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\\\")\\n        \\n        print(\\\"=\\\" * 60)\\n        if hasattr(orderbook, 'best_bid') and orderbook.best_bid:\\n            print(f\\\"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: {self.quotation_to_float(orderbook.best_bid):.2f}\\\")\\n        if hasattr(orderbook, 'best_ask') and orderbook.best_ask:\\n            print(f\\\"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {self.quotation_to_float(orderbook.best_ask):.2f}\\\")\\n        print(f\\\"‚è∞ –í—Ä–µ–º—è: {data['timestamp'].strftime('%H:%M:%S')}\\\")\\n    \\n    def quotation_to_float(self, quotation):\\n        \\\"\\\"\\\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float\\\"\\\"\\\"\\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\\n            return quotation.units + quotation.nano / 1e9\\n        return float(quotation) if quotation else 0.0\\n\\nif __name__ == \\\"__main__\\\":\\n    client = TinkoffAPIClient()\\n    client.print_pretty_orderbook(\\\"SBER\\\")\\n\",\n      \"size\": 4306,\n      \"encoding\": \"utf-8\"\n    },\n    \"src/data_feed/moex_client.py\": {\n      \"content\": \"import requests\\nimport pandas as pd\\nfrom src.utils.logger import log\\n\\nclass MOEXClient:\\n    \\\"\\\"\\\"\\n    –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å API –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.base_url = \\\"https://iss.moex.com/iss\\\"\\n        self.session = requests.Session()\\n        log.info(\\\"MOEX –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\\\")\\n    \\n    def get_security_info(self, ticker: str) -> dict:\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∏—Ç—å –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É–º–∞–≥–µ\\\"\\\"\\\"\\n        url = f\\\"{self.base_url}/securities/{ticker}.json\\\"\\n        try:\\n            response = self.session.get(url)\\n            response.raise_for_status()\\n            data = response.json()\\n            log.info(f\\\"–î–∞–Ω–Ω—ã–µ –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω—ã\\\")\\n            return data\\n        except Exception as e:\\n            log.error(f\\\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ {ticker}: {e}\\\")\\n            return {}\\n    \\n    def get_current_market_data(self, ticker: str) -> dict:\\n        \\\"\\\"\\\"–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\\\"\\\"\\\"\\n        url = f\\\"{self.base_url}/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json\\\"\\n        try:\\n            response = self.session.get(url)\\n            data = response.json()\\n            \\n            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\\n            market_data = data.get('marketdata', {}).get('data', [])\\n            if market_data:\\n                # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è –∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\\n                last_trade = market_data[0]\\n                return {\\n                    'last_price': last_trade[12],  # LAST\\n                    'change': last_trade[13],      # CHANGE\\n                    'volume': last_trade[9]        # VOLUME\\n                }\\n            return {}\\n        except Exception as e:\\n            log.error(f\\\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö {ticker}: {e}\\\")\\n            return {}\\n\\nif __name__ == \\\"__main__\\\":\\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç\\n    client = MOEXClient()\\n    \\n    # –¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ SBER\\n    sber_info = client.get_security_info(\\\"SBER\\\")\\n    if sber_info:\\n        log.info(\\\"‚úÖ MOEX –∫–ª–∏–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç - –¥–∞–Ω–Ω—ã–µ SBER –ø–æ–ª—É—á–µ–Ω—ã\\\")\\n    \\n    sber_market = client.get_current_market_data(\\\"SBER\\\")\\n    if sber_market:\\n        log.info(f\\\"‚úÖ –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ SBER: {sber_market}\\\")\\n\",\n      \"size\": 2126,\n      \"encoding\": \"utf-8\"\n    }\n  }\n}",
      "size": 63237,
      "encoding": "utf-8"
    },
    "test_vscode.py": {
      "content": "import sys\nprint(\"üéØ VSCode —Ç–µ—Å—Ç –∑–∞–ø—É—â–µ–Ω!\")\nprint(f\"Python –ø—É—Ç—å: {sys.executable}\")\nprint(f\"–í–µ—Ä—Å–∏—è Python: {sys.version}\")\n\nif \"trading_env\" in sys.executable:\n    print(\"‚úÖ –†–∞–±–æ—Ç–∞–µ–º –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏!\")\nelse:\n    print(\"‚ùå –ù–ï –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏!\")\n\nimport os\nprint(f\"üìÅ –ü—É—Ç—å: {os.getcwd()}\")\n",
      "size": 300,
      "encoding": "utf-8"
    },
    "tests/test_basic.py": {
      "content": "# test_basic.py\nimport pandas as pd\nimport numpy as np\nimport requests\nimport ccxt\n\nprint(\"‚úÖ –í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Ä–∞–±–æ—Ç–∞—é—Ç!\")\n\n# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ\ndata = pd.DataFrame({\n    'price': [100, 101, 102, 101, 103],\n    'volume': [1000, 1500, 1200, 1800, 2000]\n})\n\nprint(\"üìä –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:\")\nprint(data)\nprint(f\"üìà –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {data['price'].mean():.2f}\")\n\n# –ü—Ä–æ–≤–µ—Ä—è–µ–º requests\nresponse = requests.get('https://httpbin.org/json')\nprint(f\"üåê HTTP –∑–∞–ø—Ä–æ—Å: {response.status_code}\")",
      "size": 474,
      "encoding": "utf-8"
    },
    "tests/final_structure_test.py": {
      "content": "import sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))\n\ndef test_imports():\n    \"\"\"–¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à–∏ –º–æ–¥—É–ª–∏\"\"\"\n    print(\"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã...\")\n    \n    try:\n        from src.utils.logger import log\n        print(\"‚úÖ src.utils.logger - –û–ö\")\n    except ImportError as e:\n        print(f\"‚ùå src.utils.logger: {e}\")\n    \n    try:\n        from src.data_feed.moex_client import MOEXClient\n        print(\"‚úÖ src.data_feed.moex_client - –û–ö\")\n    except ImportError as e:\n        print(f\"‚ùå src.data_feed.moex_client: {e}\")\n    \n    try:\n        import pandas as pd\n        print(\"‚úÖ pandas - –û–ö\")\n    except ImportError as e:\n        print(f\"‚ùå pandas: {e}\")\n    \n    print(\"\\nüéØ –¢–µ—Å—Ç –∏–º–ø–æ—Ä—Ç–æ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω\")\n\nif __name__ == \"__main__\":\n    test_imports()\n",
      "size": 827,
      "encoding": "utf-8"
    },
    "tests/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "scripts/hhru_data_export_v2.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö HeadHunter (HHRU) - –ø–µ—Ä–∏–æ–¥ —Å 26.09.2024\n\"\"\"\n\nimport os\nimport sys\nimport csv\nfrom datetime import datetime, timedelta\nfrom dotenv import load_dotenv\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nload_dotenv()\n\nfrom tinkoff.invest import Client, CandleInterval\nfrom tinkoff.invest.utils import now\nfrom utils.logger import log\n\nclass HHDataExporter:\n    def __init__(self):\n        self.token = os.getenv('INVEST_TOKEN')\n        if not self.token:\n            log.error(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n            raise ValueError(\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        log.info(\"HeadHunter Data Exporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def find_hhru_instrument(self):\n        \"\"\"–ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter –ø–æ —Ç–∏–∫–µ—Ä—É\"\"\"\n        with Client(self.token) as client:\n            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–∏–∫–µ—Ä–æ–≤ HeadHunter\n            tickers_to_try = [\"HEAD\"]\n            \n            for ticker in tickers_to_try:\n                log.info(f\"üîç –ò—â–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º: {ticker}\")\n                instruments = client.instruments.find_instrument(query=ticker)\n                \n                for instrument in instruments.instruments:\n                    if instrument.ticker.upper() == ticker.upper():\n                        log.info(f\"‚úÖ –ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker})\")\n                        log.info(f\"   FIGI: {instrument.figi}\")\n                        log.info(f\"   –¢–∏–ø: {instrument.instrument_type}\")\n                        return instrument\n            \n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter\")\n            return None\n    \n    def get_historical_candles(self, figi, from_date, to_date):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥\"\"\"\n        candles_data = []\n        \n        with Client(self.token) as client:\n            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –ø–æ –¥–Ω—è–º\n            response = client.market_data.get_candles(\n                figi=figi,\n                from_=from_date,\n                to=to_date,\n                interval=CandleInterval.CANDLE_INTERVAL_DAY\n            )\n            \n            for candle in response.candles:\n                candles_data.append({\n                    'time': candle.time.strftime('%Y-%m-%d %H:%M:%S'),\n                    'open': self.quotation_to_float(candle.open),\n                    'high': self.quotation_to_float(candle.high),\n                    'low': self.quotation_to_float(candle.low),\n                    'close': self.quotation_to_float(candle.close),\n                    'volume': candle.volume,\n                    'is_complete': candle.is_complete\n                })\n            \n            log.info(f\"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(candles_data)} —Å–≤–µ—á–µ–π\")\n            return candles_data\n    \n    def quotation_to_float(self, quotation):\n        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float\"\"\"\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\n            return quotation.units + quotation.nano / 1e9\n        return float(quotation) if quotation else 0.0\n    \n    def export_to_csv(self, candles_data, output_path):\n        \"\"\"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV\"\"\"\n        if not candles_data:\n            log.error(\"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞\")\n            return False\n        \n        try:\n            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n                fieldnames = ['time', 'open', 'high', 'low', 'close', 'volume', 'is_complete']\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                \n                writer.writeheader()\n                for candle in candles_data:\n                    writer.writerow(candle)\n            \n            log.info(f\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}\")\n            return True\n            \n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}\")\n            return False\n    \n    def run_export(self):\n        \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞\"\"\"\n        log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö HeadHunter...\")\n        \n        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç\n        instrument = self.find_hhru_instrument()\n        if not instrument:\n            return False\n        \n        # –ù–û–í–´–ô –ü–ï–†–ò–û–î: —Å 26.09.2024 –ø–æ 16.11.2025\n        from_date = datetime(2024, 9, 26)\n        to_date = datetime(2025, 11, 16)\n        \n        log.info(f\"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {from_date.strftime('%d.%m.%Y')} - {to_date.strftime('%d.%m.%Y')}\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\n        candles_data = self.get_historical_candles(\n            instrument.figi, \n            from_date, \n            to_date\n        )\n        \n        if not candles_data:\n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\")\n            return False\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª —Å –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ú –∏–º–µ–Ω–µ–º\n        desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n        # –•–ê–†–î–ö–û–î–ò–ú –∏–º—è —Ñ–∞–π–ª–∞\n        output_filename = \"headhunter_data_sep2024_nov2025.csv\"\n        output_path = os.path.join(desktop_path, output_filename)\n        \n        success = self.export_to_csv(candles_data, output_path)\n        \n        if success:\n            log.info(\"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n            print(f\"\\nüìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}\")\n            print(f\"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(candles_data)}\")\n            print(f\"üìÖ –ü–µ—Ä–∏–æ–¥: 26.09.2024 - 16.11.2025\")\n        \n        return success\n\ndef main():\n    \"\"\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞\"\"\"\n    try:\n        exporter = HHDataExporter()\n        exporter.run_export()\n        \n    except Exception as e:\n        log.error(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\")\n        print(\"\\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:\")\n        print(\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n        print(\"   - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ç–æ—Ä–≥–∏ –ø–æ HHRU –∏–¥—É—Ç\")\n        print(\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 5866,
      "encoding": "utf-8"
    },
    "scripts/scanner_gazp.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–°–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–∞ –ø–æ –ì–∞–∑–ø—Ä–æ–º—É\n–ó–∞–ø—É—Å–∫: python scripts/scanner_gazp.py\n\"\"\"\n\nimport sys\nimport os\nimport time\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom data_feed.orderbook import MOEXOrderbook\nfrom utils.logger import log\n\ndef main():\n    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–Ω–µ—Ä–∞\"\"\"\n    log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–∞...\")\n    \n    client = MOEXOrderbook()\n    \n    # –°–Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER (–æ–Ω –≤—Å–µ–≥–¥–∞ —Ç–æ—Ä–≥—É–µ—Ç—Å—è)\n    log.info(\"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ SBER...\")\n    test_orderbook = client.get_orderbook(\"SBER\")\n    if test_orderbook and ('bids' in test_orderbook or 'asks' in test_orderbook):\n        log.info(\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MOEX —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n    else:\n        log.error(\"‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ MOEX\")\n        return\n    \n    try:\n        while True:\n            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Å–æ–ª—å\n            os.system('clear' if os.name == 'posix' else 'cls')\n            \n            print(\"üéØ –°–ö–†–ò–ù–ï–† –°–¢–ê–ö–ê–ù–ê - –ì–ê–ó–ü–†–û–ú (GAZP)\")\n            print(\"–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\\n\")\n            \n            # –ü–æ–ª—É—á–∞–µ–º –∏ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω\n            client.print_pretty_orderbook(\"GAZP\")\n            \n            # –ñ–¥—ë–º 5 —Å–µ–∫—É–Ω–¥ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n            print(\"\\nüîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...\")\n            time.sleep(5)\n            \n    except KeyboardInterrupt:\n        log.info(\"‚èπÔ∏è  –°–∫—Ä–∏–Ω–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\")\n    except Exception as e:\n        log.error(f\"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–∫—Ä–∏–Ω–µ—Ä–µ: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 1522,
      "encoding": "utf-8"
    },
    "scripts/tinkoff_scanner.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–°–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–æ–≤ –Ω–∞ Tinkoff API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\n\"\"\"\n\nimport sys\nimport os\nimport time\nfrom dotenv import load_dotenv\n\n# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞\nload_dotenv()\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom data_feed.tinkoff_client_simple import TinkoffAPIClientSimple\nfrom utils.logger import log\n\ndef main():\n    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–Ω–µ—Ä–∞\"\"\"\n    log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–Ω–µ—Ä –Ω–∞ Tinkoff API (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)...\")\n    \n    try:\n        client = TinkoffAPIClientSimple()\n        \n        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ\n        test_data = client.get_orderbook(\"SBER\")\n        if test_data:\n            log.info(\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Tinkoff API —Ä–∞–±–æ—Ç–∞–µ—Ç\")\n        else:\n            log.error(\"‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ Tinkoff API\")\n            return\n    \n    except Exception as e:\n        log.error(f\"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}\")\n        return\n    \n    # –°–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\n    tickers = [\"ABIO\"]\n    \n    try:\n        while True:\n            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Å–æ–ª—å\n            os.system('clear' if os.name == 'posix' else 'cls')\n            \n            print(\"üéØ –°–ö–†–ò–ù–ï–† –°–¢–ê–ö–ê–ù–û–í - TINKOFF API (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)\")\n            print(\"–î–ê–ù–ù–´–ï –†–ï–ê–õ–¨–ù–´–ï - –ë–£–î–¨–¢–ï –û–°–¢–û–†–û–ñ–ù–´!\")\n            print(\"–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\\n\")\n            \n            for ticker in tickers:\n                client.print_pretty_orderbook(ticker, depth=3)\n                print()\n            \n            print(\"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 1 —Å–µ–∫—É–Ω–¥...\")\n            time.sleep(1)\n            \n    except KeyboardInterrupt:\n        log.info(\"‚èπÔ∏è  –°–∫—Ä–∏–Ω–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\")\n    except Exception as e:\n        log.error(f\"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–∫—Ä–∏–Ω–µ—Ä–µ: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 1764,
      "encoding": "utf-8"
    },
    "scripts/auto_ru_parser.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–ü–∞—Ä—Å–µ—Ä –¥–ª—è auto.ru - —Å–±–æ—Ä –º–∞—Ä–æ–∫ –∏ –º–æ–¥–µ–ª–µ–π –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π\n\"\"\"\n\nimport requests\nimport csv\nimport time\nimport os\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\nimport sys\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –ª–æ–≥–≥–µ—Ä–∞\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom utils.logger import log\n\nclass AutoRuParser:\n    def __init__(self):\n        self.session = requests.Session()\n        self.session.headers.update({\n            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n            'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',\n            'Accept-Encoding': 'gzip, deflate, br',\n            'Connection': 'keep-alive',\n            'Upgrade-Insecure-Requests': '1',\n        })\n        self.base_url = \"https://auto.ru\"\n        \n    def get_page(self, url):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É\"\"\"\n        try:\n            log.info(f\"üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}\")\n            response = self.session.get(url, timeout=10)\n            response.raise_for_status()\n            return response.text\n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}\")\n            return None\n    \n    def parse_brands_and_models(self, url, vehicle_type):\n        \"\"\"–ü–∞—Ä—Å–∏–º –º–∞—Ä–∫–∏ –∏ –º–æ–¥–µ–ª–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã\"\"\"\n        html = self.get_page(url)\n        if not html:\n            return []\n        \n        soup = BeautifulSoup(html, 'html.parser')\n        brands_data = []\n        \n        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –º–∞—Ä–∫–∞–º–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ)\n        brand_selectors = [\n            'select[name=\"mark\"] option',\n            '.Select[data-ga-name=\"mark\"] option',\n            '[data-ftid=\"sales__filter_mark\"] option',\n            'select[data-ftid=\"sales__filter_mark\"] option'\n        ]\n        \n        brand_options = None\n        for selector in brand_selectors:\n            brand_options = soup.select(selector)\n            if brand_options:\n                log.info(f\"‚úÖ –ù–∞—à–ª–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä –º–∞—Ä–æ–∫: {selector}\")\n                break\n        \n        if not brand_options:\n            log.warning(f\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–ø–∏—Å–æ–∫ –º–∞—Ä–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {url}\")\n            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–∞—Ä–∫–∏ –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º\n            brand_links = soup.select('a[href*=\"/cars/\"]')\n            log.info(f\"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –º–∞—Ä–∫–∏: {len(brand_links)}\")\n            return []\n        \n        log.info(f\"üè∑Ô∏è –ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–æ–∫: {len(brand_links)}\")\n        \n        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é –º–∞—Ä–∫—É\n        for option in brand_links:\n            brand_name = option.get_text(strip=True)\n            brand_value = option.get('value') or option.get('href', '')\n            \n            if not brand_name or brand_name in ['–õ—é–±–∞—è', '–í—Å–µ –º–∞—Ä–∫–∏', '']:\n                continue\n                \n            log.info(f\"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Ä–∫—É: {brand_name}\")\n            \n            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è —ç—Ç–æ–π –º–∞—Ä–∫–∏\n            models = self.get_models_for_brand(brand_name, brand_value, vehicle_type)\n            \n            for model_name in models:\n                brands_data.append({\n                    'brand': brand_name,\n                    'model': model_name,\n                    'vehicle_type': vehicle_type\n                })\n            \n            # –ó–∞–¥–µ—Ä–∂–∫–∞ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Å–µ—Ä–≤–µ—Ä\n            time.sleep(1)\n        \n        return brands_data\n    \n    def get_models_for_brand(self, brand_name, brand_value, vehicle_type):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–∞—Ä–∫–∏\"\"\"\n        models = []\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –º–æ–¥–µ–ª—è–º–∏\n        if 'cars' in vehicle_type.lower():\n            model_url = f\"https://auto.ru/nizhniy_novgorod/cars/{brand_name.lower()}/all/\"\n        else:\n            model_url = f\"https://auto.ru/nizhniy_novgorod/lcv/{brand_name.lower()}/all/\"\n        \n        html = self.get_page(model_url)\n        if not html:\n            return models\n        \n        soup = BeautifulSoup(html, 'html.parser')\n        \n        # –ò—â–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä –º–æ–¥–µ–ª–µ–π\n        model_selectors = [\n            'select[name=\"model\"] option',\n            '.Select[data-ga-name=\"model\"] option',\n            '[data-ftid=\"sales__filter_model\"] option',\n            'select[data-ftid=\"sales__filter_model\"] option'\n        ]\n        \n        model_options = None\n        for selector in model_selectors:\n            model_options = soup.select(selector)\n            if model_options:\n                break\n        \n        if model_options:\n            for option in model_options:\n                model_name = option.get_text(strip=True)\n                if model_name and model_name not in ['–õ—é–±–∞—è', '–í—Å–µ –º–æ–¥–µ–ª–∏', '']:\n                    models.append(model_name)\n        \n        log.info(f\"   üöó –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è {brand_name}: {len(models)}\")\n        return models\n    \n    def save_to_csv(self, data, filename):\n        \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª\"\"\"\n        desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n        filepath = os.path.join(desktop_path, filename)\n        \n        try:\n            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\n                fieldnames = ['brand', 'model', 'vehicle_type']\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                \n                writer.writeheader()\n                for row in data:\n                    writer.writerow(row)\n            \n            log.info(f\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filepath}\")\n            log.info(f\"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(data)}\")\n            return True\n            \n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}\")\n            return False\n    \n    def run_parser(self):\n        \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞\"\"\"\n        log.info(\"üöó –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä Auto.ru...\")\n        \n        all_data = []\n        \n        # –ü–∞—Ä—Å–∏–º –ª–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\n        log.info(\"üîç –ü–∞—Ä—Å–∏–º —Ä–∞–∑–¥–µ–ª '–õ–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ'...\")\n        cars_url = \"https://auto.ru/nizhniy_novgorod/cars/all/\"\n        cars_data = self.parse_brands_and_models(cars_url, \"–õ–µ–≥–∫–æ–≤–æ–π\")\n        all_data.extend(cars_data)\n        \n        # –ü–∞—Ä—Å–∏–º –ª–µ–≥–∫–∏–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\n        log.info(\"üîç –ü–∞—Ä—Å–∏–º —Ä–∞–∑–¥–µ–ª '–õ—ë–≥–∫–∏–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ'...\")\n        lcv_url = \"https://auto.ru/nizhniy_novgorod/lcv/all/\"\n        lcv_data = self.parse_brands_and_models(lcv_url, \"–ì—Ä—É–∑–æ–≤–æ–π\")\n        all_data.extend(lcv_data)\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n        if all_data:\n            self.save_to_csv(all_data, \"auto_ru_brands_models.csv\")\n            log.info(\"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n        else:\n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\")\n        \n        return all_data\n\ndef main():\n    \"\"\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞\"\"\"\n    try:\n        parser = AutoRuParser()\n        parser.run_parser()\n        \n    except Exception as e:\n        log.error(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 7071,
      "encoding": "utf-8"
    },
    "scripts/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "scripts/hhru_data_export.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö HeadHunter (HHRU)\n\"\"\"\n\nimport os\nimport sys\nimport csv\nfrom datetime import datetime, timedelta\nfrom dotenv import load_dotenv\n\n# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nload_dotenv()\n\nfrom tinkoff.invest import Client, CandleInterval\nfrom tinkoff.invest.utils import now\nfrom utils.logger import log\n\nclass HHDataExporter:\n    def __init__(self):\n        self.token = os.getenv('INVEST_TOKEN')\n        if not self.token:\n            log.error(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n            raise ValueError(\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        log.info(\"HeadHunter Data Exporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def find_hhru_instrument(self):\n        \"\"\"–ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter –ø–æ —Ç–∏–∫–µ—Ä—É\"\"\"\n        with Client(self.token) as client:\n            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–∏–∫–µ—Ä–æ–≤ HeadHunter\n            tickers_to_try = [\"HHRU\", \"HHRS\", \"HH\", \"HHR\"]\n            \n            for ticker in tickers_to_try:\n                log.info(f\"üîç –ò—â–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º: {ticker}\")\n                instruments = client.instruments.find_instrument(query=ticker)\n                \n                for instrument in instruments.instruments:\n                    if instrument.ticker.upper() == ticker.upper():\n                        log.info(f\"‚úÖ –ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker})\")\n                        log.info(f\"   FIGI: {instrument.figi}\")\n                        log.info(f\"   –¢–∏–ø: {instrument.instrument_type}\")\n                        return instrument\n            \n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter\")\n            return None\n    \n    def get_historical_candles(self, figi, from_date, to_date):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥\"\"\"\n        candles_data = []\n        \n        with Client(self.token) as client:\n            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –ø–æ –¥–Ω—è–º\n            response = client.market_data.get_candles(\n                figi=figi,\n                from_=from_date,\n                to=to_date,\n                interval=CandleInterval.CANDLE_INTERVAL_DAY\n            )\n            \n            for candle in response.candles:\n                candles_data.append({\n                    'time': candle.time.strftime('%Y-%m-%d %H:%M:%S'),\n                    'open': self.quotation_to_float(candle.open),\n                    'high': self.quotation_to_float(candle.high),\n                    'low': self.quotation_to_float(candle.low),\n                    'close': self.quotation_to_float(candle.close),\n                    'volume': candle.volume,\n                    'is_complete': candle.is_complete\n                })\n            \n            log.info(f\"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(candles_data)} —Å–≤–µ—á–µ–π\")\n            return candles_data\n    \n    def quotation_to_float(self, quotation):\n        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float\"\"\"\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\n            return quotation.units + quotation.nano / 1e9\n        return float(quotation) if quotation else 0.0\n    \n    def export_to_csv(self, candles_data, output_path):\n        \"\"\"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV\"\"\"\n        if not candles_data:\n            log.error(\"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞\")\n            return False\n        \n        try:\n            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n                fieldnames = ['time', 'open', 'high', 'low', 'close', 'volume', 'is_complete']\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                \n                writer.writeheader()\n                for candle in candles_data:\n                    writer.writerow(candle)\n            \n            log.info(f\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}\")\n            return True\n            \n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}\")\n            return False\n    \n    def run_export(self):\n        \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞\"\"\"\n        log.info(\"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö HeadHunter...\")\n        \n        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç\n        instrument = self.find_hhru_instrument()\n        if not instrument:\n            return False\n        \n        # –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö\n        from_date = datetime(2024, 1, 1)\n        to_date = datetime(2025, 11, 16)\n        \n        log.info(f\"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {from_date.strftime('%d.%m.%Y')} - {to_date.strftime('%d.%m.%Y')}\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\n        candles_data = self.get_historical_candles(\n            instrument.figi, \n            from_date, \n            to_date\n        )\n        \n        if not candles_data:\n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\")\n            return False\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª\n        desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n        output_filename = f\"headhunter_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n        output_path = os.path.join(desktop_path, output_filename)\n        \n        success = self.export_to_csv(candles_data, output_path)\n        \n        if success:\n            log.info(\"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n            print(f\"\\nüìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}\")\n            print(f\"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(candles_data)}\")\n        \n        return success\n\ndef main():\n    \"\"\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞\"\"\"\n    try:\n        exporter = HHDataExporter()\n        exporter.run_export()\n        \n    except Exception as e:\n        log.error(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\")\n        print(\"\\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:\")\n        print(\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n        print(\"   - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ç–æ—Ä–≥–∏ –ø–æ HHRU –∏–¥—É—Ç\")\n        print(\"   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 5756,
      "encoding": "utf-8"
    },
    "scripts/auto_ru_parser_simple.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è auto.ru\n\"\"\"\n\nimport requests\nimport csv\nimport os\nimport sys\nimport json\nimport time\n\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom utils.logger import log\n\nclass SimpleAutoRuParser:\n    def __init__(self):\n        self.session = requests.Session()\n        self.session.headers.update({\n            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',\n            'Accept': 'application/json, text/plain, */*',\n        })\n    \n    def get_api_data(self, category):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API auto.ru\"\"\"\n        url = f\"https://auto.ru/-/ajax/desktop/listing/\"\n        params = {\n            'section': 'all',\n            'category': category,\n            'sort': 'fresh_relevance_1-desc'\n        }\n        \n        try:\n            log.info(f\"üîß –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ API –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category}\")\n            response = self.session.get(url, params=params, timeout=10)\n            response.raise_for_status()\n            \n            data = response.json()\n            return data\n            \n        except Exception as e:\n            log.error(f\"‚ùå –û—à–∏–±–∫–∞ API –¥–ª—è {category}: {e}\")\n            return None\n    \n    def extract_brands_from_api(self, api_data, vehicle_type):\n        \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ–º –±—Ä–µ–Ω–¥—ã –∏–∑ API –¥–∞–Ω–Ω—ã—Ö\"\"\"\n        brands_data = []\n        \n        if not api_data or 'state' not in api_data:\n            return brands_data\n        \n        state = api_data['state']\n        \n        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –æ –±—Ä–µ–Ω–¥–∞—Ö\n        possible_paths = [\n            state.get('listing', {}).get('data', {}).get('filters', {}).get('mark', []),\n            state.get('filters', {}).get('mark', []),\n            state.get('mark', [])\n        ]\n        \n        marks = []\n        for path in possible_paths:\n            if path and isinstance(path, list) and len(path) > 0:\n                marks = path\n                break\n        \n        log.info(f\"üè∑Ô∏è –ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–æ–∫ –≤ API: {len(marks)}\")\n        \n        for mark in marks:\n            if isinstance(mark, dict):\n                brand_name = mark.get('name', mark.get('title', ''))\n                if brand_name and brand_name not in ['–õ—é–±–∞—è', '–í—Å–µ –º–∞—Ä–∫–∏']:\n                    # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫—É –±–µ–∑ –º–æ–¥–µ–ª–µ–π\n                    brands_data.append({\n                        'brand': brand_name,\n                        'model': '–í—Å–µ –º–æ–¥–µ–ª–∏',\n                        'vehicle_type': vehicle_type\n                    })\n        \n        return brands_data\n    \n    def run_parser(self):\n        \"\"\"–ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä\"\"\"\n        log.info(\"üöó –ó–∞–ø—É—Å–∫–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä Auto.ru...\")\n        \n        all_data = []\n        \n        # –õ–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\n        cars_data = self.get_api_data('cars')\n        if cars_data:\n            cars_brands = self.extract_brands_from_api(cars_data, \"–õ–µ–≥–∫–æ–≤–æ–π\")\n            all_data.extend(cars_brands)\n        \n        time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏\n        \n        # –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏\n        lcv_data = self.get_api_data('lcv')\n        if lcv_data:\n            lcv_brands = self.extract_brands_from_api(lcv_data, \"–ì—Ä—É–∑–æ–≤–æ–π\")\n            all_data.extend(lcv_brands)\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV\n        if all_data:\n            desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n            filepath = os.path.join(desktop_path, \"auto_ru_brands_simple.csv\")\n            \n            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\n                writer = csv.DictWriter(csvfile, fieldnames=['brand', 'model', 'vehicle_type'])\n                writer.writeheader()\n                writer.writerows(all_data)\n            \n            log.info(f\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filepath}\")\n            log.info(f\"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(all_data)}\")\n        else:\n            log.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\")\n        \n        return all_data\n\ndef main():\n    try:\n        parser = SimpleAutoRuParser()\n        parser.run_parser()\n    except Exception as e:\n        log.error(f\"‚ùå –û—à–∏–±–∫–∞: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "size": 4113,
      "encoding": "utf-8"
    },
    ".vscode/settings.json": {
      "content": "{\n    \"python.defaultInterpreterPath\": \"${workspaceFolder}/trading_env/bin/python\",\n    \"python.terminal.activateEnvironment\": true,\n    \"python.linting.enabled\": true,\n    \"python.formatting.provider\": \"black\",\n    \"python.formatting.blackArgs\": [\"--line-length\", \"100\"],\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n        \"source.organizeImports\": \"explicit\"\n    },\n    \"python.analysis.extraPaths\": [\"./src\"],\n    \"files.autoSave\": \"onFocusChange\",\n    \"terminal.integrated.shellArgs.osx\": [\"-l\"],\n    \"[python]\": {\n        \"editor.defaultFormatter\": \"ms-python.python\"\n    }\n}\n",
      "size": 605,
      "encoding": "utf-8"
    },
    "src/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/strategies/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/utils/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/utils/logger.py": {
      "content": "from loguru import logger\nimport sys\nimport os\n\ndef setup_logger():\n    \"\"\"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è trading –±–æ—Ç–∞\"\"\"\n    \n    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\n    os.makedirs(\"logs\", exist_ok=True)\n    \n    # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π handler\n    logger.remove()\n    \n    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π handler\n    logger.add(\n        sys.stdout,\n        format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>\",\n        level=\"INFO\",\n        colorize=True\n    )\n    \n    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª–æ–≤—ã–π handler\n    logger.add(\n        \"logs/trading_bot.log\",\n        rotation=\"10 MB\",\n        retention=\"10 days\",\n        level=\"DEBUG\",\n        format=\"{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}\"\n    )\n    \n    return logger\n\n# –°–æ–∑–¥–∞—ë–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä\nlog = setup_logger()\n\nif __name__ == \"__main__\":\n    log.info(\"–õ–æ–≥–≥–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!\")\n    log.debug(\"–û—Ç–ª–∞–¥–æ—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\")\n    log.warning(\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ\")\n",
      "size": 1049,
      "encoding": "utf-8"
    },
    "src/risk_management/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/execution/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/data_feed/__init__.py": {
      "content": "",
      "size": 0,
      "encoding": "utf-8"
    },
    "src/data_feed/tinkoff_client_simple.py": {
      "content": "import os\nimport sys\nfrom datetime import datetime\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nsrc_root = os.path.dirname(current_dir)\nsys.path.insert(0, src_root)\n\nfrom tinkoff.invest import Client\nfrom utils.logger import log\n\nclass TinkoffAPIClientSimple:\n    def __init__(self):\n        self.token = os.getenv('INVEST_TOKEN')\n        if not self.token:\n            log.error(\"‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n            raise ValueError(\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        log.info(\"Tinkoff API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)\")\n    \n    def find_instrument_by_ticker(self, ticker):\n        with Client(self.token) as client:\n            instruments = client.instruments.find_instrument(query=ticker)\n            for instrument in instruments.instruments:\n                if instrument.ticker == ticker:\n                    log.info(f\"–ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker}), FIGI: {instrument.figi}\")\n                    # –£–ë–ò–†–ê–ï–ú –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã\n                    return instrument\n            log.error(f\"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º {ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n            return None\n    \n    def get_orderbook(self, ticker: str, depth: int = 5):\n        instrument = self.find_instrument_by_ticker(ticker)\n        if not instrument:\n            return None\n            \n        try:\n            with Client(self.token) as client:\n                log.info(f\"–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å—Ç–∞–∫–∞–Ω –¥–ª—è FIGI: {instrument.figi}, –≥–ª—É–±–∏–Ω–∞: {depth}\")\n                orderbook = client.market_data.get_order_book(figi=instrument.figi, depth=depth)\n                \n                # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ç–∞–∫–∞–Ω–∞\n                log.info(f\"–°—Ç–∞–∫–∞–Ω –ø–æ–ª—É—á–µ–Ω: {orderbook}\")\n                log.info(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ bids: {len(orderbook.bids)}\")\n                log.info(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ asks: {len(orderbook.asks)}\")\n                \n                return {\n                    'ticker': ticker,\n                    'instrument': instrument,\n                    'orderbook': orderbook,\n                    'timestamp': datetime.now()\n                }\n                \n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}\")\n            return None\n    \n    def print_pretty_orderbook(self, ticker: str, depth: int = 5):\n        data = self.get_orderbook(ticker, depth)\n        \n        if not data:\n            print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}\")\n            return\n        \n        orderbook = data['orderbook']\n        instrument = data['instrument']\n        \n        print(f\"\\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker} ({instrument.name}):\")\n        print(\"=\" * 60)\n        \n        if orderbook.asks:\n            print(\"üí∞ –ü–†–û–î–ê–ñ–ò (asks):\")\n            for ask in orderbook.asks:\n                price = self.quotation_to_float(ask.price)\n                quantity = ask.quantity\n                print(f\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        else:\n            print(\"üí∞ –ü–†–û–î–ê–ñ–ò (asks): –ø—É—Å—Ç–æ\")\n        \n        print(\"-\" * 30)\n        \n        if orderbook.bids:\n            print(\"üõí –ü–û–ö–£–ü–ö–ò (bids):\")\n            for bid in orderbook.bids:\n                price = self.quotation_to_float(bid.price)\n                quantity = bid.quantity\n                print(f\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        else:\n            print(\"üõí –ü–û–ö–£–ü–ö–ò (bids): –ø—É—Å—Ç–æ\")\n        \n        print(\"=\" * 60)\n        if hasattr(orderbook, 'best_bid_price') and orderbook.best_bid_price:\n            print(f\"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: {self.quotation_to_float(orderbook.best_bid_price):.2f}\")\n        else:\n            print(f\"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö\")\n            \n        if hasattr(orderbook, 'best_ask_price') and orderbook.best_ask_price:\n            print(f\"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {self.quotation_to_float(orderbook.best_ask_price):.2f}\")\n        else:\n            print(f\"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö\")\n            \n        print(f\"‚è∞ –í—Ä–µ–º—è: {data['timestamp'].strftime('%H:%M:%S')}\")\n    \n    def quotation_to_float(self, quotation):\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\n            return quotation.units + quotation.nano / 1e9\n        return float(quotation) if quotation else 0.0\n\nif __name__ == \"__main__\":\n    client = TinkoffAPIClientSimple()\n    client.print_pretty_orderbook(\"SBER\")\n",
      "size": 4292,
      "encoding": "utf-8"
    },
    "src/data_feed/orderbook.py": {
      "content": "import requests\nimport pandas as pd\nimport sys\nimport os\n\n# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nsrc_root = os.path.dirname(current_dir)\nsys.path.insert(0, src_root)\n\nfrom utils.logger import log\n\nclass MOEXOrderbook:\n    \"\"\"–ö–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ –∑–∞—è–≤–æ–∫ —Å MOEX\"\"\"\n    \n    def __init__(self):\n        self.base_url = \"https://iss.moex.com/iss\"\n        self.session = requests.Session()\n        log.info(\"MOEX Orderbook –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def get_orderbook(self, ticker: str) -> dict:\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –∑–∞—è–≤–æ–∫ –ø–æ —Ç–∏–∫–µ—Ä—É\"\"\"\n        url = f\"{self.base_url}/engines/stock/markets/shares/securities/{ticker}/orderbook.json\"\n        \n        try:\n            response = self.session.get(url)\n            response.raise_for_status()\n            data = response.json()\n            \n            # –ü–∞—Ä—Å–∏–º —Å—Ç–∞–∫–∞–Ω\n            orderbook_data = self._parse_orderbook(data)\n            log.info(f\"–°—Ç–∞–∫–∞–Ω –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω\")\n            return orderbook_data\n            \n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}\")\n            log.error(f\"URL –±—ã–ª: {url}\")\n            return {}\n    \n    def _parse_orderbook(self, data: dict) -> dict:\n        \"\"\"–ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞–∫–∞–Ω–∞\"\"\"\n        result = {}\n        \n        # –ü–∞—Ä—Å–∏–º –ø–æ–∫—É–ø–∫–∏ (bids)\n        if 'orderbook' in data and 'bids' in data['orderbook']:\n            bids_data = data['orderbook']['bids']\n            if bids_data:\n                result['bids'] = pd.DataFrame(bids_data)\n        \n        # –ü–∞—Ä—Å–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks)  \n        if 'orderbook' in data and 'asks' in data['orderbook']:\n            asks_data = data['orderbook']['asks']\n            if asks_data:\n                result['asks'] = pd.DataFrame(asks_data)\n        \n        return result\n    \n    def print_pretty_orderbook(self, ticker: str, levels: int = 5):\n        \"\"\"–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω\"\"\"\n        orderbook = self.get_orderbook(ticker)\n        \n        if not orderbook or ('bids' not in orderbook and 'asks' not in orderbook):\n            print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}\")\n            print(\"‚ÑπÔ∏è  –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\")\n            print(\"   - –¢–æ—Ä–≥–∏ –ø–æ —ç—Ç–æ–π –±—É–º–∞–≥–µ –Ω–µ –∏–¥—É—Ç\")\n            print(\"   - –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ MOEX\")\n            print(\"   - –¢–∏–∫–µ—Ä —É–∫–∞–∑–∞–Ω –Ω–µ–≤–µ—Ä–Ω–æ\")\n            return\n        \n        print(f\"\\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker}:\")\n        print(\"=\" * 50)\n        \n        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks) - —Å–≤–µ—Ä—Ö—É\n        if 'asks' in orderbook and not orderbook['asks'].empty:\n            print(\"üí∞ –ü–†–û–î–ê–ñ–ò (asks):\")\n            asks_df = orderbook['asks'].head(levels)\n            for _, row in asks_df.iterrows():\n                price = row[0]  # –¶–µ–Ω–∞\n                quantity = row[1]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ\n                print(f\"   {price:8.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        \n        print(\"-\" * 30)\n        \n        # –í—ã–≤–æ–¥–∏–º –ø–æ–∫—É–ø–∫–∏ (bids) - —Å–Ω–∏–∑—É\n        if 'bids' in orderbook and not orderbook['bids'].empty:\n            print(\"üõí –ü–û–ö–£–ü–ö–ò (bids):\")\n            bids_df = orderbook['bids'].head(levels)\n            for _, row in bids_df.iterrows():\n                price = row[0]  # –¶–µ–Ω–∞\n                quantity = row[1]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ\n                print(f\"   {price:8.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        \n        print(\"=\" * 50)\n\nif __name__ == \"__main__\":\n    client = MOEXOrderbook()\n    client.print_pretty_orderbook(\"SBER\")\n",
      "size": 3403,
      "encoding": "utf-8"
    },
    "src/data_feed/tinkoff_client.py": {
      "content": "import os\nimport sys\nfrom datetime import datetime\nfrom dotenv import load_dotenv\n\n# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env\nload_dotenv()\n\n# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nsrc_root = os.path.dirname(current_dir)\nsys.path.insert(0, src_root)\n\nfrom tinkoff.invest import Client, GetOrderBookRequest\nfrom tinkoff.invest.schemas import InstrumentStatus\nfrom utils.logger import log\n\nclass TinkoffAPIClient:\n    \"\"\"–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Tinkoff Invest API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)\"\"\"\n    \n    def __init__(self):\n        self.token = os.getenv('INVEST_TOKEN')\n        if not self.token:\n            log.error(\"‚ùå –¢–æ–∫–µ–Ω Tinkoff Invest API –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ\")\n            raise ValueError(\"–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n        \n        log.info(\"Tinkoff API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)\")\n    \n    def find_instrument_by_ticker(self, ticker):\n        \"\"\"–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ —Ç–∏–∫–µ—Ä—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ FIGI\"\"\"\n        with Client(self.token) as client:\n            instruments = client.instruments.find_instrument(query=ticker)\n            for instrument in instruments.instruments:\n                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º instrument.state –≤–º–µ—Å—Ç–æ instrument.instrument_status\n                if instrument.ticker == ticker and instrument.state == InstrumentStatus.INSTRUMENT_STATUS_BASE:\n                    log.info(f\"–ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker}), FIGI: {instrument.figi}\")\n                    return instrument\n            log.error(f\"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º {ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n            return None\n    \n    def get_orderbook(self, ticker: str, depth: int = 5):\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –∑–∞—è–≤–æ–∫ –ø–æ —Ç–∏–∫–µ—Ä—É\"\"\"\n        instrument = self.find_instrument_by_ticker(ticker)\n        if not instrument:\n            return None\n            \n        try:\n            with Client(self.token) as client:\n                request = GetOrderBookRequest(figi=instrument.figi, depth=depth)\n                orderbook = client.market_data.get_order_book(request)\n                \n                return {\n                    'ticker': ticker,\n                    'instrument': instrument,\n                    'orderbook': orderbook,\n                    'timestamp': datetime.now()\n                }\n                \n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}\")\n            return None\n    \n    def print_pretty_orderbook(self, ticker: str, depth: int = 5):\n        \"\"\"–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω\"\"\"\n        data = self.get_orderbook(ticker, depth)\n        \n        if not data:\n            print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}\")\n            return\n        \n        orderbook = data['orderbook']\n        instrument = data['instrument']\n        \n        print(f\"\\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker} ({instrument.name}):\")\n        print(\"=\" * 60)\n        \n        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks) - —Å–≤–µ—Ä—Ö—É\n        if orderbook.asks:\n            print(\"üí∞ –ü–†–û–î–ê–ñ–ò (asks):\")\n            for ask in orderbook.asks:\n                price = self.quotation_to_float(ask.price)\n                quantity = ask.quantity\n                print(f\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        \n        print(\"-\" * 30)\n        \n        # –í—ã–≤–æ–¥–∏–º –ø–æ–∫—É–ø–∫–∏ (bids) - —Å–Ω–∏–∑—É  \n        if orderbook.bids:\n            print(\"üõí –ü–û–ö–£–ü–ö–ò (bids):\")\n            for bid in orderbook.bids:\n                price = self.quotation_to_float(bid.price)\n                quantity = bid.quantity\n                print(f\"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤\")\n        \n        print(\"=\" * 60)\n        if hasattr(orderbook, 'best_bid') and orderbook.best_bid:\n            print(f\"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: {self.quotation_to_float(orderbook.best_bid):.2f}\")\n        if hasattr(orderbook, 'best_ask') and orderbook.best_ask:\n            print(f\"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {self.quotation_to_float(orderbook.best_ask):.2f}\")\n        print(f\"‚è∞ –í—Ä–µ–º—è: {data['timestamp'].strftime('%H:%M:%S')}\")\n    \n    def quotation_to_float(self, quotation):\n        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float\"\"\"\n        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\n            return quotation.units + quotation.nano / 1e9\n        return float(quotation) if quotation else 0.0\n\nif __name__ == \"__main__\":\n    client = TinkoffAPIClient()\n    client.print_pretty_orderbook(\"SBER\")\n",
      "size": 4306,
      "encoding": "utf-8"
    },
    "src/data_feed/moex_client.py": {
      "content": "import requests\nimport pandas as pd\nfrom src.utils.logger import log\n\nclass MOEXClient:\n    \"\"\"\n    –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å API –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏\n    \"\"\"\n    \n    def __init__(self):\n        self.base_url = \"https://iss.moex.com/iss\"\n        self.session = requests.Session()\n        log.info(\"MOEX –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def get_security_info(self, ticker: str) -> dict:\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É–º–∞–≥–µ\"\"\"\n        url = f\"{self.base_url}/securities/{ticker}.json\"\n        try:\n            response = self.session.get(url)\n            response.raise_for_status()\n            data = response.json()\n            log.info(f\"–î–∞–Ω–Ω—ã–µ –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω—ã\")\n            return data\n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ {ticker}: {e}\")\n            return {}\n    \n    def get_current_market_data(self, ticker: str) -> dict:\n        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\"\"\"\n        url = f\"{self.base_url}/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json\"\n        try:\n            response = self.session.get(url)\n            data = response.json()\n            \n            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n            market_data = data.get('marketdata', {}).get('data', [])\n            if market_data:\n                # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è –∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n                last_trade = market_data[0]\n                return {\n                    'last_price': last_trade[12],  # LAST\n                    'change': last_trade[13],      # CHANGE\n                    'volume': last_trade[9]        # VOLUME\n                }\n            return {}\n        except Exception as e:\n            log.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö {ticker}: {e}\")\n            return {}\n\nif __name__ == \"__main__\":\n    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç\n    client = MOEXClient()\n    \n    # –¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ SBER\n    sber_info = client.get_security_info(\"SBER\")\n    if sber_info:\n        log.info(\"‚úÖ MOEX –∫–ª–∏–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç - –¥–∞–Ω–Ω—ã–µ SBER –ø–æ–ª—É—á–µ–Ω—ã\")\n    \n    sber_market = client.get_current_market_data(\"SBER\")\n    if sber_market:\n        log.info(f\"‚úÖ –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ SBER: {sber_market}\")\n",
      "size": 2126,
      "encoding": "utf-8"
    }
  }
}

================================================================================
–§–ê–ô–õ: requirements.txt
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/requirements.txt
================================================================================

pandas>=2.0.0
numpy>=1.24.0
requests>=2.28.0
ccxt>=4.0.0
moexalex>=0.7.0
backtrader>=1.9.78
loguru>=0.7.0
python-dotenv>=1.0.0
tinkoff-invest>=2.1.0


================================================================================
–§–ê–ô–õ: testGit.txt
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/testGit.txt
================================================================================



================================================================================
–§–ê–ô–õ: test_debug.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/test_debug.py
================================================================================

import os
from dotenv import load_dotenv
load_dotenv()

from tinkoff.invest import Client

token = os.getenv('INVEST_TOKEN')
with Client(token) as client:
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–∑–æ–≤–∞
    from tinkoff.invest.schemas import GetOrderBookRequest
    
    # –í–∞—Ä–∏–∞–Ω—Ç 1
    try:
        request = GetOrderBookRequest(figi="BBG004730N88", depth=5)
        result = client.market_data.get_order_book(request)
        print("‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 1 —Å GetOrderBookRequest —Ä–∞–±–æ—Ç–∞–µ—Ç")
    except Exception as e:
        print(f"‚ùå –í–∞—Ä–∏–∞–Ω—Ç 1: {e}")
    
    # –í–∞—Ä–∏–∞–Ω—Ç 2  
    try:
        result = client.market_data.get_order_book(figi="BBG004730N88", depth=5)
        print("‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 2 —Å –ø—Ä—è–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç")
    except Exception as e:
        print(f"‚ùå –í–∞—Ä–∏–∞–Ω—Ç 2: {e}")



================================================================================
–§–ê–ô–õ: test_instruments.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/test_instruments.py
================================================================================

#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
"""

import os
import sys
from dotenv import load_dotenv

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

load_dotenv()

def main():
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...")
    
    token = os.getenv('INVEST_TOKEN')
    if not token:
        print("‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    try:
        from tinkoff.invest import Client
        from tinkoff.invest.schemas import InstrumentStatus
        
        with Client(token) as client:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ SBER
            instruments = client.instruments.find_instrument(query="SBER")
            print(f"üîç –ù–∞–π–¥–µ–Ω–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ SBER: {len(instruments.instruments)}")
            
            for i, instrument in enumerate(instruments.instruments[:3]):  # –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 3
                print(f"\n–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {i+1}:")
                print(f"  –¢–∏–∫–µ—Ä: {instrument.ticker}")
                print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {instrument.name}")
                print(f"  FIGI: {instrument.figi}")
                print(f"  State: {instrument.state}")
                print(f"  Status: {InstrumentStatus(instrument.state).name}")
                
                # –ü–æ–∫–∞–∂–µ–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã –æ–±—ä–µ–∫—Ç–∞
                print(f"  –í—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã: {[attr for attr in dir(instrument) if not attr.startswith('_')]}")
                
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: test_orderbook.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/test_orderbook.py
================================================================================

#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç —Å—Ç–∞–∫–∞–Ω–∞ - –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from data_feed.orderbook import MOEXOrderbook

def main():
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞–∫–∞–Ω...")
    
    client = MOEXOrderbook()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER (–æ–Ω –≤—Å–µ–≥–¥–∞ —Ç–æ—Ä–≥—É–µ—Ç—Å—è)
    print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω SBER...")
    client.print_pretty_orderbook("SBER")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ GAZP
    print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω GAZP...")
    client.print_pretty_orderbook("GAZP")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: test_setup.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/test_setup.py
================================================================================

print("üéâ –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
print("–í—ã –≤ –ø–∞–ø–∫–µ:", __file__)

import sys
print("Python –ø—É—Ç—å:", sys.executable)

# –ü—Ä–æ–≤–µ—Ä–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    import pandas as pd
    print("‚úÖ pandas —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
except ImportError:
    print("‚ùå pandas –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

try:
    import numpy as np
    print("‚úÖ numpy —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω") 
except ImportError:
    print("‚ùå numpy –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


================================================================================
–§–ê–ô–õ: test_tinkoff.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/test_tinkoff.py
================================================================================

#!/usr/bin/env python3
"""
–¢–µ—Å—Ç Tinkoff API - –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from data_feed.tinkoff_client import TinkoffAPIClient

def main():
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º Tinkoff API...")
    
    try:
        client = TinkoffAPIClient()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER
        print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω SBER...")
        client.print_pretty_orderbook("SBER")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ GAZP
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–∫–∞–Ω GAZP...")
        client.print_pretty_orderbook("GAZP")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("‚ÑπÔ∏è  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
        print("   - –¢–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        print("   - –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É")
        print("   - –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–æ–∫–µ–Ω–∞")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: test_tinkoff_simple.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/test_tinkoff_simple.py
================================================================================

#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç Tinkoff API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)
"""

import os
import sys
from dotenv import load_dotenv

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

load_dotenv()

def main():
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Tinkoff API...")
    
    token = os.getenv('INVEST_TOKEN')
    if not token:
        print("‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        return
    
    try:
        from tinkoff.invest import Client
        
        with Client(token) as client:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—á–µ—Ç–∞
            accounts = client.users.get_accounts()
            print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!")
            print(f"üìã –ù–∞–π–¥–µ–Ω–æ —Å—á–µ—Ç–æ–≤: {len(accounts.accounts)}")
            
            for account in accounts.accounts:
                print(f"   - {account.name} (ID: {account.id})")
                
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: test_vscode.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/test_vscode.py
================================================================================

import sys
print("üéØ VSCode —Ç–µ—Å—Ç –∑–∞–ø—É—â–µ–Ω!")
print(f"Python –ø—É—Ç—å: {sys.executable}")
print(f"–í–µ—Ä—Å–∏—è Python: {sys.version}")

if "trading_env" in sys.executable:
    print("‚úÖ –†–∞–±–æ—Ç–∞–µ–º –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏!")
else:
    print("‚ùå –ù–ï –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏!")

import os
print(f"üìÅ –ü—É—Ç—å: {os.getcwd()}")


================================================================================
–§–ê–ô–õ: working_requirements.txt
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/working_requirements.txt
================================================================================

pandas>=2.0.0
numpy>=1.24.0
requests>=2.28.0
ccxt>=4.0.0
python-binance>=1.0.19
aiohttp>=3.8.0
websocket-client>=1.5.0
backtrader>=1.9.78
loguru>=0.7.0
python-dotenv>=1.0.0
pydantic>=2.0.0
scipy>=1.10.0
scikit-learn>=1.2.0
matplotlib>=3.7.0
plotly>=5.13.0
seaborn>=0.12.0


================================================================================
–§–ê–ô–õ: project_utils/export_project.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/project_utils/export_project.py
================================================================================

#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª
–ó–∞–ø—É—Å–∫: python project_utils/export_project.py
"""

import os
import json
import base64
from datetime import datetime

def export_project():
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç –≤ –æ–¥–∏–Ω JSON —Ñ–∞–π–ª"""
    print("üì§ –í—ã–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞...")
    
    project_data = {
        "export_date": datetime.now().isoformat(),
        "project_name": "Python Trading Bot",
        "files": {}
    }
    
    # –ò—Å–∫–ª—é—á–∞–µ–º—ã–µ –ø–∞–ø–∫–∏ –∏ —Ñ–∞–π–ª—ã
    exclude_dirs = {'.git', '__pycache__', 'trading_env', 'data', 'logs'}
    exclude_files = {'.DS_Store'}
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞
    for root, dirs, files in os.walk("."):
        # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–∞–ø–∫–∏
        dirs[:] = [d for d in dirs if d not in exclude_dirs]
        
        for file in files:
            if file in exclude_files:
                continue
                
            file_path = os.path.join(root, file)
            relative_path = file_path[2:]  # —É–±–∏—Ä–∞–µ–º ./
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∞–º —Å–∫—Ä–∏–ø—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞
            if "project_utils/export_project.py" in relative_path:
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # –î–ª—è .env —Ñ–∞–π–ª–∞ –∑–∞–º–µ–Ω—è–µ–º —Ç–æ–∫–µ–Ω –Ω–∞ placeholder
                if file == '.env':
                    lines = content.split('\n')
                    new_lines = []
                    for line in lines:
                        if line.startswith('INVEST_TOKEN='):
                            new_lines.append('INVEST_TOKEN=–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω')
                        else:
                            new_lines.append(line)
                    content = '\n'.join(new_lines)
                
                project_data["files"][relative_path] = {
                    "content": content,
                    "size": len(content),
                    "encoding": "utf-8"
                }
                
                print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω: {relative_path}")
                
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {relative_path}: {e}")
                project_data["files"][relative_path] = {
                    "content": f"# –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}",
                    "size": 0,
                    "error": str(e)
                }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    output_filename = f"project_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    try:
        with open(output_filename, 'w', encoding='utf-8') as f:
            json.dump(project_data, f, indent=2, ensure_ascii=False)
        
        file_size = os.path.getsize(output_filename) / 1024 / 1024
        print(f"\nüéâ –ü—Ä–æ–µ–∫—Ç —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤: {output_filename}")
        print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size:.2f} MB")
        print(f"üìÅ –§–∞–π–ª–æ–≤ –≤ —ç–∫—Å–ø–æ—Ä—Ç–µ: {len(project_data['files'])}")
        print("\nüìã –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø—Ä–æ–µ–∫—Ç–∞:")
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        for file_path in sorted(project_data["files"].keys()):
            file_info = project_data["files"][file_path]
            print(f"  - {file_path} ({file_info['size']} –±–∞–π—Ç)")
            
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ Trading Bot Project Exporter")
    print("=" * 50)
    print("–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –≤ –æ–¥–∏–Ω JSON —Ñ–∞–π–ª")
    print("–¢–æ–∫–µ–Ω API –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ '–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω'")
    print("=" * 50)
    
    success = export_project()
    
    if success:
        print("\n‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print("üí° –ü–µ—Ä–µ–¥–∞–π—Ç–µ JSON —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞")
    else:
        print("\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –ø—Ä–æ–µ–∫—Ç–∞")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: scripts/__init__.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/scripts/__init__.py
================================================================================



================================================================================
–§–ê–ô–õ: scripts/auto_ru_parser.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/scripts/auto_ru_parser.py
================================================================================

#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è auto.ru - —Å–±–æ—Ä –º–∞—Ä–æ–∫ –∏ –º–æ–¥–µ–ª–µ–π –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
"""

import requests
import csv
import time
import os
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import sys

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –ª–æ–≥–≥–µ—Ä–∞
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from utils.logger import log

class AutoRuParser:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        self.base_url = "https://auto.ru"
        
    def get_page(self, url):
        """–ü–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
        try:
            log.info(f"üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            return response.text
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
            return None
    
    def parse_brands_and_models(self, url, vehicle_type):
        """–ü–∞—Ä—Å–∏–º –º–∞—Ä–∫–∏ –∏ –º–æ–¥–µ–ª–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        html = self.get_page(url)
        if not html:
            return []
        
        soup = BeautifulSoup(html, 'html.parser')
        brands_data = []
        
        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –º–∞—Ä–∫–∞–º–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ)
        brand_selectors = [
            'select[name="mark"] option',
            '.Select[data-ga-name="mark"] option',
            '[data-ftid="sales__filter_mark"] option',
            'select[data-ftid="sales__filter_mark"] option'
        ]
        
        brand_options = None
        for selector in brand_selectors:
            brand_options = soup.select(selector)
            if brand_options:
                log.info(f"‚úÖ –ù–∞—à–ª–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä –º–∞—Ä–æ–∫: {selector}")
                break
        
        if not brand_options:
            log.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–ø–∏—Å–æ–∫ –º–∞—Ä–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {url}")
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–∞—Ä–∫–∏ –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º
            brand_links = soup.select('a[href*="/cars/"]')
            log.info(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –º–∞—Ä–∫–∏: {len(brand_links)}")
            return []
        
        log.info(f"üè∑Ô∏è –ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–æ–∫: {len(brand_links)}")
        
        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é –º–∞—Ä–∫—É
        for option in brand_links:
            brand_name = option.get_text(strip=True)
            brand_value = option.get('value') or option.get('href', '')
            
            if not brand_name or brand_name in ['–õ—é–±–∞—è', '–í—Å–µ –º–∞—Ä–∫–∏', '']:
                continue
                
            log.info(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Ä–∫—É: {brand_name}")
            
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è —ç—Ç–æ–π –º–∞—Ä–∫–∏
            models = self.get_models_for_brand(brand_name, brand_value, vehicle_type)
            
            for model_name in models:
                brands_data.append({
                    'brand': brand_name,
                    'model': model_name,
                    'vehicle_type': vehicle_type
                })
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Å–µ—Ä–≤–µ—Ä
            time.sleep(1)
        
        return brands_data
    
    def get_models_for_brand(self, brand_name, brand_value, vehicle_type):
        """–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–∞—Ä–∫–∏"""
        models = []
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –º–æ–¥–µ–ª—è–º–∏
        if 'cars' in vehicle_type.lower():
            model_url = f"https://auto.ru/nizhniy_novgorod/cars/{brand_name.lower()}/all/"
        else:
            model_url = f"https://auto.ru/nizhniy_novgorod/lcv/{brand_name.lower()}/all/"
        
        html = self.get_page(model_url)
        if not html:
            return models
        
        soup = BeautifulSoup(html, 'html.parser')
        
        # –ò—â–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä –º–æ–¥–µ–ª–µ–π
        model_selectors = [
            'select[name="model"] option',
            '.Select[data-ga-name="model"] option',
            '[data-ftid="sales__filter_model"] option',
            'select[data-ftid="sales__filter_model"] option'
        ]
        
        model_options = None
        for selector in model_selectors:
            model_options = soup.select(selector)
            if model_options:
                break
        
        if model_options:
            for option in model_options:
                model_name = option.get_text(strip=True)
                if model_name and model_name not in ['–õ—é–±–∞—è', '–í—Å–µ –º–æ–¥–µ–ª–∏', '']:
                    models.append(model_name)
        
        log.info(f"   üöó –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è {brand_name}: {len(models)}")
        return models
    
    def save_to_csv(self, data, filename):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª"""
        desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
        filepath = os.path.join(desktop_path, filename)
        
        try:
            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['brand', 'model', 'vehicle_type']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                
                writer.writeheader()
                for row in data:
                    writer.writerow(row)
            
            log.info(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filepath}")
            log.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(data)}")
            return True
            
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}")
            return False
    
    def run_parser(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""
        log.info("üöó –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä Auto.ru...")
        
        all_data = []
        
        # –ü–∞—Ä—Å–∏–º –ª–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏
        log.info("üîç –ü–∞—Ä—Å–∏–º —Ä–∞–∑–¥–µ–ª '–õ–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ'...")
        cars_url = "https://auto.ru/nizhniy_novgorod/cars/all/"
        cars_data = self.parse_brands_and_models(cars_url, "–õ–µ–≥–∫–æ–≤–æ–π")
        all_data.extend(cars_data)
        
        # –ü–∞—Ä—Å–∏–º –ª–µ–≥–∫–∏–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏
        log.info("üîç –ü–∞—Ä—Å–∏–º —Ä–∞–∑–¥–µ–ª '–õ—ë–≥–∫–∏–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ'...")
        lcv_url = "https://auto.ru/nizhniy_novgorod/lcv/all/"
        lcv_data = self.parse_brands_and_models(lcv_url, "–ì—Ä—É–∑–æ–≤–æ–π")
        all_data.extend(lcv_data)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if all_data:
            self.save_to_csv(all_data, "auto_ru_brands_models.csv")
            log.info("‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        else:
            log.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ")
        
        return all_data

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    try:
        parser = AutoRuParser()
        parser.run_parser()
        
    except Exception as e:
        log.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: scripts/auto_ru_parser_simple.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/scripts/auto_ru_parser_simple.py
================================================================================

#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è auto.ru
"""

import requests
import csv
import os
import sys
import json
import time

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from utils.logger import log

class SimpleAutoRuParser:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Accept': 'application/json, text/plain, */*',
        })
    
    def get_api_data(self, category):
        """–ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API auto.ru"""
        url = f"https://auto.ru/-/ajax/desktop/listing/"
        params = {
            'section': 'all',
            'category': category,
            'sort': 'fresh_relevance_1-desc'
        }
        
        try:
            log.info(f"üîß –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ API –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category}")
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            return data
            
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ API –¥–ª—è {category}: {e}")
            return None
    
    def extract_brands_from_api(self, api_data, vehicle_type):
        """–ò–∑–≤–ª–µ–∫–∞–µ–º –±—Ä–µ–Ω–¥—ã –∏–∑ API –¥–∞–Ω–Ω—ã—Ö"""
        brands_data = []
        
        if not api_data or 'state' not in api_data:
            return brands_data
        
        state = api_data['state']
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –æ –±—Ä–µ–Ω–¥–∞—Ö
        possible_paths = [
            state.get('listing', {}).get('data', {}).get('filters', {}).get('mark', []),
            state.get('filters', {}).get('mark', []),
            state.get('mark', [])
        ]
        
        marks = []
        for path in possible_paths:
            if path and isinstance(path, list) and len(path) > 0:
                marks = path
                break
        
        log.info(f"üè∑Ô∏è –ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–æ–∫ –≤ API: {len(marks)}")
        
        for mark in marks:
            if isinstance(mark, dict):
                brand_name = mark.get('name', mark.get('title', ''))
                if brand_name and brand_name not in ['–õ—é–±–∞—è', '–í—Å–µ –º–∞—Ä–∫–∏']:
                    # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫—É –±–µ–∑ –º–æ–¥–µ–ª–µ–π
                    brands_data.append({
                        'brand': brand_name,
                        'model': '–í—Å–µ –º–æ–¥–µ–ª–∏',
                        'vehicle_type': vehicle_type
                    })
        
        return brands_data
    
    def run_parser(self):
        """–ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä"""
        log.info("üöó –ó–∞–ø—É—Å–∫–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä Auto.ru...")
        
        all_data = []
        
        # –õ–µ–≥–∫–æ–≤—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏
        cars_data = self.get_api_data('cars')
        if cars_data:
            cars_brands = self.extract_brands_from_api(cars_data, "–õ–µ–≥–∫–æ–≤–æ–π")
            all_data.extend(cars_brands)
        
        time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        
        # –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏
        lcv_data = self.get_api_data('lcv')
        if lcv_data:
            lcv_brands = self.extract_brands_from_api(lcv_data, "–ì—Ä—É–∑–æ–≤–æ–π")
            all_data.extend(lcv_brands)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        if all_data:
            desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
            filepath = os.path.join(desktop_path, "auto_ru_brands_simple.csv")
            
            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=['brand', 'model', 'vehicle_type'])
                writer.writeheader()
                writer.writerows(all_data)
            
            log.info(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filepath}")
            log.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(all_data)}")
        else:
            log.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ")
        
        return all_data

def main():
    try:
        parser = SimpleAutoRuParser()
        parser.run_parser()
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: scripts/hhru_data_export.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/scripts/hhru_data_export.py
================================================================================

#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö HeadHunter (HHRU)
"""

import os
import sys
import csv
from datetime import datetime, timedelta
from dotenv import load_dotenv

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

load_dotenv()

from tinkoff.invest import Client, CandleInterval
from tinkoff.invest.utils import now
from utils.logger import log

class HHDataExporter:
    def __init__(self):
        self.token = os.getenv('INVEST_TOKEN')
        if not self.token:
            log.error("‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
            raise ValueError("–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
        log.info("HeadHunter Data Exporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def find_hhru_instrument(self):
        """–ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter –ø–æ —Ç–∏–∫–µ—Ä—É"""
        with Client(self.token) as client:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–∏–∫–µ—Ä–æ–≤ HeadHunter
            tickers_to_try = ["HHRU", "HHRS", "HH", "HHR"]
            
            for ticker in tickers_to_try:
                log.info(f"üîç –ò—â–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º: {ticker}")
                instruments = client.instruments.find_instrument(query=ticker)
                
                for instrument in instruments.instruments:
                    if instrument.ticker.upper() == ticker.upper():
                        log.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker})")
                        log.info(f"   FIGI: {instrument.figi}")
                        log.info(f"   –¢–∏–ø: {instrument.instrument_type}")
                        return instrument
            
            log.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter")
            return None
    
    def get_historical_candles(self, figi, from_date, to_date):
        """–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        candles_data = []
        
        with Client(self.token) as client:
            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –ø–æ –¥–Ω—è–º
            response = client.market_data.get_candles(
                figi=figi,
                from_=from_date,
                to=to_date,
                interval=CandleInterval.CANDLE_INTERVAL_DAY
            )
            
            for candle in response.candles:
                candles_data.append({
                    'time': candle.time.strftime('%Y-%m-%d %H:%M:%S'),
                    'open': self.quotation_to_float(candle.open),
                    'high': self.quotation_to_float(candle.high),
                    'low': self.quotation_to_float(candle.low),
                    'close': self.quotation_to_float(candle.close),
                    'volume': candle.volume,
                    'is_complete': candle.is_complete
                })
            
            log.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(candles_data)} —Å–≤–µ—á–µ–π")
            return candles_data
    
    def quotation_to_float(self, quotation):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float"""
        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):
            return quotation.units + quotation.nano / 1e9
        return float(quotation) if quotation else 0.0
    
    def export_to_csv(self, candles_data, output_path):
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV"""
        if not candles_data:
            log.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return False
        
        try:
            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['time', 'open', 'high', 'low', 'close', 'volume', 'is_complete']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                
                writer.writeheader()
                for candle in candles_data:
                    writer.writerow(candle)
            
            log.info(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")
            return True
            
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}")
            return False
    
    def run_export(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        log.info("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö HeadHunter...")
        
        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        instrument = self.find_hhru_instrument()
        if not instrument:
            return False
        
        # –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö
        from_date = datetime(2024, 1, 1)
        to_date = datetime(2025, 11, 16)
        
        log.info(f"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {from_date.strftime('%d.%m.%Y')} - {to_date.strftime('%d.%m.%Y')}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        candles_data = self.get_historical_candles(
            instrument.figi, 
            from_date, 
            to_date
        )
        
        if not candles_data:
            log.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")
            return False
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª
        desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
        output_filename = f"headhunter_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        output_path = os.path.join(desktop_path, output_filename)
        
        success = self.export_to_csv(candles_data, output_path)
        
        if success:
            log.info("‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"\nüìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(candles_data)}")
        
        return success

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    try:
        exporter = HHDataExporter()
        exporter.run_export()
        
    except Exception as e:
        log.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:")
        print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        print("   - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ç–æ—Ä–≥–∏ –ø–æ HHRU –∏–¥—É—Ç")
        print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: scripts/hhru_data_export_v2.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/scripts/hhru_data_export_v2.py
================================================================================

#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö HeadHunter (HHRU) - –ø–µ—Ä–∏–æ–¥ —Å 26.09.2024
"""

import os
import sys
import csv
from datetime import datetime, timedelta
from dotenv import load_dotenv

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

load_dotenv()

from tinkoff.invest import Client, CandleInterval
from tinkoff.invest.utils import now
from utils.logger import log

class HHDataExporter:
    def __init__(self):
        self.token = os.getenv('INVEST_TOKEN')
        if not self.token:
            log.error("‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
            raise ValueError("–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
        log.info("HeadHunter Data Exporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def find_hhru_instrument(self):
        """–ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter –ø–æ —Ç–∏–∫–µ—Ä—É"""
        with Client(self.token) as client:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–∏–∫–µ—Ä–æ–≤ HeadHunter
            tickers_to_try = ["HEAD"]
            
            for ticker in tickers_to_try:
                log.info(f"üîç –ò—â–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º: {ticker}")
                instruments = client.instruments.find_instrument(query=ticker)
                
                for instrument in instruments.instruments:
                    if instrument.ticker.upper() == ticker.upper():
                        log.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker})")
                        log.info(f"   FIGI: {instrument.figi}")
                        log.info(f"   –¢–∏–ø: {instrument.instrument_type}")
                        return instrument
            
            log.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HeadHunter")
            return None
    
    def get_historical_candles(self, figi, from_date, to_date):
        """–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        candles_data = []
        
        with Client(self.token) as client:
            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –ø–æ –¥–Ω—è–º
            response = client.market_data.get_candles(
                figi=figi,
                from_=from_date,
                to=to_date,
                interval=CandleInterval.CANDLE_INTERVAL_DAY
            )
            
            for candle in response.candles:
                candles_data.append({
                    'time': candle.time.strftime('%Y-%m-%d %H:%M:%S'),
                    'open': self.quotation_to_float(candle.open),
                    'high': self.quotation_to_float(candle.high),
                    'low': self.quotation_to_float(candle.low),
                    'close': self.quotation_to_float(candle.close),
                    'volume': candle.volume,
                    'is_complete': candle.is_complete
                })
            
            log.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(candles_data)} —Å–≤–µ—á–µ–π")
            return candles_data
    
    def quotation_to_float(self, quotation):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float"""
        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):
            return quotation.units + quotation.nano / 1e9
        return float(quotation) if quotation else 0.0
    
    def export_to_csv(self, candles_data, output_path):
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV"""
        if not candles_data:
            log.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return False
        
        try:
            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['time', 'open', 'high', 'low', 'close', 'volume', 'is_complete']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                
                writer.writeheader()
                for candle in candles_data:
                    writer.writerow(candle)
            
            log.info(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")
            return True
            
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}")
            return False
    
    def run_export(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        log.info("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö HeadHunter...")
        
        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        instrument = self.find_hhru_instrument()
        if not instrument:
            return False
        
        # –ù–û–í–´–ô –ü–ï–†–ò–û–î: —Å 26.09.2024 –ø–æ 16.11.2025
        from_date = datetime(2024, 9, 26)
        to_date = datetime(2025, 11, 16)
        
        log.info(f"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {from_date.strftime('%d.%m.%Y')} - {to_date.strftime('%d.%m.%Y')}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        candles_data = self.get_historical_candles(
            instrument.figi, 
            from_date, 
            to_date
        )
        
        if not candles_data:
            log.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")
            return False
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª —Å –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ú –∏–º–µ–Ω–µ–º
        desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
        # –•–ê–†–î–ö–û–î–ò–ú –∏–º—è —Ñ–∞–π–ª–∞
        output_filename = "headhunter_data_sep2024_nov2025.csv"
        output_path = os.path.join(desktop_path, output_filename)
        
        success = self.export_to_csv(candles_data, output_path)
        
        if success:
            log.info("‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"\nüìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(candles_data)}")
            print(f"üìÖ –ü–µ—Ä–∏–æ–¥: 26.09.2024 - 16.11.2025")
        
        return success

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    try:
        exporter = HHDataExporter()
        exporter.run_export()
        
    except Exception as e:
        log.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:")
        print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        print("   - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ç–æ—Ä–≥–∏ –ø–æ HHRU –∏–¥—É—Ç")
        print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: scripts/scanner_gazp.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/scripts/scanner_gazp.py
================================================================================

#!/usr/bin/env python3
"""
–°–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–∞ –ø–æ –ì–∞–∑–ø—Ä–æ–º—É
–ó–∞–ø—É—Å–∫: python scripts/scanner_gazp.py
"""

import sys
import os
import time

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from data_feed.orderbook import MOEXOrderbook
from utils.logger import log

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–Ω–µ—Ä–∞"""
    log.info("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–∞...")
    
    client = MOEXOrderbook()
    
    # –°–Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ SBER (–æ–Ω –≤—Å–µ–≥–¥–∞ —Ç–æ—Ä–≥—É–µ—Ç—Å—è)
    log.info("–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ SBER...")
    test_orderbook = client.get_orderbook("SBER")
    if test_orderbook and ('bids' in test_orderbook or 'asks' in test_orderbook):
        log.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MOEX —Ä–∞–±–æ—Ç–∞–µ—Ç")
    else:
        log.error("‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ MOEX")
        return
    
    try:
        while True:
            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Å–æ–ª—å
            os.system('clear' if os.name == 'posix' else 'cls')
            
            print("üéØ –°–ö–†–ò–ù–ï–† –°–¢–ê–ö–ê–ù–ê - –ì–ê–ó–ü–†–û–ú (GAZP)")
            print("–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\n")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω
            client.print_pretty_orderbook("GAZP")
            
            # –ñ–¥—ë–º 5 —Å–µ–∫—É–Ω–¥ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            print("\nüîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...")
            time.sleep(5)
            
    except KeyboardInterrupt:
        log.info("‚èπÔ∏è  –°–∫—Ä–∏–Ω–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–∫—Ä–∏–Ω–µ—Ä–µ: {e}")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: scripts/tinkoff_scanner.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/scripts/tinkoff_scanner.py
================================================================================

#!/usr/bin/env python3
"""
–°–∫—Ä–∏–Ω–µ—Ä —Å—Ç–∞–∫–∞–Ω–æ–≤ –Ω–∞ Tinkoff API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)
"""

import sys
import os
import time
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from data_feed.tinkoff_client_simple import TinkoffAPIClientSimple
from utils.logger import log

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–Ω–µ—Ä–∞"""
    log.info("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–Ω–µ—Ä –Ω–∞ Tinkoff API (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)...")
    
    try:
        client = TinkoffAPIClientSimple()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        test_data = client.get_orderbook("SBER")
        if test_data:
            log.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Tinkoff API —Ä–∞–±–æ—Ç–∞–µ—Ç")
        else:
            log.error("‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ Tinkoff API")
            return
    
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        return
    
    # –°–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    tickers = ["ABIO"]
    
    try:
        while True:
            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Å–æ–ª—å
            os.system('clear' if os.name == 'posix' else 'cls')
            
            print("üéØ –°–ö–†–ò–ù–ï–† –°–¢–ê–ö–ê–ù–û–í - TINKOFF API (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)")
            print("–î–ê–ù–ù–´–ï –†–ï–ê–õ–¨–ù–´–ï - –ë–£–î–¨–¢–ï –û–°–¢–û–†–û–ñ–ù–´!")
            print("–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\n")
            
            for ticker in tickers:
                client.print_pretty_orderbook(ticker, depth=3)
                print()
            
            print("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 1 —Å–µ–∫—É–Ω–¥...")
            time.sleep(1)
            
    except KeyboardInterrupt:
        log.info("‚èπÔ∏è  –°–∫—Ä–∏–Ω–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–∫—Ä–∏–Ω–µ—Ä–µ: {e}")

if __name__ == "__main__":
    main()


================================================================================
–§–ê–ô–õ: src/__init__.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/__init__.py
================================================================================



================================================================================
–§–ê–ô–õ: src/data_feed/__init__.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/data_feed/__init__.py
================================================================================



================================================================================
–§–ê–ô–õ: src/data_feed/moex_client.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/data_feed/moex_client.py
================================================================================

import requests
import pandas as pd
from src.utils.logger import log

class MOEXClient:
    """
    –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å API –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏
    """
    
    def __init__(self):
        self.base_url = "https://iss.moex.com/iss"
        self.session = requests.Session()
        log.info("MOEX –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def get_security_info(self, ticker: str) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É–º–∞–≥–µ"""
        url = f"{self.base_url}/securities/{ticker}.json"
        try:
            response = self.session.get(url)
            response.raise_for_status()
            data = response.json()
            log.info(f"–î–∞–Ω–Ω—ã–µ –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω—ã")
            return data
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ {ticker}: {e}")
            return {}
    
    def get_current_market_data(self, ticker: str) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        url = f"{self.base_url}/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json"
        try:
            response = self.session.get(url)
            data = response.json()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            market_data = data.get('marketdata', {}).get('data', [])
            if market_data:
                # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è –∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                last_trade = market_data[0]
                return {
                    'last_price': last_trade[12],  # LAST
                    'change': last_trade[13],      # CHANGE
                    'volume': last_trade[9]        # VOLUME
                }
            return {}
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö {ticker}: {e}")
            return {}

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç
    client = MOEXClient()
    
    # –¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ SBER
    sber_info = client.get_security_info("SBER")
    if sber_info:
        log.info("‚úÖ MOEX –∫–ª–∏–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç - –¥–∞–Ω–Ω—ã–µ SBER –ø–æ–ª—É—á–µ–Ω—ã")
    
    sber_market = client.get_current_market_data("SBER")
    if sber_market:
        log.info(f"‚úÖ –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ SBER: {sber_market}")


================================================================================
–§–ê–ô–õ: src/data_feed/orderbook.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/data_feed/orderbook.py
================================================================================

import requests
import pandas as pd
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils
current_dir = os.path.dirname(os.path.abspath(__file__))
src_root = os.path.dirname(current_dir)
sys.path.insert(0, src_root)

from utils.logger import log

class MOEXOrderbook:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ –∑–∞—è–≤–æ–∫ —Å MOEX"""
    
    def __init__(self):
        self.base_url = "https://iss.moex.com/iss"
        self.session = requests.Session()
        log.info("MOEX Orderbook –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def get_orderbook(self, ticker: str) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –∑–∞—è–≤–æ–∫ –ø–æ —Ç–∏–∫–µ—Ä—É"""
        url = f"{self.base_url}/engines/stock/markets/shares/securities/{ticker}/orderbook.json"
        
        try:
            response = self.session.get(url)
            response.raise_for_status()
            data = response.json()
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç–∞–∫–∞–Ω
            orderbook_data = self._parse_orderbook(data)
            log.info(f"–°—Ç–∞–∫–∞–Ω –ø–æ {ticker} –ø–æ–ª—É—á–µ–Ω")
            return orderbook_data
            
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}")
            log.error(f"URL –±—ã–ª: {url}")
            return {}
    
    def _parse_orderbook(self, data: dict) -> dict:
        """–ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞–∫–∞–Ω–∞"""
        result = {}
        
        # –ü–∞—Ä—Å–∏–º –ø–æ–∫—É–ø–∫–∏ (bids)
        if 'orderbook' in data and 'bids' in data['orderbook']:
            bids_data = data['orderbook']['bids']
            if bids_data:
                result['bids'] = pd.DataFrame(bids_data)
        
        # –ü–∞—Ä—Å–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks)  
        if 'orderbook' in data and 'asks' in data['orderbook']:
            asks_data = data['orderbook']['asks']
            if asks_data:
                result['asks'] = pd.DataFrame(asks_data)
        
        return result
    
    def print_pretty_orderbook(self, ticker: str, levels: int = 5):
        """–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω"""
        orderbook = self.get_orderbook(ticker)
        
        if not orderbook or ('bids' not in orderbook and 'asks' not in orderbook):
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}")
            print("‚ÑπÔ∏è  –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            print("   - –¢–æ—Ä–≥–∏ –ø–æ —ç—Ç–æ–π –±—É–º–∞–≥–µ –Ω–µ –∏–¥—É—Ç")
            print("   - –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ MOEX")
            print("   - –¢–∏–∫–µ—Ä —É–∫–∞–∑–∞–Ω –Ω–µ–≤–µ—Ä–Ω–æ")
            return
        
        print(f"\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker}:")
        print("=" * 50)
        
        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks) - —Å–≤–µ—Ä—Ö—É
        if 'asks' in orderbook and not orderbook['asks'].empty:
            print("üí∞ –ü–†–û–î–ê–ñ–ò (asks):")
            asks_df = orderbook['asks'].head(levels)
            for _, row in asks_df.iterrows():
                price = row[0]  # –¶–µ–Ω–∞
                quantity = row[1]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
                print(f"   {price:8.2f} | {quantity:6} –ª–æ—Ç–æ–≤")
        
        print("-" * 30)
        
        # –í—ã–≤–æ–¥–∏–º –ø–æ–∫—É–ø–∫–∏ (bids) - —Å–Ω–∏–∑—É
        if 'bids' in orderbook and not orderbook['bids'].empty:
            print("üõí –ü–û–ö–£–ü–ö–ò (bids):")
            bids_df = orderbook['bids'].head(levels)
            for _, row in bids_df.iterrows():
                price = row[0]  # –¶–µ–Ω–∞
                quantity = row[1]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
                print(f"   {price:8.2f} | {quantity:6} –ª–æ—Ç–æ–≤")
        
        print("=" * 50)

if __name__ == "__main__":
    client = MOEXOrderbook()
    client.print_pretty_orderbook("SBER")


================================================================================
–§–ê–ô–õ: src/data_feed/tinkoff_client.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/data_feed/tinkoff_client.py
================================================================================

import os
import sys
from datetime import datetime
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils
current_dir = os.path.dirname(os.path.abspath(__file__))
src_root = os.path.dirname(current_dir)
sys.path.insert(0, src_root)

from tinkoff.invest import Client, GetOrderBookRequest
from tinkoff.invest.schemas import InstrumentStatus
from utils.logger import log

class TinkoffAPIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Tinkoff Invest API (–±–æ–µ–≤–æ–π –∫–æ–Ω—Ç—É—Ä)"""
    
    def __init__(self):
        self.token = os.getenv('INVEST_TOKEN')
        if not self.token:
            log.error("‚ùå –¢–æ–∫–µ–Ω Tinkoff Invest API –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
            raise ValueError("–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        log.info("Tinkoff API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)")
    
    def find_instrument_by_ticker(self, ticker):
        """–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ —Ç–∏–∫–µ—Ä—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ FIGI"""
        with Client(self.token) as client:
            instruments = client.instruments.find_instrument(query=ticker)
            for instrument in instruments.instruments:
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º instrument.state –≤–º–µ—Å—Ç–æ instrument.instrument_status
                if instrument.ticker == ticker and instrument.state == InstrumentStatus.INSTRUMENT_STATUS_BASE:
                    log.info(f"–ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker}), FIGI: {instrument.figi}")
                    return instrument
            log.error(f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º {ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
    
    def get_orderbook(self, ticker: str, depth: int = 5):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –∑–∞—è–≤–æ–∫ –ø–æ —Ç–∏–∫–µ—Ä—É"""
        instrument = self.find_instrument_by_ticker(ticker)
        if not instrument:
            return None
            
        try:
            with Client(self.token) as client:
                request = GetOrderBookRequest(figi=instrument.figi, depth=depth)
                orderbook = client.market_data.get_order_book(request)
                
                return {
                    'ticker': ticker,
                    'instrument': instrument,
                    'orderbook': orderbook,
                    'timestamp': datetime.now()
                }
                
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}")
            return None
    
    def print_pretty_orderbook(self, ticker: str, depth: int = 5):
        """–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞–∫–∞–Ω"""
        data = self.get_orderbook(ticker, depth)
        
        if not data:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}")
            return
        
        orderbook = data['orderbook']
        instrument = data['instrument']
        
        print(f"\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker} ({instrument.name}):")
        print("=" * 60)
        
        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–¥–∞–∂–∏ (asks) - —Å–≤–µ—Ä—Ö—É
        if orderbook.asks:
            print("üí∞ –ü–†–û–î–ê–ñ–ò (asks):")
            for ask in orderbook.asks:
                price = self.quotation_to_float(ask.price)
                quantity = ask.quantity
                print(f"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤")
        
        print("-" * 30)
        
        # –í—ã–≤–æ–¥–∏–º –ø–æ–∫—É–ø–∫–∏ (bids) - —Å–Ω–∏–∑—É  
        if orderbook.bids:
            print("üõí –ü–û–ö–£–ü–ö–ò (bids):")
            for bid in orderbook.bids:
                price = self.quotation_to_float(bid.price)
                quantity = bid.quantity
                print(f"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤")
        
        print("=" * 60)
        if hasattr(orderbook, 'best_bid') and orderbook.best_bid:
            print(f"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: {self.quotation_to_float(orderbook.best_bid):.2f}")
        if hasattr(orderbook, 'best_ask') and orderbook.best_ask:
            print(f"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {self.quotation_to_float(orderbook.best_ask):.2f}")
        print(f"‚è∞ –í—Ä–µ–º—è: {data['timestamp'].strftime('%H:%M:%S')}")
    
    def quotation_to_float(self, quotation):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Quotation –≤ float"""
        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):
            return quotation.units + quotation.nano / 1e9
        return float(quotation) if quotation else 0.0

if __name__ == "__main__":
    client = TinkoffAPIClient()
    client.print_pretty_orderbook("SBER")


================================================================================
–§–ê–ô–õ: src/data_feed/tinkoff_client_simple.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/data_feed/tinkoff_client_simple.py
================================================================================

import os
import sys
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

current_dir = os.path.dirname(os.path.abspath(__file__))
src_root = os.path.dirname(current_dir)
sys.path.insert(0, src_root)

from tinkoff.invest import Client
from utils.logger import log

class TinkoffAPIClientSimple:
    def __init__(self):
        self.token = os.getenv('INVEST_TOKEN')
        if not self.token:
            log.error("‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
            raise ValueError("–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
        log.info("Tinkoff API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–ë–û–ï–í–û–ô –ö–û–ù–¢–£–†)")
    
    def find_instrument_by_ticker(self, ticker):
        with Client(self.token) as client:
            instruments = client.instruments.find_instrument(query=ticker)
            for instrument in instruments.instruments:
                if instrument.ticker == ticker:
                    log.info(f"–ù–∞–π–¥–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {instrument.name} ({instrument.ticker}), FIGI: {instrument.figi}")
                    # –£–ë–ò–†–ê–ï–ú –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
                    return instrument
            log.error(f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å —Ç–∏–∫–µ—Ä–æ–º {ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
    
    def get_orderbook(self, ticker: str, depth: int = 5):
        instrument = self.find_instrument_by_ticker(ticker)
        if not instrument:
            return None
            
        try:
            with Client(self.token) as client:
                log.info(f"–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å—Ç–∞–∫–∞–Ω –¥–ª—è FIGI: {instrument.figi}, –≥–ª—É–±–∏–Ω–∞: {depth}")
                orderbook = client.market_data.get_order_book(figi=instrument.figi, depth=depth)
                
                # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ç–∞–∫–∞–Ω–∞
                log.info(f"–°—Ç–∞–∫–∞–Ω –ø–æ–ª—É—á–µ–Ω: {orderbook}")
                log.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ bids: {len(orderbook.bids)}")
                log.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ asks: {len(orderbook.asks)}")
                
                return {
                    'ticker': ticker,
                    'instrument': instrument,
                    'orderbook': orderbook,
                    'timestamp': datetime.now()
                }
                
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞ {ticker}: {e}")
            return None
    
    def print_pretty_orderbook(self, ticker: str, depth: int = 5):
        data = self.get_orderbook(ticker, depth)
        
        if not data:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –¥–ª—è {ticker}")
            return
        
        orderbook = data['orderbook']
        instrument = data['instrument']
        
        print(f"\nüìä –°—Ç–∞–∫–∞–Ω –ø–æ {ticker} ({instrument.name}):")
        print("=" * 60)
        
        if orderbook.asks:
            print("üí∞ –ü–†–û–î–ê–ñ–ò (asks):")
            for ask in orderbook.asks:
                price = self.quotation_to_float(ask.price)
                quantity = ask.quantity
                print(f"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤")
        else:
            print("üí∞ –ü–†–û–î–ê–ñ–ò (asks): –ø—É—Å—Ç–æ")
        
        print("-" * 30)
        
        if orderbook.bids:
            print("üõí –ü–û–ö–£–ü–ö–ò (bids):")
            for bid in orderbook.bids:
                price = self.quotation_to_float(bid.price)
                quantity = bid.quantity
                print(f"   {price:10.2f} | {quantity:6} –ª–æ—Ç–æ–≤")
        else:
            print("üõí –ü–û–ö–£–ü–ö–ò (bids): –ø—É—Å—Ç–æ")
        
        print("=" * 60)
        if hasattr(orderbook, 'best_bid_price') and orderbook.best_bid_price:
            print(f"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: {self.quotation_to_float(orderbook.best_bid_price):.2f}")
        else:
            print(f"üíé –õ—É—á—à–∏–π —Å–ø—Ä–æ—Å: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            
        if hasattr(orderbook, 'best_ask_price') and orderbook.best_ask_price:
            print(f"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {self.quotation_to_float(orderbook.best_ask_price):.2f}")
        else:
            print(f"üíé –õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            
        print(f"‚è∞ –í—Ä–µ–º—è: {data['timestamp'].strftime('%H:%M:%S')}")
    
    def quotation_to_float(self, quotation):
        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):
            return quotation.units + quotation.nano / 1e9
        return float(quotation) if quotation else 0.0

if __name__ == "__main__":
    client = TinkoffAPIClientSimple()
    client.print_pretty_orderbook("SBER")


================================================================================
–§–ê–ô–õ: src/execution/__init__.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/execution/__init__.py
================================================================================



================================================================================
–§–ê–ô–õ: src/risk_management/__init__.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/risk_management/__init__.py
================================================================================



================================================================================
–§–ê–ô–õ: src/strategies/__init__.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/strategies/__init__.py
================================================================================



================================================================================
–§–ê–ô–õ: src/utils/__init__.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/utils/__init__.py
================================================================================



================================================================================
–§–ê–ô–õ: src/utils/logger.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/src/utils/logger.py
================================================================================

from loguru import logger
import sys
import os

def setup_logger():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è trading –±–æ—Ç–∞"""
    
    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs("logs", exist_ok=True)
    
    # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π handler
    logger.remove()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π handler
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO",
        colorize=True
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª–æ–≤—ã–π handler
    logger.add(
        "logs/trading_bot.log",
        rotation="10 MB",
        retention="10 days",
        level="DEBUG",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}"
    )
    
    return logger

# –°–æ–∑–¥–∞—ë–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä
log = setup_logger()

if __name__ == "__main__":
    log.info("–õ–æ–≥–≥–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
    log.debug("–û—Ç–ª–∞–¥–æ—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
    log.warning("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ")


================================================================================
–§–ê–ô–õ: tests/__init__.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/tests/__init__.py
================================================================================



================================================================================
–§–ê–ô–õ: tests/final_structure_test.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/tests/final_structure_test.py
================================================================================

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

def test_imports():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à–∏ –º–æ–¥—É–ª–∏"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã...")
    
    try:
        from src.utils.logger import log
        print("‚úÖ src.utils.logger - –û–ö")
    except ImportError as e:
        print(f"‚ùå src.utils.logger: {e}")
    
    try:
        from src.data_feed.moex_client import MOEXClient
        print("‚úÖ src.data_feed.moex_client - –û–ö")
    except ImportError as e:
        print(f"‚ùå src.data_feed.moex_client: {e}")
    
    try:
        import pandas as pd
        print("‚úÖ pandas - –û–ö")
    except ImportError as e:
        print(f"‚ùå pandas: {e}")
    
    print("\nüéØ –¢–µ—Å—Ç –∏–º–ø–æ—Ä—Ç–æ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω")

if __name__ == "__main__":
    test_imports()


================================================================================
–§–ê–ô–õ: tests/test_basic.py
–ü–û–õ–ù–´–ô –ü–£–¢–¨: /Users/vladimirbasov/Desktop/python_trading/tests/test_basic.py
================================================================================

# test_basic.py
import pandas as pd
import numpy as np
import requests
import ccxt

print("‚úÖ –í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Ä–∞–±–æ—Ç–∞—é—Ç!")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
data = pd.DataFrame({
    'price': [100, 101, 102, 101, 103],
    'volume': [1000, 1500, 1200, 1800, 2000]
})

print("üìä –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:")
print(data)
print(f"üìà –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {data['price'].mean():.2f}")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º requests
response = requests.get('https://httpbin.org/json')
print(f"üåê HTTP –∑–∞–ø—Ä–æ—Å: {response.status_code}")

================================================================================
üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –≠–ö–°–ü–û–†–¢–ê
================================================================================
–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: 45
–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–¥–∞: 267698 –±–∞–π—Ç (261.4 –ö–ë)
–î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: 2025-12-06 22:03:58
================================================================================

üéØ –ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
1. –ò—â–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ —Å—Ç—Ä–æ–∫–µ "–§–ê–ô–õ: "
2. –í—Å–µ –ø—É—Ç–∏ —É–∫–∞–∑–∞–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ: /Users/vladimirbasov/Desktop/python_trading
3. –î–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
4. .env —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã –æ—Ç —Å–µ–∫—Ä–µ—Ç–æ–≤

================================================================================
–ö–û–ù–ï–¶ –≠–ö–°–ü–û–†–¢–ê
================================================================================
